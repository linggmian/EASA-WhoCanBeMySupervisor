Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Tradenames,Manufacturers,Funding Details,Funding Text 1,Funding Text 2,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Adamu H., Lutfi S.L., Malim N.H.A.H., Hassan R., Di Vaio A., Mohamed A.S.A.",57222538575;27567802400;35090139100;56575985100;55922628500;57190968285;,Framing twitter public sentiment on Nigerian government COVID-19 palliatives distribution using machine learning,2021,Sustainability (Switzerland),13,6,3497,,,,,10.3390/su13063497,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103101474&doi=10.3390%2fsu13063497&partnerID=40&md5=c68d161ce91902586e2c7e3bdb8b5a07,"School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Othman Yeop Abdullah Graduate School of Business (OYAGSB), Universiti Utara Malaysia (UUM), Kuala Lumpur, 50300, Malaysia; Department of Law, University of Naples “Parthenope”, Naples, 80132, Italy","Adamu, H., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi, S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Malim, N.H.A.H., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Hassan, R., Othman Yeop Abdullah Graduate School of Business (OYAGSB), Universiti Utara Malaysia (UUM), Kuala Lumpur, 50300, Malaysia; Di Vaio, A., Department of Law, University of Naples “Parthenope”, Naples, 80132, Italy; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Sustainable development plays a vital role in information and communication technology. In times of pandemics such as COVID-19, vulnerable people need help to survive. This help includes the distribution of relief packages and materials by the government with the primary objective of lessening the economic and psychological effects on the citizens affected by disasters such as the COVID-19 pandemic. However, there has not been an efficient way to monitor public funds’ accountability and transparency, especially in developing countries such as Nigeria. The understanding of public emotions by the government on distributed palliatives is important as it would indicate the reach and impact of the distribution exercise. Although several studies on English emotion classification have been conducted, these studies are not portable to a wider inclusive Nigerian case. This is because Informal Nigerian English (Pidgin), which Nigerians widely speak, has quite a different vocabulary from Standard English, thus limiting the applicability of the emotion classification of Standard English machine learning models. An Informal Nigerian English (Pidgin English) emotions dataset is constructed, pre-processed, and annotated. The dataset is then used to classify five emotion classes (anger, sadness, joy, fear, and disgust) on the COVID-19 palliatives and relief aid distribution in Nigeria using standard machine learning (ML) algorithms. Six ML algorithms are used in this study, and a comparative analysis of their performance is conducted. The algorithms are Multinomial Naïve Bayes (MNB), Support Vector Machine (SVM), Random Forest (RF), Logistics Regression (LR), K-Nearest Neighbor (KNN), and Decision Tree (DT). The conducted experiments reveal that Support Vector Machine outperforms the remaining classifiers with the highest accuracy of 88%. The “disgust” emotion class surpassed other emotion classes, i.e., sadness, joy, fear, and anger, with the highest number of counts from the classification conducted on the constructed dataset. Additionally, the conducted correlation analysis shows a significant relationship between the emotion classes of “Joy” and “Fear”, which implies that the public is excited about the palliatives’ distribution but afraid of inequality and transparency in the distribution process due to reasons such as corruption. Conclusively, the results from this experiment clearly show that the public emotions on COVID-19 support and relief aid packages’ distribution in Nigeria were not satisfactory, considering that the negative emotions from the public outnumbered the public happiness. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",COVID-19 palliatives; Machine learning; Nigerian Pidgin English Twitter dataset; Relief aid; Sentiment analysis; Social media,accountability; algorithm; COVID-19; developing world; government; machine learning; spatiotemporal analysis; Nigeria; Varanidae,,,,,"1001/PKOMP/8014001, 304/PKOMP/6315137","Funding: This research was funded jointly by RCMO, UNIVERSITI SAINS MALAYSIA under the, grants number 1001/PKOMP/8014001 and 304/PKOMP/6315137 and Research University Grant (1001/PKOMP/8014001).",,"Siddiqui, Abdul Hameed, A Sustainable Society: Its Meaning and Objectives (2018) Int. J. Res. Sci. Innov, p. 128. , www.rsisinternational.org, (accessed on 6 March 2021); (2020) Impact of COVID-19 on the Sustainable Development Goals: Pursuing the Sustainable Development Goals (SDGs) in a World Reshaped by COVID-19, , United Nations Development Programme; Frederick S. Pardee Center for International Futures. Joseph Korbel School of International Studies, University of Denver: Denver, CO, USA; Szabo, S., Nhau, B., Tsusaka, T.W., Kadigi, R.M.J., Payne, T., Kangile, J.R., Park, K.S., Burgess, N.D., Towards a Successful Post COVID-19 Transition of Monitoring, Evaluation, and Learning in Complex Sustainability Science Research-to-Policy Projects (2021) Sustainability, 13, p. 387; Rutkowska, A., Kacperak, K., Rutkowski, S., Cacciante, L., Kiper, P., Szczegielniak, J., The Impact of Isolation Due to COVID-19 on Physical Activity Levels in Adult Students (2021) Sustainability, 13, p. 446; Vaz, E., COVID-19 in Toronto: A Spatial Exploratory Analysis (2021) Sustainability, 13, p. 498; COVID-19 Dashboard by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU), , https://coronavirus.jhu.edu/map.html, (accessed on 8 January 2021); NCDC Coronavirus COVID-19 Microsite, , https://covid19.ncdc.gov.ng/, Nigeria Centre for Disease Control. Covid19.Ncdc.gov.ng; Nigeria Centre for Disease Control (NCDC). (accessed on 6 February 2021); Kemp, S., Digital 2020: Nigeria. DataReportal-Global Digital Insights, , https://datareportal.com/reports/digital-2020-nigeria, (accessed on 7 February 2021); Qiu, M., Sha, J., Utomo, S., Listening to Forests: Comparing the Perceived Restorative Characteristics of Natural Soundscapes before and after the COVID-19 Pandemic (2021) Sustainability, 13, p. 293; Tetrevova, L., Vavra, J., Munzarova, S., Communication of Socially-Responsible Activities by Higher Education Institutions (2021) Sustainability, 13, p. 483; Marinello, S., Lolli, F., Gamberini, R., The Impact of the COVID-19 Emergency on Local Vehicular Traffic and Its Consequences for the Environment: The Case of the City of Reggio Emilia (Italy) (2021) Sustainability, 13, p. 118; https://www.hrw.org/news/2020/04/14/nigeria-protect-most-vulnerable-covid-19-response, Human RightWatch. (accessed on 24 September 2020); Ricciardelli, A., Governance, Local Communities, and Citizens Participation (2018) Global Encyclopedia of Public Administration, Public Policy, and Governance, , Farazmand, A., Ed.; Springer: Cham, Switzerland; Loshin, D., Text Data Analytics: In Service of Smart Government, , https://papers.govtech.com/Text-Data-Analytics-In-Service-of-Smart-Government-49173.html, (accessed on 16 March 2021); Barns, S., Smart cities and urban data platforms: Designing interfaces for smart governance (2018) City Cult. Soc, 12, pp. 5-12; Kumar, A., Sharma, A., Systematic literature review on opinion mining of big data for government intelligence (2017) Webology, 14, pp. 6-47; Lennerholt, C., van Laere, J., Söderström, E., Implementation Challenges of Self Service Business Intelligence: A Literature Review (2018) Proceedings of the 51st Hawaii International Conference on System Sciences, 9, pp. 5055-5063. , Waikoloa Village, HI, USA, 3 January; Khan, K., Baharudin, B., Khan, A., Ullah, A., Mining opinion components from unstructured reviews: A review (2014) J. King Saud Univ. Comput. Inf. Sci, 26, pp. 258-275; https://www.statista.com/statistics/617136/digital-populationworldwide/, Digital Users Worldwide Statista. (accessed on 7 October 2020); Joshi, S., Deshpande, D., Twitter Sentiment Analysis System (2018) Int. J. Comput. Appl, 180, pp. 35-39; Varrella, S., Nigeria: Leading Social Media Platforms, , https://www.statista.com/statistics/1176101/leading-social-media-platforms-nigeria/, Statista. (accessed on 7 February 2021); (2016) Pidgin-West African Lingua Franca. BBC News, , https://www.bbc.com/news/world-africa-38000387, BBC News. 16 November (accessed on 7 February 2021); Desai, R.D., Sentiment Analysis of Twitter Data (2018) Proceedings of the 2nd International Conference on Intelligent Computing and Control Systems, pp. 114-117. , ICICCS, Madurai, India, 14-15 June; Huang, C.H., Hsieh, S.H., Predicting BIM labor cost with random forest and simple linear regression (2020) Autom. Constr, 118, p. 103280; Reddy, D.M., (2019) Twitter Sentiment Analysis using Distributed Word and Sentence Representation, , http://arxiv.org/abs/1904.12580, (accessed on 12 November 2020); Meng, L., Dong, Z.S., Christenson, L., Fulton, L., (2017) Mining Public Opinion on Twitter about Natural Disaster Response Using Machine Learning Techniques, , https://arxiv.org/ftp/arxiv/papers/2005/2005.07019.pdf, (accessed on 17 October 2020); Squicciarini, A., Tapia, A., Stehle, S., Sentiment analysis during Hurricane Sandy in emergency response (2017) Int. J. Disaster Risk Reduct, 21, pp. 213-222; Rathee, N., Joshi, N., Kaur, J., Sentiment Analysis Using Machine Learning Techniques on Python (2018) Proceedings of the 2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS), , Madurai, India, 14-15 June; Kanish, S., Henil, P., Devanshi, S., Manan, S., A Comparative Analysis of Logistic Regression, Random Forest and KNN Models for the Text Classification (2020) Augment. Hum. Res, 5, p. 1; Oyewusi, W.F., Adekanmbi, O., Akinsande, O., Semantic Enrichment of Nigerian Pidgin English for Contextual Sentiment Classification, , http://arxiv.org/abs/2003.12450?utm_source=researcher_app&utm_medium=referral&utm_campaign=RESR_MRKT_Researcher_inbound, arXiv 2020, arXiv:2003.12450v1. (accessed on 23 September 2020); Suh, A., Li, M., Digital Tracing during the COVID-19 Pandemic: User Appraisal, Emotion, and Continuance Intention (2021) Sustainability, 13, p. 608; Manguri, K.N., Ramadhan, R., Mohammed, A.P., Twitter Sentiment Analysis on Worldwide COVID-19 Outbreaks (2020) Kurd. J. Appl. Res, pp. 54-65; Bento, A.I., Thuy, N., Coady, W., Felipe, L.R., Yong, Y.A., Kosali, S., Evidence from internet search data shows information-seeking responses to news of local COVID-19 cases (2020) Natl. Acad. Sci, 117, pp. 11220-11222; Hasan, A., Moin, S., Karim, A., Shamshirband, S., Machine Learning-Based Sentiment Analysis for Twitter Accounts (2018) Math. Comput. Appl, 23, p. 11; Öztürk, N., Ayvaz, S., Sentiment analysis on Twitter: A text mining approach to the Syrian refugee crisis (2018) Telemat. Inform, 35, pp. 136-147; Yin, H., Cui, B., Lu, H., Huang, Y., Yao, J., A unified model for stable and temporal topic detection from social media data (2013) Proceedings of the International Conference Data Engineering, pp. 661-672. , Brisbane, Australia, 8-11 April; Sidarenka, U., (2019) Sentiment Analysis of German Twitter, , Ph.D. Thesis, Universität Potsdam, Berlin, Germany; Sonawane, S.S., Sentiment Analysis of Twitter Data: A Survey of Techniques (2016) Int. J. Comput. Appl, 139, pp. 5-15; Nakov, P., Ritter, A., Rosenthal, S., Sebastiani, F., Stoyanov, V., SemEval-2016 task 4: Sentiment analysis in twitter (2016) Proceedings of the SemEval 2016-10th International Workshop on Semantic Evaluation, pp. 1-18. , San Diego, CA, USA, 16-17 June; Chakriswaran, P., Vincent, D.R., Srinivasan, K., Sharma, V., Chang, C.Y., Reina, D.G., Emotion AI-driven sentiment analysis: A survey, future research directions, and open issues (2019) Appl. Sci, 9, p. 462; Balogun, T.A., In defense of Nigerian pidgin (2013) J. Lang. Cult, 4, pp. 90-98; Osoba, J.B., Analysis of Discourse in Nigerian Pidgin (2015) J. Univers. Lang, 16, pp. 131-159; Idegbekwe, D., Anthropomorphisms and the Nigerian Pidgin Proverbs: A Linguistic Conceptual Metaphorical Analysis (2020) EBSU J. Soc. Sci. Rev, 10, pp. 71-76; Bigi, B., Caron, B., Abiola, O., Developing Resources for Automated Speech Processing of the African Language Naija (Nigerian Pidgin) (2017) Proceedings of the 8th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, pp. 441-445. , Poznan, Poland, 10 November; Sung, Y.A., Kim, K.W., Kwon, H.J., Big Data Analysis of Korean Travelers’ Behavior in the Post-COVID-19 Era (2021) Sustainability, 13, p. 310; Zhao, F., Zhu, N., Hämäläinen, J., Protection of Children in Difficulty in China during the COVID-19 Pandemic (2021) Sustainability, 13, p. 279; Radulescu, C.V., Ladaru, G.R., Burlacu, S., Constantin, F., Ioanas, C., Petre, I.L., Impact of the COVID-19 Pandemic on the Romanian Labor Market (2021) Sustainability, 13, p. 271; Awwalu, J., Umar, N.A., Ibrahim, M.S., Nonyelum, O.F., A multinomial Naïve Bayes decision support system for COVID-19 detection (2020) FUDMA J. Sci, 4, pp. 704-711; Kaklamanis, M.M., Filippakis, M., Touloupos, M., Christodoulou, K., An experimental comparison of machine learning classification algorithms for breast cancer diagnosis (2019) Proceedings of the 16th European, Mediterranean, and Middle Eastern Conference, EMCIS 2019, 381, pp. 18-30. , Dubai, United Arab Emirates, 9-10 December Springer: Cham, Switzerland, 2020; Jianqiang, Z., Xiaolin, G., Comparison research on text pre-processing methods on twitter sentiment analysis (2017) IEEE Access, 5, pp. 2870-2879; Sahoo, D., Liu, C., Hoi, S.C.H., (2017) Malicious URL Detection using Machine Learning: A Survey, , arXiv arXiv:1701.07179; Rohini, J., Ambesh, B., Animesh, S., Abhishek, K.S., A Survey on Various Approaches for Sentiment Analysis and Performance Optimization (2017) Int. J. Eng. Res. Technol, 6, pp. 716-720; Khanvilkar, G., Deepali, V.P., Sentiment Analysis for Product Recommendation Using Random Forest (2018) Int. J. Eng. Technol, 7, p. 87; Joshi, A.M., Prabhune, S., Random forest: A hybrid implementation for sarcasm detection in public opinion mining (2019) Int. J. Innov. Technol. Explor. Eng, 8, pp. 5022-5025; Pathan, M., Patel, N., Yagnik, H., Shah, M., Artificial cognition for applications in smart agriculture: A comprehensive review (2020) Artif. Intell. Agric, 4, pp. 81-95; Varathan, K.D., Anastasia, G., Crestani, F., Comparative Opinion Mining: A Review (2017) J. Assoc. Inf. Sci. Technol, 64, pp. 811-829; Samuel, J., Ali, G.G., Rahman, M.M., Esawi, E., Samuel, Y., COVID-19 public sentiment insights and machine learning for tweets classification (2020) Information, 11, p. 314; Karami, A., Shah, V., Vaezi, R., Bansal, A., Twitter speaks: A case of national disaster situational awareness (2020) J. Inf. Sci, 46, pp. 313-324; Delizo, J.P.D., Abisado, M.B., De Los Trinos, M.I.P., Philippine twitter sentiments during COVID-19 Pandemic using Multinomial Naïve Bayes (2020) Int. J. Adv. Trends Comput. Sci. Eng, 64, pp. 408-412; Karisani, N., Karisani, P., (2020) Mining Coronavirus (COVID-19) Posts in Social Media, , arXiv arXiv:2004.06778; Emil, E., Jozef, B., Analysis of Online Consumer Behavior-Design of CRISP-DM Process Model (2020) Agris On-Line Pap. Econ. Inform, 9, pp. 13-22; Population, total-Nigeria | Data, , https://data.worldbank.org/indicator/SP.POP.TOTL?locations=NG, World Bank. The World Bank Group. (accessed on 6 February 2021); Kabir, A.I., Karim, R., Newaz, S., Hossain, M.I., The power of social media analytics: Text analytics based on sentiment analysis and word clouds on R (2018) J. Inform. Econ, 22, pp. 25-38; Danisman, T., Alpkocak, A., Feeler: Emotion classification of text using vector space model (2008) Conv. Commun. Interact. Soc. Intell, 1, p. 53; Thomas, B., Vinod, P., Dhanya, K.A., Multiclass emotion extraction from sentences (2014) Int. J. Sci. Eng. Res, 5, pp. 12-15","Lutfi, S.L.; School of Computer Sciences, Malaysia; email: syaheerah@usm.my",,,MDPI AG,,,,,20711050,,,,English,Sustainability,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85103101474
"Wahab M.N.A., Mohamed A.S.A., Sukor A.S.A., Teng O.C.",36471236100;57190968285;57209073616;57209690411;,Text Reader for Visually Impaired Person,2021,Journal of Physics: Conference Series,1755,1,12055,,,,,10.1088/1742-6596/1755/1/012055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102407044&doi=10.1088%2f1742-6596%2f1755%2f1%2f012055&partnerID=40&md5=c2c4db8d3189c3a5299630e0f2f124a9,"School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Centre of Advanced Sensor Technology (CEASTech), Universiti Malaysia Perlis, Perlis, Arau, 02600, Malaysia","Wahab, M.N.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Sukor, A.S.A., Centre of Advanced Sensor Technology (CEASTech), Universiti Malaysia Perlis, Perlis, Arau, 02600, Malaysia; Teng, O.C., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","There are approximately 1.3 billion people in the world have visual impairment issue. They usually have to read printed material using Braille. However, there are limitations for these people when the material is not printed in Braille. Although there is much electronic equipment that can help them to read, the prices are too expensive to afford. Thus, this paper proposes an affordable mobile application which is designed for the visually impaired person. The mobile application is able to capture the image of printed material with a mobile camera. The captured image is then converted to text by using image-to-text conversion in Optical Character Recognition (OCR) framework. Finally, the text will be read out into speech format using text-to-speech conversion in Text to Speech (TTS) framework. As a result, a person who has visual impairment can understand the printed material which is not written in Braille through listening instead of touching. Some alert sound is provided to allow the users to know what exactly happened in the mobile application. It is user friendly for the visually impaired person since the designed system has sound for guideline so they can always get to know the process of the application. © 2021 Published under licence by IOP Publishing Ltd.",,Electronic equipment; Ophthalmology; Optical character recognition; Mobile applications; Optical character recognition (OCR); Printed materials; Text conversion; Text to speech; Text-to-speech conversion; Visual impairment; Visually impaired persons; Mobile computing,,,,,"Universiti Malaysia Perlis

Universiti Sains Malaysia","This project is supported by USM Short Term Grant (PKOMP/6315262) and part of the collaboration project under Robotics, Computer Vision, and Image Processing (RCVIP) Research Group of Universiti Sains Malaysia (USM) and Centre of Advanced Sensor and Technology (CEASTech), University Malaysia Perlis (UniMAP).",,"(2014), World Health Organization (WHO) World Report on Vision; Organization, W. H., (2011) International Ststistical Classification of Diseases and Related Health Problems; I. S. for the E. of Eyesight 2006 20/20 Vision Activity-Eye Chart; Bowen, M., The Prevalence of Visual Impairment in People with Dementia (the PrOVIDe study): a cross-sectional study of people aged 60-89 years with dementia and qualitative exploration of individual, carer and professional perspectives (2016) Heal. Serv. Deliv. Res, 4, pp. 1-200; Saba, T., Sulong, G., Rehman, A., A Survey on Methods and Strategies on Touched Characters Segmentation (2010) Int. J. Res. Rev. Comput. Sci, 1, pp. 103-114; Vijayabharathi, K., Mahalakshmi, V., Implementation of OCR Using Raspberry Pi for Visually Impaired Person (2018) Int. J. Pure Appl. Math, 119, pp. 111-117; Dimitrova, D., Students with Visual Impairments: Braille Reading Rate (2015) Int. J. Cogn. Res. Sci. Eng. Educ, 3, pp. 1-6; Vader, L. A., Measuring Vision and Vision Loss Nurs (2009) Clin. North Am, 27, pp. 705-714; Ashrafi, E., National and sub-national burden of visual impairment in Iran 1990-2013 (2014) Study protocol Arch. Iran. Med, 17, pp. 810-815; Singla, S. K., Yadav, R. K., Optical character recognition based speech synthesis system using LabVIEW (2014) J. Appl. Res. Technol, 12, pp. 919-926; Jondhale, N., Gupta, S., Reading text extracted from an image using OCR and android Text to Speech (2018) Int. J. Latest Eng. Manag. Res. (IJLEMR), , ISSSN 2455-4847 03 64-67; Esmaeel, H., Apply Android Studio (SDK) Tools (2019) Int. J. Adv. Res. Comput. Sci. Softw. Eng, 5, pp. 88-92","Wahab, M.N.A.; School of Computer Sciences, Malaysia; email: mohdnadhir@usm.my",,,IOP Publishing Ltd,"5th International Conference on Electronic Design, ICED 2020",19-Aug-20,,167462,17426588,,,,English,J. Phys. Conf. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85102407044
"Al Qudah M.M.M., Mohamed A.S.A., Lutfi S.L.",57222567501;57190968285;27567802400;,Affective state recognition using thermal-based imaging: A survey,2021,Computer Systems Science and Engineering,37,1,,47,62,,,10.32604/CSSE.2021.015222,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103239312&doi=10.32604%2fCSSE.2021.015222&partnerID=40&md5=bef868e22b0f14d169bcdc8c900d2900,"School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Al Qudah, M.M.M., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi, S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","The thermal-based imaging technique has recently attracted the attention of researchers who are interested in the recognition of human affects due to its ability to measure the facial transient temperature, which is correlated with human affects and robustness against illumination changes. Therefore, studies have increasingly used the thermal imaging as a potential and supplemental solution to overcome the challenges of visual (RGB) imaging, such as the variation of light conditions and revealing original human affect. Moreover, the thermal-based imaging has shown promising results in the detection of psychophysiological signals, such as pulse rate and respiration rate in a contactless and noninvasive way. This paper presents a brief review on human affects and focuses on the advantages and challenges of the thermal imaging technique. In addition, this paper discusses the stages of thermal-based human affective state recognition, such as dataset type, preprocessing stage, region of interest (ROI), feature descriptors, and classification approaches with a brief performance analysis based on a number of works in the literature. This analysis could help beginners in the thermal imaging and affective recognition domain to explore numerous approaches used by researchers to construct an affective state system based on thermal imaging. © 2021 CRL Publishing. All rights reserved.",Affective state recognition; Feature extraction and classification; Spontaneous emotion; Thermal-based imaging,Classification (of information); Image segmentation; State estimation; Affective recognition; Classification approach; Feature descriptors; Illumination changes; Performance analysis; Psychophysiological signals; Region of interest; Transient temperature; Infrared imaging,,,,,Universiti Sains Malaysia,Funding Statement: This research was funded by the research university grant by Universiti Sains Malaysia [1001.PKOMP.8014001].,,"Greenblatt, S., Toward a universal language of motion: Reflections on a seventeenth-century muscle man (1994) LiNQ (Literature in North Queensland), 21 (2), pp. 56-62; Darwin, C., Introduction to The First Edition (1872) The Expression of Emotions in Man and Animals, p. 7. , 3rd edition, London, England: John Murray; Duchenne, G. B., de Boulogne, G. B. D., Cuthbertson, R. A., Manstead, A. S. R., Oatley, K., A review of previous work on muscle action in facial expression (1990) The Mechanism of Human Facial Expression, pp. 14-16. , https://books.google.com.sa/books?id=a9tjQC7xbNMC, New York, USA: Cambridge University Press; Ekman, P., Friesen, W. V., Constants across cultures in the face and emotion (1971) Journal of Personality and Social Psychology, 17 (2), pp. 124-129; Russell, J. A., A circumplex model of affect (1980) Journal of Personality and Social Psychology, 39 (6), p. 1161; Chen, C.H., Lee, I.J., Lin, L.Y., Augmented reality-based self-facial modeling to promote the emotional expression and social skills of adolescents with autism spectrum disorders (2015) Research in Developmental Disabilities, 36, pp. 396-403; Fendri, E., Boukhriss, R. R., Hammami, M., Fusion of thermal infrared and visible spectra for robust moving object detection (2017) Pattern Analysis and Applications, 20 (4), pp. 907-926; Desideri, L., Ottaviani, C., Malavasi, M., di Marzio, R., Bonifacci, P., Emotional processes in human-robot interaction during brief cognitive testing (2019) Computers in Human Behavior, 90 (1), pp. 331-342; Lee, M. S., Cho, Y. R., Lee, Y. K., Pae, D. S., Lim, M. T., PPG and EMG based emotion recognition using convolutional neural network (2019) ICINCO 2019-Proc. of the 16th Int. Conf. on Informatics in Control, Automation and Robotics, pp. 595-600. , Prague, Czech Republic; Miller, G. E., Cohen, S., Ritchey, A. K., Chronic psychological stress and the regulation of pro-inflammatory cytokines: A glucocorticoid-resistance model (2002) Health Psychology, 21 (6), pp. 531-541; Vitetta, L., Anton, B., Cortizo, F., Sali, A., Mind-body medicine: Stress and its impact on overall health and longevity (2005) Annals of the New York Academy of Sciences, 1057 (1), pp. 492-505; Gradus, J. L., Posttraumatic stress disorder and death from suicide (2018) Current Psychiatry Reports, 20 (11), p. S7; Mowrer, O. H., Introduction: Historical review and perespective (1960) Learning Theory and Behavior, p. 9. , Hoboken, NJ: John Wiley & Sons Inc; Frijda, N. H., Emotional behavior (1986) The Emotions, pp. 9-109. , https://books.google.com.sa/books?id=QkNuuVf-pBMC, Cambridge, UK: Cambridge University Press; Ekman, P., Universals and cultural differences in facial expressions of emotion (1971) Nebraska Sym. on Motivation, 19, pp. 209-282. , J. Cole, (ed) Lincoln, NE: Univercity of Nebraska Press; Scherer, K. R., Schorr, A., Johnstone, T., Appraisal theory (2001) Appraisal Processing in Emotion, , https://books.google.com.sa/books?id=fmtnDAAAQBAJ, Madison Avenue, New York, USA: Oxford University Press; Ortony, A., Clore, G., Appraisal theories: How cognition shapes affect into emotion (2008) Handbook of Emotions, pp. 628-642. , M. Lewis, J. M. Haviland-Jones, L. F. Barrett, (ed) 3rd edition, New York, USA: Guilford Press; Fasel, B., Luettin, J., Automatic facial expression analysis: A survey (2003) Pattern Recognition, 36 (1), pp. 259-275; Devito, J. A., Silence and paralanguage as communication (2017) ETC: A Review of General Semantics, 74 (3- 4), pp. 482-487; Knapp, M. L., Hall, J. A., Horgan, T. G., Nonverbal communication: Basic perspectives (2013) Nonverbal Communication in Human Interaction, pp. 3-19. , 8th edition, Boston, USA:Wadsworth Cengage Learning; Johar, S., (2016) Emotion, affect and personality in speech: The bias of language and paralanguage, pp. 1-6. , http://gen.lib.rus.ec/book/index.php?md5=79cb2f8fcb7c48eaa270d6b1ab364612, New York, USA: Springer International Publishing, [Online]. Available; Khatri, N. N., Shah, Z. H., Patel, S. A., Facial expression recognition: A survey (2014) Int. Journal of Computer Science and Information Technologies (IJCSIT), 5 (1), pp. 149-152; Smith, C., Scott, H., A Componential approach to the meaning of facial expressions (1997) The Psychology of Facial Expression (Studies in Emotion and Social Interaction), pp. 229-254. , G. Mandler, J. Russell and J. Fernández-Dols, (ed) Cambridge, UK: Cambridge University Press; Kihlstrom, J. F., Mulvaney, S., Tobias, B. A., Tobis, I. P., The emotional unconscious (2000) Cognition and Emotion, pp. 30-86. , https://psycnet.apa.org/record/2001-00519-002, J. F. Kihlstrom, G. H. Bower, J. P. Forgas and P. M. Niedenthal, (eds) New York, USA: Oxford University Press, [Online]. Available; Friesen, E., Ekman, P., Facial action coding system: A technique for the measurement of facial movement (1978) Consulting Psychologists Press, 3. , Palo Alto; Khalid, B., Khan, A. M., Akram, M. U., Batool, S., Person detection by fusion of visible and thermal images using convolutional neural network (2019) Int. Conf. on Communication, Computing and Digital Systems (C-CODE), pp. 143-148. , Islamabad, Pakistan; Shu, L., Xie, J., Yang, M., Li, Z., Li, Z., A review of emotion recognition using physiological signals (2018) Sensors, 18 (7), p. 2074; Kreibig, S. D., Autonomic nervous system activity in emotion: A review (2010) Biological Psychology, 84 (3), pp. 394-421; Samadiani, N., Huang, G., Cai, B., Luo, W., Chi, C.H., A review on automatic facial expression recognition systems assisted by multimodal sensor data (2019) Sensors (Basel), 19 (8), p. 1863; Jaimes, A., Sebe, N., Multimodal human-computer interaction: A survey (2007) Computer Vision and Image Understanding, 108 (1-2), pp. 116-134; Mehta, D., Siddiqui, M. F. H., Javaid, A. Y., Facial emotion recognition: A survey and real-world user experiences in mixed reality (2018) Sensors, 18 (2), p. 416; Gunes, H., Schuller, B., Pantic, M., Cowie, R., Emotion representation, analysis and synthesis in continuous space: A survey (2011) International Conference on Automatic Face and Gesture Recognition, pp. 827-834. , Santa Barbara, CA, USA; Busso, C., Deng, Z., Yildirim, S., Bulut, M., Lee, C. M., Analysis of emotion recognition using facial expressions, speech and multimodal information (2004) Proc. of the 6th Int. Conf. on Multimodal Interfaces (ICMI04), pp. 205-211. , Pennsylvania, USA: State College; Corneanu, C. A., Simón, M. O., Cohn, J. F., Guerrero, S. E., Survey on RGB, 3D, thermal, and multimodal approaches for facial expression recognition: History, trends, and affect-related applications (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, 38 (8), pp. 1548-1568; Shoumy, N. J., Ang, L. M., Seng, K. P., Rahaman, D. M., Zia, T., Multimodal big data affective analytics: A comprehensive survey using text, audio, visual and physiological signals (2020) Journal of Network and Computer Applications, 149 (1), p. 102447; Chunawale, A., Bedekar, D., Human emotion recognition using physiological signals: A survey (2020) 2nd Int. Conf. on Communication and Information Processing (ICCIP-2020), p. 9. , Tokyo, Japan; Saganowski, S., Dutkowiak, A., Dziadek, A., Dzieżyc, M., Komoszyńska, J., Emotion recognition using wearables: A systematic literature review-work-in-progress (2020) IEEE Int. Conf. on Pervasive Computing and Communications Workshops (PerCom Workshops), pp. 1-6; Faust, O., Hagiwara, Y., Hong, T. J., Lih, O. S., Acharya, U. R., Deep learning for healthcare applications based on physiological signals: A review (2018) Computer Methods and Programs in Biomedicine, 161 (1), pp. 1-13; Bong, S. Z., Murugappan, M., Yaacob, S., Methods and approaches on inferring human emotional stress changes through physiological signals: A review (2013) Int. Journal of Medical Engineering and Informatics, 5 (2), pp. 152-162; Jerritta, S., Murugappan, M., Nagarajan, R., Wan, K., Physiological signals based human emotion recognition: A review (2011) IEEE 7th Int. Colloquium on Signal Processing and its Applications, pp. 410-415; Ko, B. C., A brief review of facial emotion recognition based on visual information (2018) Sensors, 18 (2), p. 401; Revina, I. M., Emmanuel, S., A survey on human face expression recognition techniques (2018) Journal of King Saud University-Computer and Information Sciences, pp. 1-33. , andW; Filippini, C., Perpetuini, D., Cardone, D., Chiarelli, A. M., Merla, A., Thermal infrared imaging-based affective computing and its application to facilitate human robot interaction: A review (2020) Applied Sciences, 10 (8), p. 2924; Yang, B., Li, X., Hou, Y., Meier, A., Cheng, X., Non-invasive (non-contact) measurements of human thermal physiology signals and thermal comfort/discomfort poses-a review (2020) Energy and Buildings, 224 (1), p. 110261; Kumar, C. N., Shivakumar, G., A survey on human emotion analysis using thermal imaging and physiological variables (2017) Int. Journal of Current Engineering and Scientific Research (IJCESR), 4 (4), pp. 122-126; Ponsi, G., Panasiti, M. S., Rizza, G., Aglioti, S. M., Thermal facial reactivity patterns predict social categorization bias triggered by unconscious and conscious emotional stimuli (2017) Proc. of the Royal Society B: Biological Sciences, 284 (1861), p. 20170908; Ioannou, S., Gallese, V., Merla, A., Thermal infrared imaging in psychophysiology: Potentialities and limits (2014) Psychophysiology, 51 (10), pp. 951-963; van Gastel, M., Stuijk, S., de Haan, G., Robust respiration detection from remote photoplethysmography (2016) Biomedical Optics Express, 7 (12), pp. 4941-4957; Cho, Y., Automated mental stress recognition through mobile thermal imaging (2017) Seventh Int. Conf. on Affective Computing and Intelligent Interaction (ACII), pp. 596-600. , San Antonio, TX, USA; He, X., Goubran, R., Knoefel, F., IR night vision video-based estimation of heart and respiration rates (2017) IEEE Sensors Applications Symposium (SAS), pp. 1-5; Merla, A., Di Donato, L., Rossini, P., Romani, G., Emotion detection through functional infrared imaging: preliminary results (2004) Biomedizinische Technick, 48 (2), pp. 284-286; Alkali, A. H., Saatchi, R., Elphick, H., Burke, D., Thermal image processing for real-time non-contact respiration rate monitoring (2017) IET Circuits, Devices & Systems, 11 (2), pp. 142-148; Nakayama, Y., Sun, G., Abe, S., Matsui, T., Non-contact measurement of respiratory and heart rates using a CMOS camera-equipped infrared camera for prompt infection screening at airport quarantine stations (2015) IEEE Int. Conf. on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA), pp. 1-4. , Shenzhen, China; Park, S. B., Kim, G., Baek, H. J., Han, J. H., Kim, J. H., Remote pulse rate measurement from near-infrared videos (2018) IEEE Signal Processing Letters, 25 (8), pp. 1271-1275; Yang, M., Liu, Q., Turner, T., Wu, Y., Vital sign estimation from passive thermal video (2008) IEEE Conf. on Computer Vision and Pattern Recognition, pp. 1-8. , Anchorage, AK, USA; Fei, J., Pavlidis, I., Thermistor at a distance: Unobtrusive measurement of breathing (2009) IEEE Transactions on Biomedical Engineering, 57 (4), pp. 988-998; Murthy, J. N., van Jaarsveld, J., Fei, J., Pavlidis, I., Harrykissoon, R. I., Thermal infrared imaging: A novel method to monitor airflow during polysomnography (2009) Sleep, 32 (11), pp. 1521-1527; Basu, A., Routray, A., Shit, S., Deb, A. K., Human emotion recognition from facial thermal image based on fused statistical feature and multi-class SVM (2015) Annual IEEE India Conf. (INDICON), pp. 1-5. , New Delhi, India; Mohd, M. N. H., Kashima, M., Sato, K., Watanabe, M., Mental stress recognition based on non-invasive and non-contact measurement from stereo thermal and visible sensors (2015) Int. Journal of Affective Engineering, 14 (1), pp. 9-17; Nguyen, T., Tran, K., Nguyen, H., Towards thermal region of interest for human emotion estimation (2018) 10th Int. Conf. on Knowledge and Systems Engineering (KSE), pp. 152-157. , Ho Chi Minh City. Vietnam; Wang, S., Pan, B., Chen, H., Ji, Q., Thermal augmented expression recognition (2018) IEEE Transactions on Cybernetics, 48 (7), pp. 2203-2214; Yan, X., Andrews, T. J., Jenkins, R., Young, A.W., Cross-cultural differences and similarities underlying otherrace effects for facial identity and expression (2018) Quarterly Journal of Experimental Psychology, 69 (7), pp. 1247-1254; Wang, S., Liu, Z., Wang, Z., Wu, G., Shen, P., Analyses of a multimodal spontaneous facial expression database (2013) IEEE Transactions on Affective Computing, 4 (1), pp. 34-46; Bhowmik, M. K., Saha, P., Singha, A., Bhattacharjee, D., Dutta, P., Enhancement of robustness of face recognition system through reduced Gaussianity in Log-ICA (2019) Expert Systems with Applications, 116 (1), pp. 96-107; Zhang, X., Yin, L., Cohn, J. F., Canavan, S., Reale, M., Bp4d-spontaneous: A high-resolution spontaneous 3d dynamic facial expression database (2014) Image and Vision Computing, 32 (10), pp. 692-706; Chu, C.-H., Peng, S.-M., Implementation of face recognition for screen unlocking on mobile device (2015) Proc. of the 23rd ACM Int. Conf. on Multimedia, pp. 1027-1030. , Brisbane, Australia; Jian, B.-L., Chen, C. L., Huang, M. W., Yau, H. T., Emotion-specific facial activation maps based on infrared thermal image sequences (2019) IEEE Access, 7, pp. 48046-48052; Elanthendral, V., Rekha, R., Rameshkumar, M., Thermal imaging for facial expression-fatigue detection (2014) International Journal for Research in Applied Science & Engineering Technology (IJRASET), 2 (XII), pp. 14-17; Nguyen, H., Chen, F., Kotani, K., Le, B., Fusion of visible images and thermal image sequences for automated facial emotion estimation (2014) Journal of Mobile Multimedia, 10 (3-4), pp. 294-308; Kopaczka, M., Kolk, R., Merhof, D., A fully annotated thermal face database and its application for thermal facial expression recognition (2018) IEEE Int. Instrumentation and Measurement Technology Conf. (I2MTC), pp. 1-6. , Houston, TX, USA; Merhof, D., Acar, K., Kopaczka, M., Robust facial landmark detection and face tracking in thermal infrared images using active appearance models (2016) Int. Conf. on Computer Vision Theory and Applications, pp. 150-158. , Rome, Italy; Mostafa, E., Farag, A., Shalaby, A., Ali, A., Gault, T., Long term facial parts tracking in thermal imaging for uncooperative emotion recognition (2013) IEEE Sixth Int. Conf. on Biometrics: Theory, Applications and Systems (BTAS), pp. 1-6. , Arlington, VA, USA; Wang, S., He, S., Wu, Y., He, M., Ji, Q., Fusion of visible and thermal images for facial expression recognition (2014) Frontiers of Computer Science, 8 (2), pp. 232-242; Shi, X., Wang, S., Zhu, Y., Expression recognition from visible images with the help of thermal images (2015) Proc. of the 5th ACM on Int. Conf. on Multimedia Retrieval, pp. 563-566. , Shanghai, China; Siddiqui, M. F. H., Javaid, A. Y., A multimodal facial emotion recognition framework through the fusion of speech with visible and infrared images (2020) Multimodal Technologies and Interaction, 4 (3), p. 46; Wang, S., He, S., Spontaneous facial expression recognition by fusing thermal infrared and visible images (2013) Intelligent Autonomous Systems 12. Advances in Intelligent Systems and Computing, 194, pp. 263-272. , Heidelberg, Berlin, Germany: Springer; Nayak, S., Panda, S. K., Uttarkabat, S., A non-contact framework based on thermal and visual imaging for classification of affective states during HCI (2020) 4th Int. Conf. on Trends in Electronics and Informatics (ICOEI)(48184), pp. 653-660. , Tirunelveli, India; Kolli, A., Fasih, A., Al Machot, F., Kyamakya, K., Non-intrusive car driver's emotion recognition using thermal camera (2011) International Workshop on Nonlinear Dynamics and Synchronization, INDS. Proc. of the Joint INDS'11 & ISTET'11, pp. 1-5. , Klagenfurt, Austria; Latif, M., Sidek, S., Rusli, N., Fatai, S., Emotion detection from thermal facial imprint based on GLCM features (2016) ARPN J. Eng. Appl. Sci, 11 (1), pp. 345-350; Kopaczka, M., Kolk, R., Merhof, D., A fully annotated thermal face database and its application for thermal facial expression recognition (2018) IEEE Int. Instrumentation and Measurement Technology Conf. (I2MTC), pp. 1-6. , Houston, TX, USA; Cross, C. B., Skipper, J. A., Petkie, D. T., Thermal imaging to detect physiological indicators of stress in humans (2013) Proc. SPIE Thermosense: Thermal Infrared Applications XXXV, 8705, p. 87050I. , 1-8705I-15; Carrapiço, R., Mourao, A., Magalhaes, J., Cavaco, S., A comparison of thermal image descriptors for face analysis (2015) 23rd European Signal Processing Conf. (EUSIPCO), pp. 829-833. , Nice, France; Pérez-Rosas, V., Narvaez, A., Burzo, M., Mihalcea, R., Thermal imaging for affect detection (2013) PETRA '13: The 6th Int. Conf. on Pervasive Technologies Related to Assistive Environments, pp. 1-4. , Rhodes, Greece; Liu, P., Yin, L., Spontaneous facial expression analysis based on temperature changes and head motions (2015) 11th IEEE Int. Conf. and Workshops on Automatic Face and Gesture Recognition (FG), pp. 1-6. , Ljubljana, Slovenia; Wang, S., He, M., Gao, Z., He, S., Ji, Q., Emotion recognition from thermal infrared images using deep Boltzmann machine (2014) Frontiers of Computer Science, 8 (4), pp. 609-618; Boccanfuso, L., Wang, Q., Leite, I., Li, B., Torres, C., A thermal emotion classifier for improved human-robot interaction (2016) 25th IEEE Int. Sym. on Robot and Human Interactive Communication (RO-MAN), pp. 718-723. , New York, NY, USA; Latif, M., Yusof, M. H., Sidek, S., Rusli, N., Texture descriptors based affective states recognition-frontal face thermal image (2016) IEEE EMBS Conf. on Biomedical Engineering and Sciences (IECBES), pp. 80-85. , Kuala Lumpur, Malaysia; Nguyen, H., Kotani, K., Chen, F., Le, B., Estimation of human emotions using thermal facial information (2014) Fifth Int. Conf. on Graphic and Image Processing (ICGIP2013) Proc, 9069. , Hong Kong, China, 90690O 1-90690O-5; Goulart, C., Valadão, C., Delisle-Rodriguez, D., Caldeira, E., Bastos, T., Emotion analysis in children through facial emissivity of infrared thermal imaging (2019) PloS One, 14 (3), p. e0212928; Khan, M. M., Ward, R. D., Ingleby, M., Classifying pretended and evoked facial expressions of positive and negative affective states using infrared measurement of skin temperature (2009) ACM Transactions on Applied Perception (TAP), 6 (1), pp. 1-22; Haamer, R. E., Rusadze, E., Lüsi, I., Ahmed, T., Escalera, S., Review on emotion recognition databases (2017) Human-Robot Interaction-Theory and Application, p. 39. , 1st edition, London, UK: IntechOpen; Wang, S., Liu, Z., Lv, S., Lv, Y., Wu, G., A natural visible and infrared facial expression database for expression recognition and emotion inference (2010) IEEE Transactions on Multimedia, 12 (7), pp. 682-691; Nguyen, H., Kotani, K., Chen, F., Le, B., A thermal facial emotion database and its analysis (2013) Pacific-Rim Sym. on Image and Video Technology, pp. 397-408. , Berlin, Heidelberg: Springer; Ordun, C., Raff, E., Purushotham, S., (2020) The use of AI for thermal emotion recognition: A review of problems and limitations in standard design and data, pp. 1-13. , https://arxiv.org/pdf/2009.10589.pdf, [Online]. Available; Zhu, X., Ramanan, D., Face detection, pose estimation, and landmark localization in the wild (2012) IEEE Conf. on Computer Vision and Pattern Recognition, pp. 2879-2886. , Providence, RI, USA; Trujillo, L., Olague, G., Hammoud, R., Hernandez, B., Automatic feature localization in thermal images for facial expression recognition (2005) IEEE Computer Society Conf. on Computer Vision and Pattern Recognition (CVPR'05)-Workshops, p. 14. , San Diego, CA, USA; Cruz-Albarran, I. A., Benitez-Rangel, J. P., Osornio-Rios, R. A., Morales-Hernandez, L. A., Human emotions detection based on a smart-thermal system of thermographic images (2017) Infrared Physics & Technology, 81 (1), pp. 250-261; Stemberger, J., Allison, R. S., Schnell, T., Thermal imaging as a way to classify cognitive workload (2010) Canadian Conf. on Computer and Robot Vision, pp. 231-238. , Ottawa, Canada; Jarlier, S., Grandjean, D., Delplanque, S., N'Diaye, K., Cayeux, I., Thermal analysis of facial muscles contractions (2011) IEEE Transactions on Affective Computing, 2 (1), pp. 2-9; Rivera, H., Goulart, C., Favarato, A., Valadão, C., Caldeira, E., Development of an automatic expression recognition system based on facial action coding system (2017) Simpósio Brasileiro de Automação Inteligente (SBAI2017), pp. 615-620. , Porto Alegre, Brazil; Ojala, T., Pietikainen, M., Maenpaa, T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (7), pp. 971-987; Mallat, K., Dugelay, J. L., A benchmark database of visible and thermal paired face images across multiple variations (2018) Int. Conf. of the Biometrics Special Interest Group (BIOSIG), pp. 1-5. , Darmstadt, Germany","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",,,Tech Science Press,,,,,2676192,,CSSEE,,English,Comput Syst Sci Eng,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85103239312
"Bello R.-W., Mohamed A.S.A., Talib A.Z.",57209469141;57190968285;35570816900;,Contour Extraction of Individual Cattle from an Image Using Enhanced Mask R-CNN Instance Segmentation Method,2021,IEEE Access,9,,9400819,56984,57000,,,10.1109/ACCESS.2021.3072636,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104249692&doi=10.1109%2fACCESS.2021.3072636&partnerID=40&md5=e8ed42fe4d10155350dda431983c7360,"School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Bello, R.-W., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Talib, A.Z., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","In animal husbandry, the traceability of individual cattle, their health information, and performance records greatly depend on computer vision and image processing-based approaches. However, some of these approaches perform below expectations in obtaining real-time information about individual cattle. No doubt, inaccurate segmentation and incomplete extraction of each cattle object from an image are notable contributory factors. As accurate segmentation is a prerequisite for obtaining real-time information about individual cattle, and since the algorithm of Mask R-CNN relies on the algorithm of simultaneous localization and mapping (SLAM), for the construction of the semantic map, which sometimes exchanges image background for the foreground, there is a need to enhance the available approaches towards achieving precision animal husbandry. To achieve this, an enhanced Mask R-CNN instance segmentation method is proposed to support indistinct boundaries and irregular shapes of cattle bodies. The methods employed in the research are in multiple folds: (1) Pre-enhancement of the image using generalized color Fourier descriptors (GCFD); (2) Provision of optimal filter size that was smaller than ResNet101 (the backbone of Mask R-CNN) for the extraction of smaller and composite features; (3) Utilization of multiscale semantic features using region proposals; (4) A fully connected layer of existing Mask R-CNN integrated with a sub-network for enhanced segmentation and (5) Post-enhancement of the image using Grabcut. Experiments on the datasets of cattle images produced better results when compared to other state-of-the-art methods with 0.93 mAP. © 2013 IEEE.",Animal husbandry; cattle; Grabcut; instance segmentation; Mask R-CNN,Agriculture; Animals; Convolutional neural networks; Extraction; Image segmentation; Semantics; Contour Extraction; Contributory factors; Fourier descriptors; Health informations; Real-time information; Segmentation methods; Simultaneous localization and mapping; State-of-the-art methods; Image enhancement,,,,,"1001 / PKOMP / 8014001

Universiti Sains Malaysia","This work was supported by the Division of Research and Innovation (RCMO), Research University under Grant 1001 / PKOMP / 8014001 and School of Computer Sciences, Universiti Sains Malaysia.","The authors received funding from the Division of Research and Innovation (RCMO), Research University Grant (1001 / PKOMP / 8014001) and School of Computer Sciences, Uni-versiti Sains Malaysia for this publication.","Van Hertem, T., Rooijakkers, L., Berckmans, D., Fernández, A.P., Norton, T., Berckmans, D., Vranken, E., Appropriate data visualisation is key to precision livestock farming acceptance (2017) Comput. Electron. Agricult., 138, pp. 1-10. , Jun; Kumar, S., Pandey, A., Satwik, K.S.R., Kumar, S., Singh, S.K., Singh, A.K., Mohan, A., Deep learning framework for recognition of cattle using muzzle point image pattern (2018) Measurement, 116, pp. 1-17. , Feb; Bello, R., Talib, A.Z., Mohamed, A.S.A., Deep learning-based architectures for recognition of cow using cow nose image pattern (2020) Gazi Univ. J. Sci., 33 (3), pp. 831-844; Norouzzadeh, M.S., Nguyen, A., Kosmala, M., Swanson, A., Palmer, M.S., Packer, C., Clune, J., Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning (2018) Proc. Nat. Acad. Sci. USA, 115 (25), pp. E5716-E5725. , Jun; Petersen, W.E., The identification of the bovine by means of nose-prints (1922) J. Dairy Sci., 5 (3), pp. 249-258. , May; Bos, J.M., Bovenkerk, B., Feindt, P.H., Van Dam, Y.K., The quantified animal: Precision livestock farming and the ethical implications of objectification (2018) Food Ethics, 2 (1), pp. 77-92. , Dec; Zin, T.T., Kobayashi, I., Tin, P., Hama, H., A general video surveillance framework for animal behavior analysis (2016) Proc. 3rd Int. Conf. Comput. Meas. Control Sensor Netw. (CMCSN), pp. 130-133. , May; Lynn, N.C., Zin, T.T., Kobayashi, I., Automatic assessing body condition score from digital images by active shape model and multiple regression technique (2017) Proc. Int. Conf. Artif. Life Robot., Miyazaki, pp. 311-314; Nasirahmadi, A., Edwards, S.A., Sturm, B., Implementation of machine vision for detecting behaviour of cattle and pigs (2017) Livestock Sci., 202, pp. 25-38. , Aug; Hansen, M.F., Smith, M.L., Smith, L.N., Jabbar, K.A., Forbes, D., Automated monitoring of dairy cow body condition, mobility and weight using a single 3D video capture device (2018) Comput. Ind., 98, pp. 14-22. , Jun; Tebug, S.F., Missohou, A., Sabi, S.S., Juga, J., Poole, E.J., Tapio, M., Marshall, K., Using body measurements to estimate live weight of dairy cattle in low-input systems in Senegal (2018) J. Appl. Animal Res., 46 (1), pp. 87-93. , Jan; Zhang, A.L., Wu, B.P., Wuyun, C.T., Jiang, D.X., Xuan, E.C., Ma, F.Y., Algorithm of sheep body dimension measurement and its applications based on image analysis (2018) Comput. Electron. Agricult., 153, pp. 33-45. , Oct; Tang, P., Wang, C., Wang, X., Liu, W., Zeng, W., Wang, J., Object detection in videos by high quality object linking (2020) Ieee Trans. Pattern Anal. Mach. Intell., 42 (5), pp. 1272-1278. , May; Bello, R.W., Talib, A.Z., Mohamed, A.S.A., Olubummo, D.A., Otobo, F.N., Image-based individual cow recognition using body patterns (2020) Int. J. Adv. Comput. Sci. Appl., 11 (3), pp. 92-98; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 91-99; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask R-CNN (2017) Proc. Ieee Int. Conf. Comput. Vis., pp. 2961-2969. , Oct; Neumann, L., Zisserman, A., Vedaldi, A., Relaxed softmax: Efficient confidence auto-calibration for safe pedestrian detection (2018) Proc. Nips Workshop Mach. Learn. Intell. Transp. Syst., pp. 1-8; Chen, L.-C., Hermans, A., Papandreou, G., Schroff, F., Wang, P., Adam, H., MaskLab: Instance segmentation by refining object detection with semantic and direction features (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 4013-4022. , Jun; Fathi, A., Wojna, Z., Rathod, V., Wang, P., Song, H.O., Guadarrama, S., Murphy, K.P., (2017) Semantic Instance Segmentation Via Deep Metric Learning, , http://arxiv.org/abs/1703.10277, arXiv:1703.10277. [Online]; Gardenier, J., Underwood, J., Clark, C., Object detection for cattle gait tracking (2018) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), pp. 2206-2213. , May; Song, X., Bokkers, E.A.M., Tol Der Van, P.P.J., Koerkamp, P.W.G.G., Van Mourik, S., Automated body weight prediction of dairy cows using 3-dimensional vision (2018) J. Dairy Sci., 101 (5), pp. 4448-4459. , May; Arnab, A., Torr, P.H.S., Pixelwise instance segmentation with a dynamically instantiated network (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 441-450. , Jul; Bell, S., Zitnick, C.L., Bala, K., Girshick, R., Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2874-2883. , Jun; Cao, Z., Simon, T., Wei, S.-E., Sheikh, Y., Realtime multi-person 2D pose estimation using part affinity fields (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 7291-7299. , Jul; Girshick, R., Iandola, F., Darrell, T., Malik, J., Deformable part models are convolutional neural networks (2015) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 437-446. , Jun; Hayder, Z., He, X., Salzmann, M., (2016) Shape-aware Instance Segmentation, , https://arxiv.org/abs/1612.03129, arXiv:1612.03129. [Online]; Kirillov, A., Levinkov, E., Andres, B., Savchynskyy, B., Rother, C., InstanceCut: From edges to instances with MultiCut (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 5008-5017. , Jul; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs (2018) Ieee Trans. Pattern Anal. Mach. Intell., 40 (4), pp. 834-848. , Apr; Li, K., Hariharan, B., Malik, J., Iterative instance segmentation (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3659-3667. , Jun; Zhao, K., Kang, J., Jung, J., Sohn, G., Building extraction from satellite images using mask R-CNN with building boundary regularization (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 247-251. , Jun; Bai, M., Urtasun, R., Deep watershed transform for instance segmentation (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 5221-5229. , Jul; Ter-Sarkisov, A., Ross, R., Kelleher, J., Earley, B., Keane, M., (2018) Beef Cattle Instance Segmentation Using Fully Convolutional Neural Network, , http://arxiv.org/abs/1807.01972, arXiv:1807.01972. [Online]; Pinheiro, P.O., Collobert, R., Dollár, P., Learning to segment object candidates (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 1990-1998; Pinheiro, P.O., Lin, T.Y., Collobert, R., Dollár, P., Learning to refine object segments (2016) Proc. Eur. Conf. Comput. Vis., pp. 75-91; Fuentes, A., Yoon, S., Park, J., Park, D.S., Deep learning-based hierarchical cattle behavior recognition with spatio-temporal information (2020) Comput. Electron. Agricult., 177, pp. 1-11. , Oct; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3431-3440. , Jun; Girshick, R., Donahue, J., Darrell, T., Malik, J., Region-based convolutional networks for accurate object detection and segmentation (2016) Ieee Trans. Pattern Anal. Mach. Intell., 38 (1), pp. 142-158. , Jan; Li, Y., Qi, H., Dai, J., Ji, X., Wei, Y., Fully convolutional instanceaware semantic segmentation (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2359-2367. , Jul; Xu, B., Wang, W., Falzon, G., Kwan, P., Guo, L., Chen, G., Tait, A., Schneider, D., Automated cattle counting using mask R-CNN in quadcopter vision system (2020) Comput. Electron. Agricult., 171, pp. 1-12. , Apr; Hariharan, B., Arbeláez, P., Girshick, R., Malik, J., Simultaneous detection and segmentation (2014) Proc. Eur. Conf. Comput. Vis., pp. 297-312; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Mennesson, J., Saint-Jean, C., Mascarilla, L., Color object recognition based on a Clifford Fourier transform (2011) Guide to Geometric Algebra in Practice., pp. 175-191. , London, U.K.: Springer; Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2117-2125. , Jul; Wu, X., Wen, S., Xie, Y.A., Improvement of mask-RCNN object segmentation algorithm (2019) Proc. Int. Conf. Intell. Robot. Appl., pp. 582-591; Russell, B.C., Torralba, A., Murphy, K.P., Freeman, W.T., LabelMe: A database andWeb-based tool for image annotation (2008) Int. J. Comput. Vis., 77 (1-3), pp. 157-173. , May; Alshdaifat, N.F.F., Talib, A.Z., Osman, M.A., Improved deep learning framework for fish segmentation in underwater videos (2020) Ecol. Informat., 59, pp. 1-11. , Sep; Qiao, Y., Truman, M., Sukkarieh, S., Cattle segmentation and contour extraction based on Mask R-CNN for precision livestock farming (2019) Comput. Electron. Agricult., 165, pp. 1-9; Kristan, M., Matas, J., Leonardis, A., Vojíř, T., Pflugfelder, R., Fernandez, G., Nebehay, G., Čehovin, L., A novel performance evaluation methodology for single-target trackers (2016) Ieee Trans. Pattern Anal. Mach. Intell., 38 (11), pp. 2137-2155. , Nov; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proc. Ieee Conf. Comput. Vis. Pattern Recognit., pp. 248-255. , Jun; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L., Microsoft COCO: Common objects in context (2014) Proc. Eur. Conf. Comput. Vis., pp. 740-755. , Cham, Switzerland: Springer; Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The Pascal visual object classes (VOC) challenge (2010) Int. J. Comput. Vis., 88 (2), pp. 303-338. , Jun; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 6517-6525. , Jul; Zhang, H., Tian, Y., Wang, K., Zhang, W., Wang, F.-Y., Mask SSD: An effective single-stage approach to object instance segmentation (2020) Ieee Trans. Image Process., 29, pp. 2078-2093; Dai, J., He, K., Sun, J., Instance-aware semantic segmentation via multi-task network cascades (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3150-3158. , Jun; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , http://arxiv.org/abs/1409.1556, arXiv:1409. 1556. [Online]","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85104249692
"Bello R.-W., Talib A.Z.H., Mohamed A.S.A.B.",57209469141;35570816900;57190968285;,Deep belief network approach for recognition of cow using cow nose image pattern,2021,Walailak Journal of Science and Technology,18,5,8984,1,14,,,10.48048/wjst.2021.8984,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102515523&doi=10.48048%2fwjst.2021.8984&partnerID=40&md5=d71a97f803cc60b24bf406f16b3553b1,"School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Bello, R.-W., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Talib, A.Z.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Mohamed, A.S.A.B., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","A deep belief network is proposed to learn the discriminatory cow nose image texture features for a robust representation of cows' features and recognition using a cow nose image pattern. Deep belief network is a deep learning model that is graphically based, and it is applied to learn the extracted feature sets of cow nose image pattern for hierarchical representation by using the training details of the training phase of the system proposed. Deep belief network application is useful in animal biometrics to monitor the animals through its recognition and identification techniques. Biometrics application emanated from computer vision and pattern recognition. Its application plays an important role in registering and monitoring animals through its recognition and identification techniques. Because the existing physical-based feature representation methods and manual visual feature extractions cannot handle animal recognition, the deep belief network technique is proposed using the animal's visual attributes. An experiment performed under a controlled condition of identification indicated that the proposed method outshines the existing methods with approximately 98.99 % accuracy. Four thousand cow nose images from an existing database of 400 individual cows contribute to the community of research, especially in the animal biometrics for identification of individual cow. © 2021, Walailak University. All rights reserved.",Animal biometrics; Convolutional neural network; Cow nose image; Deep belief network; Identification,,,,,,,,,"Vlad, M, Parvulet, RA, Vlad, MS, A survey of livestock identification systems (2012) Proceedings of the 13th WSEAS International Conference on Automation and Information, pp. 165-170; Roberts, CM, Radio frequency identification (RFID) (2006) Comput. Secur, 25, pp. 18-26; Wang, Z, Fu, Z, Chen, W, Hu, J, A RFID-based traceability system for cattle breeding in china (2010) Proceedings of the 2010 IEEE International Conference on Computer Application and System Modeling, pp. V2-567. , Taiyuan, China; Krizhevsky, A, Sutskever, I, Hinton, G, Imagenet classification with deep convolutional neural networks (2012) Proceedings of the Advances in Neural Information Processing Systems, pp. 1097-1105. , Curran and Associates, Red Hook, NY, USA; Farabet, C, Couprie, C, Najman, L, LeCun, Y, Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mac. Intell, 35, pp. 1915-1929; Sun, Y, Wang, X, Tang, X, Deep convolutional network cascade for facial point detection (2013) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, 2013, pp. 3476-3483; Kumar, S, Singh, SK, Visual animal biometrics: Survey (2016) IET Biometrics, 6, pp. 139-156; Kumar, S, Singh, SK, Datta, T, Gupta, HP, A fast cattle recognition system using smart devices (2016) Proceedings of the 2016 ACM conference on Multimedia, pp. 742-743. , Amsterdam, Netherlands; Barron, UG, Butler, F, McDonnell, K, Ward, S, The end of the identity crisis? Advances in biometric markers for animal identification (2009) Irish Veterinary J, 62, pp. 204-208; Jain, AK, Ross, AA, Nandakumar, K, (2011) Introduction to biometrics, , Springer Science and Business Media; Giot, R, El-Abed, M, Rosenberger, C, Fast computation of the performance evaluation of biometric systems: Application to multibiometrics (2013) Future Generat. Comput. Syst, 29, pp. 788-799; Jain, AK, Ross, A, Prabhakar, S, An introduction to biometric recognition (2004) IEEE Trans. Circ. Syst. Video Tech, 14, pp. 4-20; Petersen, WE, The identification of the bovine by means of nose-prints (1922) J. Dairy Sci, 5, pp. 249-258; Kohl, HS, Burkhart, T, Animal biometrics: Quantifying and detecting phenotypic appearance (2013) Trends Ecol. Evol, 28, pp. 432-441; Reiter, S, Sattlecker, G, Lidauer, L, Kickinger, F, Öhlschuster, M, Auer, W, Schweinzer, V, Iwersen, M, Evaluation of an ear-tag-based accelerometer for monitoring rumination in dairy cows (2018) J. Dairy Sci, 101, pp. 3398-3411; Seijas, C, Montilla, G, Frassato, L, Identification of Rodent Species Using Deep Learning (2019) Computación y Sistemas, 23, p. 257; Hansen, MF, Smith, ML, Smith, LN, Salter, MG, Baxter, EM, Farish, M, Grieve, B, Towards on-farm pig face recognition using convolutional neural networks (2018) Comput. Ind, 98, pp. 145-152; Kumar, S, Singh, SK, Cattle recognition: A new frontier in visual animal biometrics research (2019) Proceedings of the National Academy of Sciences, pp. 1-20. , India; Norouzzadeh, MS, Nguyen, A, Kosmala, M, Swanson, A, Palmer, MS, Packer, C, Clune, J, Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning (2018) Proc. Natl. Acad. Sci Unit States Am, 115, pp. E5716-E5725; Zin, TT, Phyo, CN, Tin, P, Hama, H, Kobayashi, I, Image technology based cow identification system using deep learning (2018) Proceedings of the International Multi Conference of Engineers and Computer Scientists; Kumar, S, Pandey, A, Satwik, KSR, Kumar, S, Singh, SK, Singh, AK, Mohan, A, Deep learning framework for recognition of cattle using muzzle point image pattern (2018) Measurement, 116, pp. 1-17; Iswanto, IA, Li, B, Visual object tracking based on mean-shift and particle-Kalman filter (2017) Proc. Comput. Sci, 116, pp. 587-595; Noviyanto, A, Arymurthy, AM, Automatic cattle identification based on muzzle photo using speed-up robust features approach (2012) Proceedings of the 3rd European Conference of Computer Science, p. 114; Nasirahmadi, A, Richter, U, Hensel, O, Edwards, S, Sturm, B, Using machine vision for investigation of changes in pig group lying patterns (2015) Comput. Electron. Agr, 119, pp. 184-190; Minagawa, H, Fujimura, T, Ichiyanagi, M, Tanaka, K, Fangquan, M, Identification of beef cattle by analyzing images of their muzzle patterns lifted on paper (2002) Proceedings of the 3rd Asian Conference for Information Technology in Asian Agricultural Information Technology and Management, pp. 596-600; Barry, B, Gonzales-Barron, U, McDonnell, K, Butler, F, Ward, S, Using muzzle pattern recognition as a biometric approach for cattle identification (2007) Trans. ASABE, 50, pp. 1073-1080; Dalal, N, Triggs, B, Histograms of oriented gradients for human detection (2005) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 886-893; Awad, AI, Zawbaa, HM, Mahmoud, HA, Nabi, EHHA, Fayed, RH, Hassanien, AE, A robust cattle identification scheme using muzzle print images (2013) Proceedings of IEEE Federated Conference on Computer Science and Information Systems, pp. 529-534; Noviyanto, A, Arymurthy, AM, Beef cattle identification based on muzzle pattern using a matching refinement technique in the sift method (2013) Comp. Electr. Agr, 99, pp. 77-84; Ehsani, K, Bagherinezhad, H, Redmon, J, Mottaghi, R, Farhadi, A, Who let the dogs out? Modeling dog behavior from visual data (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4051-4060; Kumar, S, Tiwari, S, Singh, SK, Face recognition for cattle (2015) Proceedings of 3rd IEEE International Conference on Image Information Processing, pp. 65-72; Gaber, T, Tharwat, A, Hassanien, AE, Snasel, V, Biometric cattle identification approach based on webers local descriptor and AdaBoost classifier (2016) Comp. Electr. Agr, 122, pp. 55-66; Risha, KP, Chempak, KA, Sindhu, CS, Difference of gaussian on frame differenced image (2016) Int. J. Innovat. Res. Electr. Electron. Instrum. Contr. Eng, 3, pp. 92-95; Vincent, P, Larochelle, H, Lajoie, I, Bengio, Y, Manzagol, PA, Stacked denoising auto-encoders: Learning useful representations in a deep network with a local denoising criterion (2010) J. Mach. Learn. Res, 11, pp. 3371-3408; Vincent, P, Larochelle, H, Bengio, Y, Manzagol, PA, Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 1096-1103; Bengio, Y, Learning deep architectures for AI (2009) Found. Trends Mach. Learn, 2, pp. 1-127; Bengio, Y, Courville, A, Vincent, P, Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Mach. Intell, 35, pp. 1798-1828","Bello, R.-W.; School of Computer Sciences, Malaysia; email: sirbrw@yahoo.com",,,Walailak University,,,,,16863933,,,,English,Walailak J. Sci. Technol.,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85102515523
"Younis H.A., Mohamed A.S.A., Jamaludin R., Ab Wahab M.N.",57210408507;57190968285;54401335900;36471236100;,"Survey of robotics in education, taxonomy, applications, and platforms during COVID-19",2021,"Computers, Materials and Continua",67,1,,687,707,,,10.32604/cmc.2021.013746,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099334783&doi=10.32604%2fcmc.2021.013746&partnerID=40&md5=43113133f6b79fd33e1266ad8985eca1,"College of Education for Women University of Basrah, Basrah, Iraq; School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; Centre For Instructional Technology & Multimedia, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia","Younis, H.A., College of Education for Women University of Basrah, Basrah, Iraq, School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; Jamaludin, R., Centre For Instructional Technology & Multimedia, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; Ab Wahab, M.N., School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia","The coronavirus disease 2019 (COVID-19) is characterized as a disease caused by a novel coronavirus known as severe acute respiratory coronavirus syndrome 2 (SARS-CoV-2; formerly known as 2019-nCoV). In December 2019, COVID-19 began to appear in a few countries. By the beginning of 2020, it had spread to most countries across the world. This is when education challenges began to arise. The COVID-19 crisis led to the closure of thousands of schools and universities all over the world. Such a situation requires reliance on e-learning and robotics education for students to continue their studies to avoid the mingling between people and students. In relation to this alternative learning solution, the present study was conducted. A systematic literature review on educational robotics (ER) keywords between 2015–2020 was carried out for the purpose to review a total of 2253 articles from the selected sources; Scopus (452), Taylor & Francis (311), Science Direct (427), IEEE Xplore (221), and Web of Science (842). This review procedure was labelled as Taxonomy 1. After filtering Taxonomy 1, it was found that 98 scientific articles formed the so-called Taxonomy II that was categorized into six categories: (i) Robotics concepts, (ii) Device, (iii) Robotic applications, (iv) Manufacturing robots, (v) Robotics analysis, and (vi) Education/taxonomy. For this study, only 35 articles in this specific field were selected, of which were then assigned into three categories: (i) Application, (ii) Platform, and (iii) Educational. The results show that the application category carries 17.4%, platform 20%, and education 22.85%. This study serves as the application platform to help students, academics, and researchers. © 2021 Tech Science Press. All rights reserved.",Application platform; COVID-19; Educational; Educational robotics; Taxonomy,Diseases; Robotics; Students; Tantalum compounds; Taxonomies; Application platforms; Educational robotics; Robotic applications; Robotics education; Scientific articles; Systematic literature review; Three categories; Web of Science; Educational robots,,,,,,"Funding Statement: The authors received funding from Division of Research and Innovation, Universiti Sains Malaysia for this study.",,"Ahmed, H., La, H. M., Education-robotics symbiosis: An evaluation of challenges and proposed recommendations (2019) 9th IEEE Integrated STEM Education Conf., USA, pp. 222-229; Miller, D. P., Nourbakhsh, I., Robotics for education (2016) Springer Handbook of Robotics, pp. 2115-2134. , Springer; Santos, C. B., Ferreira, D. J., De Souza, M. C. B. D. N. R., Martins, A. R., Robotics and programming: Attracting girls to technology (2016) Int. Conf. on Advances in Computing, Communications and Informatics, ICACCI, Jaipur, India, pp. 2052-2056; Younis, Hussain A., Jamaludin, R., Wahab, M. N. A., Mohamed, A. S. A., The review of NAO robotics in educational 2014–2020 in COVID-19 virus (pandemic era): Technologies, type of application, advantage, disadvantage and motivation (2020) Journal of Physics: IOP; Sharkey, A. J. C., Should we welcome robot teachers? (2016) Ethics and Information Technology, 18 (4), pp. 283-297; Mohan, R., Robotics: Its components, sensing, laws and applications (2019) International Journal of Engineering in Computer Science, 1 (1), pp. 16-20. , 16; Peternel, L., Tsagarakis, N., Caldwell, D., Ajoudani, A., Robot adaptation to human physical fatigue in human-robot co-manipulation (2018) Autonomous Robots, 42 (5), pp. 1011-1021; Chatzilygeroudis, K., Vassiliades, V., Stulp, F., Calinon, S., Mouret, J. B., A survey on policy search algorithms for learning robot controllers in a handful of trials (2020) IEEETransactionsonRobotics, 36 (2), pp. 328-347; Abdulkareem, K. H., Mohammed, M. A., Gunasekaran, S. S., Al-Mhiqani, M. N., Mutlag, A. A., A review of fog computing and machine learning: Concepts, applications, challenges, and open issues (2019) IEEE Access, 7, pp. 153123-153140; Atmatzidou, S., Demetriadis, S., Advancing students’ computational thinking skills through educational robotics: A study on age and gender relevant differences (2016) Robotics and Autonomous Systems, 75, pp. 661-670; Istikomah, I., Budiyanto, C., The contribution of educational robotics and constructivist approach to computational thinking in the 21st century (2019) 1st Int. Conf. on Computer Science and Engineering, Indonesia, pp. 610-616; Schöpping, T., Korthals, T., Hesse, M., AMiRo: A mini robot as versatile teaching platform (2019) Journal of Intelligent & Robotic Systems, 81 (1); Feng, T., Zou, L., Yan, J., Shi, W., Liu, Y., Brazilian robotics olympiad: A successful paradigm for science and technology dissemination (2016) International Journal of Advanced Robotic Systems, 13 (5), pp. 1-8; Krajcsi, A., Csapodi, C., Stettner, E., Algotaurus: An educational computer programming game for beginners (2019) Interactive Learning Environments, 6 (2), pp. 1-14; Vega, J., Cañas, J. M., Open vision system for low-cost robotics education (2019) Electronics, 8 (11), pp. 1-20; Luciano, S. C., Kost, A. R., Robotic laboratory for distance education (2016) Optics Education and Outreach, 9946, p. 99460O; Bachiller-Burgos, P., Barbecho, I., Calderita, L. V., Bustos, P., Manso, L. J., Learn block: A robot-agnostic educational programming tool (2020) IEEE Access, 8, pp. 30012-30026; Dayoub, F., Morris, T., Corke, P., Rubbing shoulders with mobile service robots (2015) IEEE Access, 3, pp. 333-342; Tan, N., Hayat, A. A., Elara, M. R., Wood, K. L., A framework for taxonomy and evaluation of self-reconfigurable robotic systems (2020) IEEE Access, 8, pp. 13969-13986; Čehovin Zajc, L., Rezelj, A., Skočaj, D., Teaching with open-source robotic manipulator (2019) Advances in Intelligent Systems and Computing, 829, pp. 189-198; Ferreira, N. M. F., Moita, F., Santos, V. D. N., Ferreira, J., Santos, J., Education with robots inspired in biological systems (2019) Advances in Intelligent Systems and Computing, 829, pp. 207-213; Pinto, J. G. V. H., Monteiro, J. M., Costa, P., (2018) Prototyping and Programming a Multipurpose Educational Mobile Robot—NaSSIE, pp. 199-206. , Springer Nature Switzerland AG: Springer; Lopez-Caudana, E., Ponce, P., Cervera, L., Iza, S., Mazon, N., Robotic platform for teaching maths in junior high school (2018) International Journal on Interactive Design and Manufacturing, 12 (4), pp. 1349-1360; Hameed, I. A., Strazdins, G., Hatlemark, H. A. M., Jacobsen, I. S., Damdam, J. O., Robots that can mix serious with fun (2018) Int. Conf. on Advanced Machine Learning Technologies and Applications, pp. 595-604; Schiffer, S., Ferrein, A., Erika—early robotics introduction at kindergarten age (2018) Multimodal Technologies and Interaction, 2 (4), pp. 1-20; Chiazzese, G., Arrigo, M., Chifari, A., Lonati, V., Tosto, C., Educational robotics in primary school: Measuring the development of computational thinking skills with the bebras tasks (2019) InformaticsJournal, 6 (4), pp. 1-12; Negrini, L., Teacher training in educational robotics an experience in southern switzerland: The PReSO project (2019) Robotics in Educationc, pp. 92-97. , https://www.springer.com/gp/book/9783319970844, [Online]. Available; Keller, L., John, I., Motivating female students for computer science by means of robot workshops (2020) International Journal of Engineering Pedagogy, 10 (1), pp. 94-108; Mondada, F., Bonnet, E., Davrajh, S., Johal, W., Stopforth, R., R2T2: Robotics to integrate educational efforts in south africa and europe (2016) International Journal of Advanced Robotic Systems, 13 (5), pp. 1-13; Alex Polishuk, I. V., Student-robot interactions in museum workshops: Learning activities and outcomes (2017) Robotics in Education, pp. 233-244. , https://www.springer.com/gp/book/9783319429748, [Online]. Available; Marios Xenos, C. K., Yiannoutsou, N., Grizioti, M., Nikitopoulou, S., Learning programming with educational robotics: Towards an integrated approach (2017) International Conference EduRobotics, 560, pp. 215-222; Kandlhofer, M., Steinbauer, G., Evaluating the impact of educational robotics on pupils’ technical- and social-skills and science related attitudes (2016) Robotics and Autonomous Systems, 75, pp. 679-685; Georg Jäggle, A. W., Vincze, Markus, Gottfried Koppensteiner, W. L., Merdan, M., (2019) Ibridge—Participative Cross-Generational Approach with Educational Robotics, pp. 263-274. , Springer, AISC 829; Kantosalo, A., Riihiaho, S., Experience evaluations for human-computer co-creative processes–planning and conducting an evaluation in practice (2019) Connection Science, Taylor & Francis Group, 31 (1), pp. 60-81; Bargagna, S., Castro, E., Cecchi, F., Cioni, G., Dario, P., Educational robotics in down syndrome: A feasibility study (2019) Technology Knowledge and Learning, 24 (2), pp. 315-323; Conchinha, C., Osório, P., De Freitas, J. C., Playful learning: Educational robotics applied to students with learning disabilities (2016) Int. Sym. on Computers in Education, SIIE 2015, pp. 167-171. , IEEE, Setubal, Portugal; Urlings, C. C., Coppens, K. M., Borghans, L., Measurement of executive functioning using a playful robot in kindergarten (2019) Computers in the Schools, 36 (4), pp. 255-273; Alhaddad, B. B. A. Y., Javed, H., Connor, O., Dena Al Thani, J. J. C., (2019) RoboticTrainsasanEducational andTherapeuticToolforAutismSpectrumDisorderIntervention, pp. 249-262. , Switzerland: Springer Nature Switzerland AG; Amin, M. Z., Zamin, N., Rahim, H. A., Hassan, N. I., Kamarudin, N. D., Robo therapist: A sustainable approach to teach basic expressions for special needs children in malaysia (2018) International Journal of Engineering and Technology(UAE), 7 (3), pp. 103-106; Francis, K., Bruce, C., Davis, B., Drefs, M., Hallowell, D., Multidisciplinary perspectives on a video case of children designing and coding for robotics (2017) Mathematics and Technology Education, 17 (3), pp. 165-178. , etal; Macgilchrist, F., Allert, H., Bruch, A., Students and society in the 2020s. Three future ‘histories’ of education and technology (2020) Learning Media and Technology, 45 (1), pp. 76-89; Patil, S., Mane, V., Patil, P., Social innovation in education system by using robotic process automation (Rpa) (2019) International Journal of Innovative Technology and Exploring Engineering, 8 (11), pp. 3757-3760; Mohammed, M. A., Abdulkareem, K. H., Al-Waisy, A. S., Mostafa, S. A., Al-Fahdawi, S., Benchmarking methodology for selection of optimal COVID-19 diagnostic model based on entropy and TOPSIS methods (2020) IEEE Access, 8, pp. 99115-99131","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",,,Tech Science Press,,,,,15462218,,,,English,Comput. Mater. Continua,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85099334783
"Bello R.W., Olubummo D.A., Seiyaboh Z., Enuma O.C., Talib A.Z., Mohamed A.S.A.",57209469141;57216345013;57218909817;57221132880;35570816900;57190968285;,Cattle identification: The history of nose prints approach in brief,2020,IOP Conference Series: Earth and Environmental Science,594,1,12026,,,,,10.1088/1755-1315/594/1/012026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098322994&doi=10.1088%2f1755-1315%2f594%2f1%2f012026&partnerID=40&md5=0d3041d52593cec60c8070445fce1db5,"School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Department of Mathematical Sciences, University of Africa, Toru-Orua, Bayelsa, Nigeria; Department of Computer and Information Systems, Robert Morris University, Moon-Township, PA, United States; Institute of Research in Applicable Computing (IRAC), University of BedfordshireLU1 3JU, United Kingdom; Department of Planning, Research and Statistics, Ministry of Health, Bayelsa, Nigeria","Bello, R.W., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia, Department of Mathematical Sciences, University of Africa, Toru-Orua, Bayelsa, Nigeria; Olubummo, D.A., Department of Computer and Information Systems, Robert Morris University, Moon-Township, PA, United States; Seiyaboh, Z., Institute of Research in Applicable Computing (IRAC), University of BedfordshireLU1 3JU, United Kingdom; Enuma, O.C., Department of Planning, Research and Statistics, Ministry of Health, Bayelsa, Nigeria; Talib, A.Z., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia","Petersen was the first published paper to address cattle biometrics and identification problem by suggesting a permanent cattle identification method based on nose print principles widely accepted today. His major concern was on proper identification of cattle for registration and of cattle on an official test so that the possibility of swapping, false insurance claims, and ownership disputes can be guarded against. It was with this identification problem in the mind of every breeder that the practicable suggestion of using nose print as means of identification was made by O. H. Baker of the American Jersey Cattle Club in Petersen's paper entitled ""The identification of the bovine by means of nose-prints"". Before the advent of the nose print method, cattle identification has been by conventional constructs such as tattoo, tags, photographs, descriptions, branding (hot and freeze), ear notching, and sketching (drawings) the color markings on them on paper for registration and identification purposes. These classical methods of identification cause trouble among the breeders especially when their cattle are sold or are on an official test due to lack of artistic ability on the part of the breeders which makes the matching of the sketches and the markings on the cattle disagree. Presented in this paper are the various cattle biometrics and identification methods, most especially from the classical methods to the modern methods. © Published under licence by IOP Publishing Ltd.",,Biometrics; Insurance; Mammals; Classical methods; Color markings; Identification method; Identification problem; Insurance claims; Petersen; Agriculture,,,,,,,,"Petersen, W E, The identification of the bovine by means of nose-prints (1922) J. Dairy Sci, 5, pp. 249-258; Neary, M, Yager, A, (2002) Methods of livestock identification, , (Purdue University Department of Animal Sciences) 1-9 AS-556-W; Blancou, J, A history of the traceability of animals and animal products (2001) Revue Scientifique et Technique-Office International des Epizooties, 20, pp. 420-425; Ghirardi, J J, Caja, G, Garín, D, Casellas, J, Hernández-Jover, M, Evaluation of the retention of electronic identification boluses in the forestomachs of cattle (2006) J. Anim. Sci, 84, pp. 2260-2268; Bello, R W, Abubakar, S, Development of a software package for cattle identification in Nigeria (2019) J. Appl. Sci. Environ. Manag, 23, pp. 1825-1828; Bello, R W, Moradeyo, O M, Monitoring cattle grazing behavior and intrusion using global positioning system and virtual fencing (2019) Asian J. Mathemat. Sci, 3, pp. 4-14; Bello, R W, Abubakar, S, Framework for Modeling Cattle Behavior through Grazing Patterns (2020) Asian J. Mathemat. Sci, 4, pp. 75-79; Bello, R W, Talib, A Z H, Mohamed, A S A B, A framework for real-Time cattle monitoring using multimedia networks (2020) Intern. J. Recent Technol. Engin, 8, pp. 974-979; Marchant, J, Secure animal identification and source verification (2002) J M Communications UK, pp. 1-28; Bello, R W, Talib, A Z, Mohamed, A S A, Olubummo, D A, Otobo, F N, Image-based Individual Cow Recognition using Body Patterns (2020) Intern. J. Adv. Comp. Sci. Appl, 11, pp. 92-98; Bello, R, Talib, A, Mohamed, A, Deep learning-based architectures for recognition of cow using cow nose image pattern Gazi Uni (2020) J. Sci, pp. 1-1; Cai, C, Li, J, Cattle face recognition using local binary pattern descriptor (2013) 2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, pp. 1-4; Zin, T T, Phyo, C N, Tin, P, Hama, H, Kobayashi, I, Image technology based cow identification system using deep learning (2018) Lecture Notes in Engineering and Computer Science In Proceedings of the International MultiConference of Engineers and Computer Scientists, 1, pp. 320-323; Kumar, S, Singh, S K, Automatic identification of cattle using muzzle point pattern: A hybrid feature extraction and classification paradigm Multim (2017) Tools Appl, 76, pp. 26551-26580; Kumar, S, Pandey, A, Satwik, K S R, Kumar, S, Singh, S K, Singh, A K, Mohan, A, Deep learning framework for recognition of cattle using muzzle point image pattern Measurement (2018) J. Intern. Measurem. Confeder, 116, pp. 1-17; Kumar, S, Singh, S K, Cattle recognition: A new frontier in visual animal biometrics research (2019) Proceedings of the National Academy of Sciences India Section A Physical Sciences, pp. 1-20; Mahmoud, H A, Hadad, H M R E, Automatic cattle muzzle print classification system using multiclass support vector machine (2015) International Journal of Image Mining (IJIM), 1, pp. 126-140; Ahmed, S, Gaber, T, Tharwat, A, Hassanien, A E, Snáel, V, Muzzle-based cattle identification using speed up robust feature approach 2015 (2015) International Conference on Intelligent Networking and Collaborative Systems, pp. 99-104; Evans, J, Van Eenennaam, A, (2005) Livestock identification. An introduction to electronic animal identifications systems and comparison of technologies Emerging management systems in animal identification, pp. 1-12. , http://animalscience.ucdavis.edu/animalID/, [Disponible en Línea]; Allen, A, Golden, B, Taylor, M, Patterson, D, Henriksen, D, Skuce, R, Evaluation of retinal imaging technology for the biometric identification of bovine animals in northern Ireland (2008) Livest Sci, 116, pp. 42-52","Bello, R.W.; School of Computer Sciences, Malaysia; email: sirbrw@yahoo.com",Carranca C.Feng X.,,IOP Publishing Ltd,"6th International Conference on Agricultural and Biological Sciences, ABS 2020",23 August 2020 through 26 August 2020,,165910,17551307,,,,English,IOP Conf. Ser. Earth Environ. Sci.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85098322994
"Ayounis H., Jamaludin R., Wahab M.N.A., Mohamed A.S.A.",57220178798;54401335900;36471236100;57190968285;,"The review of NAO robotics in Educational 2014-2020 in COVID-19 Virus (Pandemic Era): Technologies, type of application, advantage, disadvantage and motivation",2020,IOP Conference Series: Materials Science and Engineering,928,3,32014,,,,,10.1088/1757-899X/928/3/032014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097147382&doi=10.1088%2f1757-899X%2f928%2f3%2f032014&partnerID=40&md5=14d86cccb2dcdfbbe6ff53d583eef4ef,"College of Education for Women, University of Basrah, Basrah, Iraq; School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia","Ayounis, H., College of Education for Women, University of Basrah, Basrah, Iraq, School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Jamaludin, R., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Wahab, M.N.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia","The use of robotics in education is a very important issue for disposal and galaxies in this era of the pandemic (COVID-19). Where this study examines the topic of robotics in education (RIE) by using modern and specific query methods extracted from different research sites and based on judicious scholar's standards. These sites are Web of Science, Taylor and Francis and Science Direct. After careful investigation and deep research, the following titles should be taken which are (a)Educational robots, (b)education in robots, (c) human-robot interaction, (d) Higher Education, (e) academic, (f) smart pedagogy, (j)student, and (h) tutors. The retrieved articles were filtered according to the Use of robotics in Education. A total of 98 articles were selected and examined. Finally, we examined the taxonomy of these articles of robotics in Education base on faith and guidance, according to specific criteria, into six groups, which include Faith and Guidance, Concepts, Device, Application, Manufacturing, Studies Analysis and educational. Therefore, this work will be the platform and the guide for student, researcher, educators, anyone how interest in this field. The current focus in this area is on employing papers containing NAO robots and that 17 articles. © 2020 Published under licence by IOP Publishing Ltd.",academic; Education in robots; NAO robot; smart pedagogy; student,,,,,,,,,"Rodriguez, I., Astigarraga, A., Jauregi, E., Ruiz, T., Lazkano, E., Humanizing NAO robot teleoperation using ROS (2015) IEEE-RAS Int. Conf. Humanoid Robot, pp. 179-186. , 2015-Febru; Ali, S., (2020) Hand gesture based control of NAO robot using myo armband 953, , (Springer International Publishing); Mubin, O., Cappuccio, M., Alnajjar, F., Ahmad, M. I., Shahid, S., Can a robot invigilator prevent cheating? (2020) AI Soc; Hameed, I. A., Strazdins, G., Hatlemark, H. A. M., Jakobsen, I. S., Damdam, J. O., Robots that can mix serious with fun (2018) International Conference on Advanced Machine Learning Technologies and Applications, pp. 595-604; Caudana, E. L., Baltazar Reyes, G., Acevedo, R. G., Ponce, P., Mazon, N., Hernandez, J. M., RoboTICs: Implementation of a Robotic Assistive Platform in a Mathematics High School Class (2019) IEEE Int. Symp. Ind. Electron, pp. 1589-1594. , 2019-June; Wan, Z., Qin, W., Song, K., Wang, B., (2018) Design and Implementation of Virtual Instructor Based on NAO Robot, 690, pp. 1207-1212; Mubin, O., Ahmad, M. I., Kaur, S., Shi, W., Khan, A., Social Robots in Public Spaces: A Meta-review (2018) International Conference on Social Robotics, pp. 213-220; Pöhner, N., Hennecke, M., Evaluation of a robotics course with the humanoid Robot NAO in CS teacher education (2018) ACM Int. Conf. Proceeding Ser, pp. 2-3; Michieletto, S., Tosello, E., Pagello, E., Menegatti, E., Teaching humanoid robotics by means of human teleoperation through RGB-D sensors (2016) Rob. Auton. Syst, 75, pp. 671-678; Hawley, L., Suleiman, W., Control framework for cooperative object transportation by two humanoid robots (2019) Rob. Auton. Syst, 115, pp. 1-16; Rosanda, V., Starčič, A. I., A review of social robots in classrooms: Emerging educational technology and teacher education (2019) Educ. Self Dev, 14, pp. 93-106; Hong, N. W. W., Chew, E., Sze-Meng, J. W., The review of educational robotics research and the need for real-world interaction analysis 2016 (2016) 14th Int. Conf. Control. Autom. Robot. Vision, ICARCV 2016; Kossewska, J., Kłosowska, J., Acceptance of Robot-Mediated Teaching and Therapy for Children With Atypical Development by Polish Professionals (2020) J. Policy Pract. Intellect. Disabil, 17, pp. 21-30; Keller, L., John, I., Motivating female students for computer science by means of robot workshops (2020) Int. J. Eng. Pedagog, 10, pp. 94-108; Santos, C. B., Ferreira, D. J., De Souza, M. C. B. D. N. R., Martins, A. R., Robotics and programming: Attracting girls to technology 2016 (2016) Int. Conf. Adv. Comput. Commun. Informatics, ICACCI, 2016, pp. 2052-2056; Wright, J. R., Ginter, E. S., David, B. G., Kilbourne, B. J., Wells, J. R., Intermediate programming methodologies for manipulating Modern Humanoid Robots Univers (2019) J. Electr. Electron. Eng, 6, pp. 214-222; The Next Wave of Learning with Humanoid Robot: Learning Innovation Design starts with 'Hello NAO,' (2019) Accid. Anal. Prev, 19, pp. 501-502; Giaretta, A., De Donno, M., Dragoni, N., Secure Coding and Ethical Hacking Workshops with NAO for Engaging K-12 Female Students (2018) CS ACM Int. Conf. Proceeding Ser; Alex Polishuk, I. V., (2017) Student-Robot Interactions in Museum Workshops: Learning Activities and Outcomes","Ayounis, H.; College of Education for Women, Iraq; email: hussain.younis@uobasrah.edu.iq",Shafik S.S.Roomi A.B.Sharrad F.I.,,IOP Publishing Ltd,"2nd International Scientific Conference of Al-Ayen University, ISCAU 2020",15 July 2020 through 17 July 2020,,165187,17578981,,,,English,IOP Conf. Ser. Mater. Sci. Eng.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85097147382
"Yee Hui D.O., Lutfi S.L., Naim S., Akhtar Z., Azlan Mohamed A.S., Siddique K.",57219472499;27567802400;55413206700;46661628200;57190968285;57191228422;,The sound of trust: Towards modelling computational trust using voice-only cues at zero-acquaintance,2020,"Advances in Science, Technology and Engineering Systems",5,4,,469,476,,,10.25046/AJ050456,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092894298&doi=10.25046%2fAJ050456&partnerID=40&md5=d554b99e76bddc28af3d0eb4ec95b67e,"Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Woosong University, Technology Department, Endicott College of International Studies, Daejeon, 34606, South Korea; University of Memphis, Tennessee, 38152, United States; Xiamen University Malaysia, Sepang, 43900, Malaysia","Yee Hui, D.O., Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Lutfi, S.L., Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Naim, S., Woosong University, Technology Department, Endicott College of International Studies, Daejeon, 34606, South Korea; Akhtar, Z., University of Memphis, Tennessee, 38152, United States; Azlan Mohamed, A.S., Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Siddique, K., Xiamen University Malaysia, Sepang, 43900, Malaysia","Trust is essential in many interdependent human relationships. Trustworthiness is measured via the effectiveness of the relationships involving human perception. The decision to trust others is often made quickly (even at zero acquaintance). Previous research has shown the significance of voice in perceived trustworthiness. However, the listeners' characteristics were not considered. A system has yet to be produced that can quantitatively predict the degree of trustworthiness in a voice. This research aims to investigate the relationship between trustworthiness and different vocal features while considering the listener's physical characteristics, towards modelling a computational trust model. This study attempts to predict the degree of trustworthiness in voice by using an Artificial Neural Network (ANN) model. A set of 30 audio clips of white males were obtained, acoustically analyzed and then distributed to a large group of untrained Malaysian respondents who rated their degree of trust in the speakers of each audio clip on a scale of 0 to 10. The ANOVA test showed a statistically significant difference of trust ratings across different types and intensities of emotion, duration of audio clip, average fundamental frequencies, speech rates, articulation rates, average loudness, ethnicity of listener and ages of listener (p <.01). The findings conclude that Malaysians tend to trust white males who talk faster and longer, speak louder, have an f0 between 132.03Hz & 149.52Hz, and show a neutral emotion or rather stoic (arousal<.325). Results suggest that Indians are the most trusting Malaysian ethnic group, followed by Bumiputera from East Malaysia and then followed by Malays. Chinese are the least trusting Malaysian ethnic group. The data was fed into an ANN model to be evaluated, which yielded a perfect percentage accuracy (100%) in degree of trustworthiness 39.70% of the time. Given a threshold of two-point deviation, the ANN had a prediction accuracy of 76.86%. © 2020 ASTES Publishers. All rights reserved.",Artificial neural network; True; Voice; Zero acquaintance,,,,,,"XMUMRF/2019-C3/IECE/0006

Universiti Sains Malaysia: 1001/PKOMP/8014001, 304/PKOMP/6315137","This work was supported by the Research Management Center, Xiamen University Malaysia under the XMUM Research Program Cycle 3 (Grant XMUMRF/2019-C3/IECE/0006). The authors also thank Universiti Sains Malaysia for the partial funding of this work from the grant no. 304/PKOMP/6315137 and 1001/PKOMP/8014001.",,"Ambady, N., Krabbenhoft, M. A., Hogan, D., The 30-sec sale: Using thin-slice judgments to evaluate sales effectiveness (2006) J. Consum. Psychol, 16 (1), pp. 4-13. , https://doi.org/10.1207/s15327663jcp1601_2; Stirrat, M., Perrett, D. I., Valid Facial Cues to Cooperation and Trust: Male Facial Width and Trustworthiness (2010) Psychol. Sci, 21 (3), pp. 349-354. , https://doi.org/10.1177/0956797610362647; Kenny, D. A., West, T. V, Zero acquaintance: Definitions, statistical model, findings, and process (2008) First impressions, pp. 129-146. , New York, Guilford Press; Ambady, N., Rosenthal, R., Half a minute: Predicting teacher evaluations from thin slices of nonverbal behavior and physical attractiveness (1993) J. Pers. Soc. Psychol, 64 (3), p. 431. , https://doi.org/10.1037/0022-3514.64.3.431; Eisenkraft, N., Accurate by way of aggregation: Should you trust your intuition-based first impressions? (2013) J. Exp. Soc. Psychol, 49 (2), pp. 277-279. , https://doi.org/10.1016/j.jesp.2012.11.005; Hecht, M. A., LaFrance, M., How (Fast) Can I Help You? Tone of Voice and Telephone Operator Efficiency in Interactions 1 (1995) J. Appl. Soc. Psychol, 25 (23), pp. 2086-2098; Ambady, N., Bernieri, F. J., Richeson, J. A., (2000) Toward a histology of social behavior: Judgmental accuracy from thin slices of the behavioral stream, 32, pp. 201-271. , https://doi.org/10.1016/S0065-2601(00)80006-4, Academic Press; Mohammad, S. M., Kiritchenko, S., Using nuances of emotion to identify personality (2013) Proc. ICWSM, , https://arxiv.org/abs/1309.6352; Höhmann, H. H., Malieva, E., The concept of trust: Some notes on definitions, forms and sources (2005) Trust Entrep.), pp. 7-23; Edwards, C., Edwards, A., Stoll, B., Lin, X., Massey, N., Evaluations of an artificial intelligence instructor's voice: Social Identity Theory in human-robot interactions (2019) Comput. Human Behav, 90, pp. 357-362. , https://doi.org/10.1016/j.chb.2018.08.027; Goel, A., Creeden, B., Kumble, M., Salunke, S., Shetty, A., Wiltgen, B., Using watson for enhancing human-computer co-creativity (2015) 2015 AAAI Fall Symposium Series; Følstad, A., Nordheim, C. B., Bjørkli, C. A., What makes users trust a chatbot for customer service? An exploratory interview study (2018) International Conference on Internet Science, pp. 194-208. , https://doi.org/10.1007/978-3-030-01437-7_16; Ciechanowski, L., Przegalinska, A., Magnuski, M., Gloor, P., In the shades of the uncanny valley: An experimental study of human-chatbot interaction (2019) Futur. Gener. Comput. Syst, 92, pp. 539-548. , https://doi.org/10.1016/j.future.2018.01.055; Fenwick, J., Barclay, L., Schmied, V., Chatting: an important clinical tool in facilitating mothering in neonatal nurseries (2001) J. Adv. Nurs, 33 (5), pp. 583-593. , https://doi.org/10.1046/j.1365-2648.2001.01694.x; Bos, N., Olson, J., Gergle, D., Olson, G., Wright, Z., Effects of Four Computer-mediated Communications Channels on Trust Development (2002) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 135-140. , https://doi.org/10.1145/503376.503401; Qiu, L., Benbasat, I., Online Consumer Trust and Live Help Interfaces: The Effects of Text-to-Speech Voice and Three-Dimensional Avatars (2005) Int. J. Human-Computer Interact, 19 (1), pp. 75-94. , https://doi.org/10.1207/s15327590ijhc1901_6; Greenspan, S., Goldberg, D., Weimer, D., Basso, A., Interpersonal Trust and Common Ground in Electronically Mediated Communication (2000) Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work, pp. 251-260. , https://doi.org/10.1145/358916.358996; Schirmer, A., Feng, Y., Sen, A., Penney, T. B., Angry, old, male-and trustworthy? How expressive and person voice characteristics shape listener trust (2019) PLoS One, 14 (1), p. e0210555. , https://doi.org/10.1371/journal.pone.0210555; Hughes, S. M., Harrison, M. A., Your Cheatin' Voice Will Tell on You: Detection of Past Infidelity from Voice (2017) EPsychol, 15 (2), p. 1474704917711513. , https://doi.org/10.1177/1474704917711513; Belin, P., Boehme, B., McAleer, P., The sound of trustworthiness: Acoustic-based modulation of perceived voice personality (2017) PLoS One, 12 (10), pp. 1-9. , https://doi.org/10.1371/journal.pone.0185651; Doney, P. M., Cannon, J. P., Mullen, M. R., Understanding the influence of national culture on the development of trust (1998) Acad. Manag. Rev, 23 (3), pp. 601-620. , https://doi.org/10.2307/259297; Gefen, D., Heart, T. H., On the need to include national culture as a central issue in e-commerce trust beliefs (2006) J. Glob. Inf. Manag, 14 (4), pp. 1-30. , https://doi.org/10.4018/jgim.2006100101; Zaheer, S., Zaheer, A., Trust across borders (2006) J. Int. Bus. Stud, 37 (1), pp. 21-29. , https://doi.org/10.1057/palgrave.jibs.8400180; Niebuhr, O., Voße, J., Brem, A., What makes a charismatic speaker? A computer-based acoustic-prosodic analysis of Steve Jobs tone of voice (2016) Comput. Human Behav, 64, pp. 366-382. , https://doi.org/10.1016/j.chb.2016.06.059; Anolli, L., Ciceri, R., The voice of deception: Vocal strategies of naive and able liars (1997) J. Nonverbal Behav, 21 (4), pp. 259-284; Zuckerman, M., DeFrank, R. S., Hall, J. A., Larrance, D. T., Rosenthal, R., Facial and vocal cues of deception and honesty (1979) J. Exp. Soc. Psychol, 15 (4), pp. 378-396. , https://doi.org/10.1016/0022-1031(79)90045-3; Kirchhübel, C., Howard, D. M., Detecting suspicious behaviour using speech: Acoustic correlates of deceptive speech-An exploratory investigation (2013) Appl. Ergon, 44 (5), pp. 694-702. , https://doi.org/10.1016/j.apergo.2012.04.016; Torre, I., White, L., Goslin, J., (2016) Behavioural mediation of prosodic cues to implicit judgements of trustworthiness, , https://doi.org/10.21437/SpeechProsody.2016-167; Korovaiko, N., Thomo, A., Trust prediction from user-item ratings (2013) Soc. Netw. Anal. Min, 3 (3), pp. 749-759. , https://doi.org/10.1007/s13278-013-0122-z; DuBois, T., Golbeck, J., Srinivasan, A., Predicting trust and distrust in social networks (2011) 2011 IEEE third international conference on privacy, security, risk and trust and 2011 IEEE third international conference on social computing, pp. 418-424. , https://doi.org/10.1109/PASSAT/SocialCom.2011.56; Zong, B., Xu, F., Jiao, J., Lv, J., A broker-assisting trust and reputation system based on artificial neural network (2009) 2009 IEEE International Conference on Systems, Man and Cybernetics, pp. 4710-4715. , https://doi.org/10.1109/ICSMC.2009.5346098; Bejou, D., Wray, B., Ingram, T. N., Determinants of relationship quality: an artificial neural network analysis (1996) J. Bus. Res, 36 (2), pp. 137-143. , https://doi.org/10.1016/0148-2963(95)00100-X; Lee, J. J., Knox, B., Breazeal, C., Modeling the dynamics of nonverbal behavior on interpersonal trust for human-robot interactions (2013) 2013 AAAI Spring Symposium Series, , http://hdl.handle.net/1721.1/69244; Ekonomou, L., Greek long-term energy consumption prediction using artificial neural networks (2010) Energy, 35 (2), pp. 512-517. , https://doi.org/10.1016/j.energy.2009.10.018; Imhof, M., Listening to Voices and Judging People (2010) Int. J. List, 24 (1), pp. 19-33. , https://doi.org/10.1080/10904010903466295; Smith, B. L., Brown, B. L., Strong, W. J., Rencher, A. C., Effects of Speech Rate on Personality Perception (1975) Lang. Speech, 18 (2), pp. 145-152. , https://doi.org/10.1177/002383097501800203; Ismail, M. N., Chee, S. S., Nawawi, H., Yusoff, K., Lim, T. O., James, W. P. T., Obesity in Malaysia (2002) Obes. Rev, 3 (3), pp. 203-208. , https://doi.org/10.1046/j.1467-789X.2002.00074.x; Swami, V., Furnham, A., Self-assessed intelligence: Inter-ethnic, rural-urban, and sex differences in Malaysia (2010) Learn. Individ. Differ, 20 (1), pp. 51-55. , https://doi.org/10.1016/j.lindif.2009.11.002; Barros, P., Churamani, N., Lakomkin, E., Siqueira, H., Sutherland, A., Wermter, S., The OMG-Emotion Behavior Dataset (2018) Proceedings of the International Joint Conference on Neural Networks, pp. 2018-July. , https://doi.org/10.1109/IJCNN.2018.8489099; Ekman, P., Friesen, W. V., Constants across cultures in the face and emotion (1971) J. Pers. Soc. Psychol, 17 (2), pp. 124-129. , https://psycnet.apa.org/doi/10.1037/h0030377; Trouvain, J., Schmidt, S., Schröder, M., Schmitz, M., Barry, W. J., (2006) Modelling personality features by changing prosody in synthetic speech, , https://doi.org/10.22028/D291-25920; Quené, H., On the just noticeable difference for tempo in speech (2007) J. Phon, 35 (3), pp. 353-362. , https://doi.org/10.1016/j.wocn.2006.09.001; Yulin, G., The Spectrum of Trust and Distrust (2012) Jiangsu Soc. Sci, 1","Lutfi, S.L.; Universiti Sains Malaysia, Malaysia; email: syahherah@usm.my
Siddique, K.; Xiamen University MalaysiaMalaysia; email: kamran.siddique@xmu.edu.my",,,ASTES Publishers,,,,,24156698,,,,English,"Adv. Sci., Technol. Eng. Syst.",Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85092894298
"Bello R.-W., Talib A.Z.H., Mohamed A.S.A.B.",57209469141;35570816900;57190968285;,Deep learning-based architectures for recognition of cow using cow nose image pattern,2020,Gazi University Journal of Science,33,3,,831,844,,2,10.35378/gujs.605631,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090096917&doi=10.35378%2fgujs.605631&partnerID=40&md5=f63289f0e46e042875b36a64bbd523e2,"School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang  11800, Malaysia","Bello, R.-W., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang  11800, Malaysia; Talib, A.Z.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang  11800, Malaysia; Mohamed, A.S.A.B., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang  11800, Malaysia","Stacked denoising auto-encoder and deep belief network are proposed as methods of deep learning for cow nose image texture feature extraction, and for learning the extracted features for better representation. While stacked denoising auto-encoder is applied for encoding and decoding of the extracted features, a deep belief network is applied for learning the extracted features and representing the cow nose image in feature space. Stacked denoising auto-encoder and deep belief network help in animal biometrics. Biometrics emanated from computer vision and pattern recognition and it plays an important role in the automated animal registration and identification process. Using the visual attributes of cow, and for the fact that the existing visual feature extraction and representation methods are not capable of handling cow recognition; deep belief network and stacked denoising auto-encoder are proposed. An experiment performed under different conditions of identification indicated that deep belief network outshines other methods with approximately 98.99% accuracy. 4000 cow nose images from an existing database of 400 individual cows contribute to the community of research especially in the animal biometrics for identification of individual cow. © 2020, Gazi University Eti Mahallesi. All rights reserved.",Animal biometrics; Cow nose image; DBN; Deep learning; SDAE,Animals; Biometrics; Extraction; Feature extraction; Image texture; Learning systems; Signal encoding; Textures; Deep belief networks; Encoding and decoding; Identification of individuals; Identification process; Representation method; Texture feature extraction; Visual attributes; Visual feature extraction; Deep learning,,,,,,,,"Kumar, S., Singh, S.K., Datta, T., Gupta, H.P., A fast cattle recognition system using smart devices (2016) Proceedings of the 2016 ACM Conference on Multimedia, pp. 742-743; Noviyanto, A., Arymurthy, A.M., Automatic cattle identification based on muzzle photo using speed-up robust features approach (2012) Proceedings of the 3rd European Conference of Computer Science, ECCS, 110, p. 114; Kohl, H.S., Burkhart, T., Animal biometrics: quantifying and detecting phenotypic Appearance (2013) Trends Ecol. Evol, 28 (7), pp. 432-441; Duyck, J., Finn, C., Hutcheon, A., Vera, P., Salas, J., Ravela, S., Sloop: a pattern retrieval engine for individual animal identification (2015) Pattern Recogn, 48 (4), pp. 1059-1073; Nasirahmadi, A., Richter, U., Hensel, O., Edwards, S., Sturm, B., Using machine vision for investigation of changes in pig group lying patterns (2015) Computers and Electronics in Agriculture, (119), pp. 184-190; Wang, Z., Fu, Z., Chen, W., Hu, J., A rfid-based traceability system for cattle breeding in china (2010) Proceedings of 2010 IEEE International Conference on Computer Application and System Modeling (ICCASM), (2), pp. V2-567; Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Incetas, M. O., Demirci, R., Yavuzcan, H. G., Automatic Color Edge Detection with Similarity Transformation (2019) Gazi University Journal of Science, 32 (2), pp. 458-469; Sun, Y., Wang, X., Tang, X., Deep convolutional network cascade for facial point detection (2013) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3476-3483; Kumar, S., Singh, S.K., Visual animal biometrics: survey (2016) IET Biometrics, 6 (3), pp. 139-156; Barron, U.G., Butler, F., McDonnell, K., Ward, S., The end of the identity crisis? Advances in biometric markers for animal identification (2009) Irish Veterinary J, 62 (3), pp. 204-208; Reiter, S., Sattlecker, G., Lidauer, L., Kickinger, F., Öhlschuster, M., Auer, W., Iwersen, M., Evaluation of an ear-tag-based accelerometer for monitoring rumination in dairy cows (2018) Journal of Dairy Science, 101 (4), pp. 3398-3411; Seijas, C., Montilla, G., Frassato, L., Identification of Rodent Species Using Deep Learning (2019) Computación y Sistemas, 23 (1), p. 257; Hansen, M.F., Smith, M.L., Smith, L.N., Salter, M.G., Baxter, E.M., Farish, M., Grieve, B., Towards on-farm pig face recognition using convolutional neural networks (2018) Computers in Industry, 98, pp. 145-152; Kumar, S., Singh, S.K., Cattle Recognition: A New Frontier in Visual Animal Biometrics Research (2019) Proceedings of the National Academy of Sciences, India Section A: Physical Sciences, pp. 1-20; Norouzzadeh, M.S., Nguyen, A., Kosmala, M., Swanson, A., Palmer, M.S., Packer, C., Clune, J., Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning (2018) Proceedings of the National Academy of Sciences, 115 (25), pp. E5716-E5725; Zin, T.T., Phyo, C.N., Tin, P., Hama, H., Kobayashi, I., Image technology based cow identification system using deep learning (2018) Proceedings of the International MultiConference of Engineers and Computer Scientists, 1; Kumar, S., Pandey, A., Satwik, K.S.R., Kumar, S., Singh, S.K., Singh, A.K., Mohan, A., Deep learning framework for recognition of cattle using muzzle point image pattern (2018) Measurement, 116, pp. 1-17; Iswanto, I.A., Li, B., Visual object tracking based on mean-shift and particle-Kalman filter (2017) Procedia Computer Science, 116, pp. 587-595; Minagawa, H., Fujimura, T., Ichiyanagi, M., Tanaka, K., Fangquan, M., Identification of beef cattle by analyzing images of their muzzle patterns lifted on paper (2002) Proceedings of the 3rd Asian Conference for Information Technology in Asian Agricultural Information Technology & Management, pp. 596-600; Barry, B., Gonzales-Barron, U., McDonnell, K., Butler, F., Ward, S., Using muzzle pattern recognition as a biometric approach for cattle identification (2007) Trans. ASABE, 50 (3), pp. 1073-1080; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Proc. CVPR, 1, pp. 886-893; Awad, A.I., Zawbaa, H.M., Mahmoud, H.A., Nabi, E.H.H.A., Fayed, R.H., Hassanien, A.E., A robust cattle identification scheme using muzzle print images (2013) Proceedings of IEEE Federated Conference on Computer Science and Information Systems (FedCSIS), pp. 529-534; Noviyanto, A., Arymurthy, A.M., Beef cattle identification based on muzzle pattern using a matching refinement technique in the sift method (2013) Comp. Electr. Agr, (99), pp. 77-84; Kumar, S., Tiwari, S., Singh, S.K., Face recognition for cattle (2015) Proceedings of 3rd IEEE International Conference on Image Information Processing (ICIIP), pp. 65-72; Ehsani, K., Bagherinezhad, H., Redmon, J., Mottaghi, R., Farhadi, A., Who let the dogs out? modeling dog behavior from visual data (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4051-4060; Gaber, T., Tharwat, A., Hassanien, A.E., Snasel, V., Biometric cattle identification approach based on webers local descriptor and AdaBoost classifier (2016) Comp. Electr. Agr, (122), pp. 55-66; Risha, K.P., Chempak, K.A., Sindhu, C.S., Difference of Gaussian on Frame Differenced Image (2016) International Journal of Innovative Research in Electrical, Electronics, Instrumentation and Control Engineering, 3 (1), pp. 92-95; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., Stacked denoising auto-encoders: learning useful representations in a deep network with a local denoising criterion (2010) JMLR, (11), pp. 3371-3408; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 1096-1103. , ACM; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning, 2 (1), pp. 1-127; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828","Bello, R.-W.; School of Computer Sciences, Malaysia; email: sirbrw@yahoo.com",,,Gazi Universitesi,,,,,21471762,,,,English,GU J. Sci.,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85090096917
"Bello R.-W., Talib A.Z., Mohamed A.S.A., Olubummo D.A., Otobo F.N.",57209469141;35570816900;57190968285;57216345013;57216337593;,Image-based individual cow recognition using body patterns,2020,International Journal of Advanced Computer Science and Applications,11,3,,92,98,,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083241430&partnerID=40&md5=98fd3a91ca93346abd229678bad5b879,"School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Department of Computer and Information Systems, Robert Morris University, Moon-Township, PA, United States; Department of Mathematical Sciences, University of Africa, Toru-Orua, Bayelsa State, Nigeria","Bello, R.-W., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Talib, A.Z., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau, Pinang, 11800, Malaysia; Olubummo, D.A., Department of Computer and Information Systems, Robert Morris University, Moon-Township, PA, United States; Otobo, F.N., Department of Mathematical Sciences, University of Africa, Toru-Orua, Bayelsa State, Nigeria","The existence of illumination variation, non-rigid object, occlusion, non-linear motion, and real-time implementation requirement has made tracking in computer vision a challenging task. In order to recognize individual cow and to mitigate all the challenging tasks, an image processing system is proposed using the body pattern images of the cow. This system accepts an input image, performs processing operation on the image, and output results in form of classification under certain categories. Technically, convolutional neural network is modeled for the training and testing of each pattern image of 1000 acquired images of 10 species of cow which will pass it through a series of convolution layers with filters, pooling, fully connected layers and softmax function for the pattern images classification with probabilistic values between 0 and 1. The performance evaluation of the proposed system for both training and testing data was carried out for each cow's identification and 92.59% and 89.95% accuracies were achieved respectively. © 2020, Science and Information Organization.",Body patterns; Convolutional neural network; Cow; Image; Recognition,,,,,,"Institute of Postgraduate Studies, Universiti Sains Malaysia, IPS: 11800","This work was supported in part by the Institute of Postgraduate Studies, Universiti Sains Malaysia, 11800 USM, Penang, MALAYSIA.",,"Miao, Z., Gaynor, K.M., Wang, J., Liu, Z., Muellerklein, O., Norouzzadeh, M.S., Getz, W.M., Insights and approaches using deep learning to classify wildlife (2019) Scientific Reports, 9 (1), pp. 1-9; Kumar, S., Singh, S.K., Cattle Recognition: A New Frontier in Visual Animal Biometrics Research (2019) Proceedings of the National Academy of Sciences, India Section A: Physical Sciences, pp. 1-20; Zin, T.T., Phyo, C.N., Tin, P., Hama, H., Kobayashi, I., Image technology based cow identification system using deep learning (2018) Proceedings of the International MultiConference of Engineers and Computer Scientists, p. 1; Bello, R.W., Moradeyo, O.M., Monitoring Cattle Grazing Behavior and Intrusion Using Global Positioning System and Virtual Fencing (2019) Asian Journal of Mathematical Sciences, 3 (4), pp. 4-14; Bello, R.W., An overview of animal behavioral adaptive frightening system (2018) International Journal of Mathematics and Physical Sciences Research, 6 (1), pp. 126-133; Barron, U.G., Butler, F., McDonnell, K., Ward, S., The end of the identity crisis? Advances in biometric markers for animal identification (2009) Irish Veterinary J, 62 (3), pp. 204-208; Shen, M., Liu, L., Yan, L., Lu, M., Yao, W., Yang, X., Review of monitoring technology for animal individual in animal husbandry (2014) Nongye Jixie Xuebao = Transactions of the Chinese Society For Agricultural Machinery, 45 (10), pp. 245-251; Bello, R.W., Abubakar, S., Development of a Software Package for Cattle Identification in Nigeria (2019) Journal of Applied Sciences and Environmental Management, 23 (10), pp. 1825-1828. , https://dx.doi.org/10.4314/jasem.v23i10.9; Bello, R.W., Talib, A.Z.H., Mohamed, A.S.A.B., A Framework for Real-time Cattle Monitoring using Multimedia Networks (2020) International Journal of Recent Technology and Engineering, 8 (5); Grooms, D., (2007) Radio Frequency Identification (RFID) Technology For Cattle"", Extension Bulletin E-2970, , Michigan State University, Jan; Lu, Y., He, X., Wen, Y., Wang, P.S., A new cow identification system based on iris analysis and recognition (2014) International Journal of Biometrics, 6 (1), pp. 18-32; Kumar, S., Tiwari, S., Singh, S.K., Face recognition of cattle: Can it be done? (2016) Proceedings of the National Academy of Sciences, India Section A: Physical Sciences, 86 (2), pp. 137-148; Kumar, S., Tiwari, S., Singh, S.K., Face recognition for cattle (2015) Third IEEE International Conference On Image Information Processing (ICIIP), pp. 65-72; Marchant, J., Secure animal identification and source verification (2002) JM Communications, UK, pp. 1-28; Allen, A., Golden, B., Taylor, M., Patterson, D., Henriksen, D., Skuce, R., Evaluation of retinal imaging technology for the biometric identification of bovine animals in northern Ireland (2008) Livest Sci, 116 (1), pp. 42-52; Baranov, A., Graml, R., Pirchner, F., Schmid, D., Breed differences and intra-breed genetic variability of dermatoglyphic pattern of cattle (1993) J Anim Breed Genet, 110 (1-6), pp. 385-392; Johnston, A., Edwards, D., Welfare implications of identification of cattle by ear tags (1996) The Veterinary Record, 138 (25), pp. 612-614; Wardrope, D.D., Problems with the use of ear tags in cattle (1995) The Veterinary Record, 137 (26), pp. 675-675; Wang, Z., Fu, Z., Chen, W., Hu, J., A RFID-based traceability system for cattle breeding in china (2010) Proceedings of 2010 International Conference On Computer Application and System Modeling (ICCASM 2010), 2, pp. V2-567; Noviyanto, A., Arymurthy, A.M., Beef cattle identification based on muzzle pattern using a matching refinement technique in the sift method (2013) Comput Electron Agric, 99, pp. 77-84; Petersen, W.E., The identification of the bovine by means of nose-prints (1922) Journal of Dairy Science, 5 (3), pp. 249-258; Minagawa, H., Fujimura, T., Ichiyanagi, M., Tanaka, K., Fangquan, M., Identification of beef cattle by analyzing images of their muzzle patterns lifted on paper"", Proceedings of the 3rd Asian Conference for Information Technology in Asian agricultural information technology & management (2002) Publications of the Japanese Society of Agricultural Informatics, 8, pp. 596-600; Tharwat, A., Gaber, T., Hassanien, A.E., Cattle identification based on muzzle images using gabor features and svm classifier (2014) Proceedings of Advanced Machine Learning Technologies and Applications, pp. 236-247; Mishra, S., Tomer, O.S., Kalm, E., Muzzle dermatoglyphics: A new method to identify bovines (1995) Asian Livestock, pp. 91-96; Barry, B., Gonzales-Barron, U., McDonnell, K., Butler, F., Ward, S., Using muzzle pattern recognition as a biometric approach for cattle identification (2007) Trans ASABE, 50 (3), pp. 1073-1080; Kim, H.T., Ikeda, Y., Choi, H.L., The identification of Japanese black cattle by their faces (2005) Asian Australasian Journal of Animal Sciences, 18 (6), pp. 868-872; Cai, C., Li, J., Cattle face recognition using local binary pattern descriptor (2013) Proceedings of 2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA), pp. 1-4; Noviyanto, A., Arymurthy, A.M., Automatic cattle identification based on muzzle photo using speed-up robust features approach (2012) Proceedings of the 3rd European Conference of Computer Science, ECCS, 110, p. 114; Awad, A.I., Zawbaa, H.M., Mahmoud, H.A., Nabi, E.H.H.A., Fayed, R.H., Hassanien, A.E., A robust cattle identification scheme using muzzle print images (2013) Proceedings of 2013 Federated Conference On Computer Science and Information Systems (FedCSIS), pp. 529-534; Eitel, A., Springenberg, J.T., Spinello, L., Riedmiller, M., Burgard, W., Multimodal deep learning for robust RGB-D object recognition (2015) 2015 IEEE/RSJ International Conference On Intelligent Robots and Systems (IROS), pp. 681-687; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Berg, A.C., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks"" (2012) Advances In Neural Information Processing Systems, pp. 1097-1105; Schwarz, M., Schulz, H., Behnke, S., RGB-D object recognition and pose estimation based on pre-trained convolutional neural network features (2015) 2015 IEEE International Conference On Robotics and Automation (ICRA), pp. 1329-1335; Jingqiu, G., Zhihai, W., Ronghua, G., Huarui, W., Cow behavior recognition based on image analysis and activities (2017) International Journal of Agricultural and Biological Engineering, 10 (3), pp. 165-174; Andrew, W., Greatwood, C., Burghardt, T., Visual localisation and individual identification of Holstein friesian cattle via deep learning (2017) Proceedings of the IEEE International Conference On Computer Vision, pp. 2850-2859; Kumar, S., Pandey, A., Satwik, K.S.R., Kumar, S., Singh, S.K., Singh, A.K., Mohan, A., Deep learning framework for recognition of cattle using muzzle point image pattern (2018) Measurement, 116, pp. 1-17; Risha, K.P., Chempak, K.A., Sindhu, C.S., Difference of Gaussian on Frame Differenced Image (2016) International Journal of Innovative Research In Electrical, Electronics, Instrumentation and Control Engineering, 3 (1), pp. 92-95; Norouzzadeh, M.S., Nguyen, A., Kosmala, M., Swanson, A., Palmer, M.S., Packer, C., Clune, J., Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning (2018) Proceedings of the National Academy of Sciences, 115 (25); Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.A., Stacked denoising auto-encoders: Learning useful representations in a deep network with a local denoising criterion (2010) Journal of Machine Learning Research, 11, pp. 3371-3408; Kamencay, P., Trnovszky, T., Benco, M., Hudec, R., Sykora, P., Satnik, A., Accurate wild animal recognition using PCA, LDA and LBPH (2016) 2016 ELEKTRO, pp. 62-67",,,,Science and Information Organization,,,,,2158107X,,,,English,Intl. J. Adv. Comput. Sci. Appl.,Article,Final,,Scopus,2-s2.0-85083241430
"Ibrahim N., Hassan F.H., Azlan Mohamed A.S., Khader A.T.",57198067619;36809487100;57190968285;24724794600;,The Impact of Spatial Layout Design on the Pedestrian Movement during Panic Situation: Pedestrian Survival Prediction,2019,Journal of Physics: Conference Series,1201,1,12066,,,,,10.1088/1742-6596/1201/1/012066,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067638748&doi=10.1088%2f1742-6596%2f1201%2f1%2f012066&partnerID=40&md5=232c96ad074a8672b576c6dac40ed732,"School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Ibrahim, N., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Hassan, F.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Azlan Mohamed, A.S., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Khader, A.T., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Crowd management has become the global issue due to the fatal incidents happened that involve the high casualties of pedestrians. During panic situation, the survival rate of the pedestrians are depends on the several parameter values that are hard to discover due to the catastrophic case scenarios and almost impossible for the scene to be created due to the human ethical conduct. Hence, with the advance of computation technique and the improvement of Artificial Intelligence (AI) process automation, the panic situations are able to be visualized with the computer simulation. However, based on the previous simulation researches, there are a lot of features that had been found that are able to influence the pedestrian movement and caused the clogging region on the spatial layout. Hence, this research has been conducted to justify and analyze the findings of influential features by simulating the near-realistic pedestrian movement using Cellular Automata (CA) approach to re-enact the real behavioral actions of the pedestrians during panic situation. Based on the near-realistic simulation and the construction of the spatial layout design based on the features that promotes the clogging region experiments, the results had shown that the structural arrangement of a space is the proper solution to increase the pedestrian survival rate and decrease the clogging region. However, the existing structural also can enhance the safety quality of the space by rearranging the obstacles in the spatial layout. This research had introduced the granularity based approach and proves that the implementation of the fine-grain obstacles' arrangement while accommodating the interior design standard may reduce the time (10 seconds, 0.1%) taken for evacuation process and increase the probability of movement directions for the pedestrians to ensure the balance usage of the egress points. © Published under licence by IOP Publishing Ltd.",,Physics; Computation techniques; Evacuation process; Pedestrian movement; Process automation; Realistic simulation; Simulation research; Structural arrangement; Survival prediction; Architectural design,,,,,,"Research experiments reported were pursued under the Bridging Grant by Universiti Sains Malaysia [304.PKOMP.6316019], Research University Grant by Universiti Sains Malaysia [1001.PKOMP.8014073] and Fundamental Research Grant Scheme (FRGS) by Ministry of Education Malaysia [203.PKOMP.6711534] and [203.PKOMP.6711713].",,"Four in a Family Killed in Fire (2017) The Star Online, , ROC 10894D; Lu, X., Luh, P.B., Tucker, A., Gifford, T., Astur, R.S., Olderman, N., Impacts of Anxiety in Building Fire and Smoke Evacuation: Modeling and Validation (2017) IEEE Robotics and Automation Letters, 2 (1), pp. 255-260; Henderson, B., Graham, C., (2017) The Telegraph, , (Unted Kingdom: Telegraph Media Group Limited) Dubai Skyscraper Fire: Torch Tower Residents Wake to Screams as Flames Engulf 79-Storey Building 2017; Jay, B.N., Tahfiz did not have fire exit; Bodies found piled on top of each other (2017) New Straits Times, , (Malaysia: New Straits Times Press (M) Berhad); Zong, X., Jiang, Y., Pedestrian-vehicle mixed evacuation model based on multi-particle swarm optimization (2016) 2016 11th International Conference on Computer Science & Education (ICCSE), pp. 568-572; Konstantara, K., Dourvas, N.I., Georgoudas, I.G., Sirakoulis, G.C., Parallel Implementation of a Cellular Automata-Based Model for Simulating Assisted Evacuation of Elderly People (2016) 2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP), pp. 702-709; Ruiz, S., Hernández, B., A Parallel Solver for Markov Decision Process in Crowd Simulations (2015) 2015 Fourteenth Mexican International Conference on Artificial Intelligence (MICAI), pp. 107-116; Hall, J.R., (2011) High-Rise Building Fires, , (Quincy, USA: National Fire Protection Association); Yan, Z., Han, X., Li, M., Accurate Assessment of RSET for Building Fire Based on Engineering Calculation and Numerical Simulation (2016) MATEC Web of Conferences, p. 04024; Huixian, J., Shaoping, Z., Navigation system design of fire disaster evacuation path in buildings based on mobile terminals (2016) 2016 11th International Conference on Computer Science & Education (ICCSE), pp. 327-331; Xueling, J., Simulation Model of Pedestrian Evacuation in High-Rise Building: Considering Group Behaviors and Real-Time Fire (2015) International Journal of Smart Home, 9 (2), p. 81. , 8192; Chen, Y., Cai, Y., Li, P., Zhang, G., Study on Evacuation Evaluation in Subway Fire Based on Pedestrian Simulation Technology (2015) Mathematical Problems in Engineering, 2015, p. 9. , 2015; Sime, J.D., Crowd psychology and engineering (1995) Safety Science, 21 (1), pp. 1-14; Tcheukam, A., Djehiche, B., Tembine, H., Evacuation of multi-level building: Design, control and strategic flow (2016) 2016 35th Chinese Control Conference (CCC); Wang, H., Simulation research based on evacuation ability estimation method (2016) 2016 12th World Congress on Intelligent Control and Automation (WCICA), pp. 645-649; Hassan, F.H., Using microscopic pedestrian simulation statistics to find clogging regions (2016) 2016 SAI Computing Conference (SAI), pp. 156-160; Miao, Q., Lv, Y., Zhu, F., A cellular automata based evacuation model on GPU platform (2012) 2012 15th International IEEE Conference on Intelligent Transportation Systems, pp. 764-768; Helbing, D., Johansson, A., (2009) Encyclopedia of Complexity and Systems Science, pp. 1-28. , Helbing D. and Johansson A. ed R. A. Meyers (New York, NY: Springer New York) Pedestrian, Crowd, and Evacuation Dynamics; Helbing, D., Farkas, I., Vicsek, T., Simulating dynamical features of escape panic (2000) Nature, 407 (6803), pp. 487-490; Helbing, D., Farkas, I.J., Molnar, P., Vicsek, T., Simulation of pedestrian crowds in normal and evacuation situations (2002) Pedestrian and Evacuation Dynamics, 21, pp. 21-58; Yamin, M., Al-Ahmadi, H.M., Muhammad, A.A., Integrating social media and mobile apps into Hajj management (2016) 2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom), pp. 1368-1372; Doshi Eloise Stevens, V., Stampede at Indian train station kills at least 22 (2017) The Washington Post, , (Washington, D.C, USA: The Washington Post); Zhang, L., Lai, D., Miranskyy, A.V., The impact of position errors on crowd simulation Simulation Modelling Practice and Theory, 90, pp. 45-63. , 2019/01/01/2019; Kihlstrom, J.F., The person-situation interaction (2013) The Oxford Handbook of Social Cognition, pp. 786-805; Winkens, A., Rupprecht, T., Seyfried, A., Klingsch, W., Empirical study of pedestrians' characteristics at bottlenecks (2010) Pedestrian and Evacuation Dynamics 2008, pp. 263-268. , (Springer); Forell, B., Seidenspinner, R., Hosser, D., Quantitative comparison of international design standards of escape routes in assembly buildings 2010 (2008) Pedestrian and Evacuation Dynamics, pp. 791-801. , (Springer)","Hassan, F.H.; School of Computer Sciences, Malaysia; email: fadratul@usm.my",Wibowo F.W.,Hemispheres,Institute of Physics Publishing,"International Conference on Electronics Representation and Algorithm 2019, ICERA 2019",29 January 2019 through 30 January 2019,,148736,17426588,,,,English,J. Phys. Conf. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85067638748
"Mohamed A.S.A., Wahab M.N.A., Krishnan S.R., Arasu D.B.L.",57190968285;36471236100;57213595266;57207817920;,Facial recognition adaptation as biometric authentication for intelligent door locking system,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11870 LNCS,,,257,267,,2,10.1007/978-3-030-34032-2_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077907707&doi=10.1007%2f978-3-030-34032-2_24&partnerID=40&md5=b9b8b8f6caacfe5ddca2f8e13aafe27a,"School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia","Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia; Wahab, M.N.A., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia; Krishnan, S.R., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia; Arasu, D.B.L., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia","As field of technology grows, security issues have gained high concern nowadays. Unfortunately, a good access authentication is high in price which had become less affordable. To overcome this scenario, Intelligent Door Locking System is proposed. This system can be divided into 3 parts, which are mobile application, server with web application and microcontroller. The mobile application will be the one in charge of having face recognition process. The face recognition will be carried out using Eigenfaces Algorithm. Users can lock the door using “Normal Lock” mode or “Secure Lock” mode. To unlock the “Normal Lock” mode, user just need to press on unlock button, while to unlock “Se- cure Lock” mode, user would need to pass biometric authentication and passcode authentication process. Once user successfully identified by the mobile application, data will be sent to microcontroller via Bluetooth. At the same time, the microcontroller will retrieve data from server database and check whether the user is having access to enter the room. If yes, the microcontroller will unlock the door. While for the server, it can be easily managed by administration using web application. Users can check their door lock condition from far distance through web application as well. They can lock the door if they realize the door is not locked wherever they are. This bring convenience to the user. © Springer Nature Switzerland AG 2019.",Eigenfaces and smart lock; Face recognition; Intelligent locking system; Security,Authentication; Biometrics; Controllers; Locks (fasteners); Microcontrollers; Mobile computing; Access authentications; Biometric authentication; Eigenfaces; Facial recognition; Intelligent locking system; Mobile applications; Recognition process; Security; Face recognition,,,,,"University of Southern Maine, USM: PKOMP/6315262, PKOMP/8014001

Universiti Sains Malaysia","Acknowledgement. This research is funded under USM RU Grant (PKOMP/8014001) and partly under USM Short Term Grant (PKOMP/6315262) and affiliated with Robotics, Computer Vision & Image Processing (RCVIP) Research Group Lab at School of Computer Sciences, Universiti Sains Malaysia.",,"Soyata, T., Muraleedharan, R., Funai, C., Kwon, M., Heinzelman, W., Cloud-vision: Real-time face recognition using a mobile-cloudlet-cloud acceleration architecture (2012) 2012 IEEE Symposium on Computers and Communications (ISCC), pp. 59-66. , Cappadocia, pp; Januzaj, Y., Luma, A., Januzaj, Y., Ramaj, V., Real time access control based on face recognition (2015) 2015 International Conference on Network Security & Computer Science, pp. 7-12. , Antalya, Turkey, pp; Young, A.W., Burton, A.M., Recognizing faces (2017) Curr. Dir. Psychol. Sci., 26 (3), pp. 212-217; Mesni, B., Authentication in door access control systems (2013) A Treatise on Electricity and Magnetism, 2, pp. 68-73. , http://kintronics.blogspot.my/2013/04/authentication-in-door-access-control.html, Clerk Maxwell, J. (ed.), 3rd edn., pp., Clarendon, Oxford; Joseph, J., Zacharia, K.P., Automatic attendance management system using face recognition (2013) Int. J. Sci. Res. (IJSR), 2 (11), pp. 327-330; Turk, M.A., Pentland, A.P., Face recognition using eigenfaces (1991) Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 586-591. , pp; Chintalapati, S., Raghunadh, M.V., Automated attendance management system based on face recognition algorithms (2013) 2013 IEEE International Conference on Computational Intelligence and Computing Research, Enathi, pp. 1-5. , pp; Dave, G., Chao, X., Sriadibhatla, K., Face Recognition in Mobile Phones, pp. 1-7. , https://stacks.stanford.edu/file/druid:rz261ds9725/Sriadibhatla_Davo_Chao_FaceRecognition.pdf, Department of Electrical Engineering, Stanford University, Stanford, USA, pp; Saini, R., Saini, A., Agarwal, D., Analysis of different face recognition algorithms (2014) Int. J. Eng. Res. Technol., 3 (11), pp. 1263-1267; Pabbaraju, A., Puchakayala, S., (2010) Face Recognition in Mobile Devices, pp. 1-9. , https://pdfs.semanticscholar.org/cc20/0b665f6c446747a48d01e89f6b1e7d7781d4.pdf, Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, pp; Mohamed, A.S.A., Face recognition using eigenfaces (2006) MRG International Conference 2006, , Salford University, Manchester, United Kingdom, Poster Presentation; Turk, M., Pentland, A., Eigenfaces for recognition (1991) J. Cogn. Neurosci., 3 (1), pp. 71-86; Belhumeur, P.N., Hespanha, J.P., Kriegman, D.J., Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection (1997) IEEE Trans. Pattern Anal. Mach. Intell., 19 (7), pp. 711-719; Karande, K.J., Talbar, S.N., Simplified and modified approach for face recognition using PCA (2007) IET-UK International Conference on Information and Communication Technology in Electrical Sciences (ICTES 2007, pp. 523-526. , Dr. M.G.R. University, Chennai; Pissarenko, D., (2003) Eigenface-Based Facial Recognition, , http://openbio.sourceforge.net/resources/eigenfaces/eigenfaces-html/facesOptions.html; Zhao, W., Chellappa, R., Phillips, P.J., Rosenfeld, A., Face recognition: A literature survey (2003) ACM Comput. Surv., 35 (4), pp. 399-458","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",Badioze Zaman H.Mohamad Ali N.Ahmad M.N.Smeaton A.F.Shih T.K.Velastin S.Terutoshi T.,,Springer,"6th International Conference on Advances in Visual Informatics, IVIC 2019",19 November 2019 through 21 November 2019,,235609,3029743,9.78303E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85077907707
"Ab Wahab M.N., Mohamed A.S.A., Chung K.C.",36471236100;57190968285;57213590210;,iPassenger: Smart passenger analytics system,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11870 LNCS,,,465,476,,,10.1007/978-3-030-34032-2_41,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077861214&doi=10.1007%2f978-3-030-34032-2_41&partnerID=40&md5=7f75c2b2631152bbc49b569aae3af9fb,"School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia","Ab Wahab, M.N., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia; Chung, K.C., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang  11800, Malaysia","Automation with intelligence has gradually become the community’s talking point around the world. Nowadays, even public transportation such as bus is equipped with video surveillance cameras mainly for monitoring and security purposes. However, they can also be used for other purposes, such as analytics system through passengers counting. This is important to help the bus service provider to improve their fleet management operation by keep tracking of the passenger ridership information. Based on this information, the service provider company can be more flexible with bus scheduling by calculation of lines and stations efficiently. Hence, this paper proposed an analytics system through video footages acquired from daily operation. The incoming and outgoing passengers are tracked based on their head using blob detection and trained MobileNet SSD. The reference line is drawn to make sure that the detected passengers’ head crossed the line before it is considered either as incoming or outgoing passengers. Based on this video analysis, the number of passengers is counted concurrent with the location of the bus. This system is tested in several cases and managed to give proper information for the bus service provider. The data is stored in a cloud database for history, graphically visualize the passenger ridership in a day, month or year. Therefore, this system is able to help the bus company to manage their resource efficiently and consequently improving their service quality and lower the cost of transportation. © Springer Nature Switzerland AG 2019.",Analytics system; Blob detection; Fleet management; Passenger ridership; Passengers counting,Bus transportation; Buses; Security systems; Analytics systems; Blob detection; Fleet management; Passenger ridership; Passengers counting; Fleet operations,,,,,"University of Southern Maine, USM

Universiti Sains Malaysia: PKOMP/6315262, PKOMP/8014001","This research is a collaboration between School of Computer Sciences, USM with Rapid Penang Sdn. Bhd. and affiliated with Robotics, Computer Vision & Image Processing (RCVIP) Research Group Lab at School of Computer Sciences, Universiti Sains Malaysia. This project is fully funded by USM Short Term Grant (PKOMP/6315262) and partially funded by USM RU Grant (PKOMP/8014001).","Acknowledgments. This research is a collaboration between School of Computer Sciences, USM with Rapid Penang Sdn. Bhd. and affiliated with Robotics, Computer Vision & Image Processing (RCVIP) Research Group Lab at School of Computer Sciences, Universiti Sains Malaysia. This project is fully funded by USM Short Term Grant (PKOMP/6315262) and partially funded by USM RU Grant (PKOMP/8014001).","Allam, Z., Newman, P., Redefining the smart city: Culture, metabolism, and governance (2018) Smart Cities, 1 (1), pp. 4-25; Albino, V., Berardi, U., Dangelico, R.M., Smart cities: Definitions, dimensions, performance, and initiatives (2015) J. Urban Technol., 22 (1), pp. 1724-1738; Debnath, A.K., Chin, H.C., Haque, M.M., Yuen, B., A methodological framework for benchmarking smart transport cities (2014) Cities, 37, pp. 47-56; Sharaby, N., Shiftan, Y., The impact of fare integration on travel behavior and transit ridership (2012) Transp. Policy, 21, pp. 63-70; Gerland, H., McDonald, I., BCounted: Automatic people counting and people flow management at airports (2016) 15Th International Conference on Automated People Movers and Automated Transit Systems, pp. 74-81. , pp; Bonyár, A., Géczy, A., Harsanyi, G., Hanák, P., Passenger detection and counting inside vehicles for ecall-a review on current possibilities (2018) IEEE 24Th International Symposium for Design and Technology in Electronic Packaging (SIITME), pp. 221-225. , pp; Oberli, C., Landau, D., Performance evaluation of UHF RFID technologies for real-time passenger tracking in intelligent public transportation systems (2008) IEEE International Symposium on Wireless Communication Systems, pp. 108-112. , pp; Zhou, Z., Chen, B., Yu, H., Understanding rfid counting protocols (2016) IEEE/ACM Trans. Netw., 24 (1), pp. 312-327; Kulkarni, D.R., Kulkarni, S.H., Nalawade, P.B., Jagtap, S.P., Passenger counting in bus transport system: A review (2016) Int. J. Innov. Emerg. Res. Eng., 3 (3), pp. 101-103; Ferreira, M., de Gouveia, J., Facchini, E., Pokorny, M., Dias, E., Real-time monitoring of public transit passenger flows through Radio Frequency Identification-RFID technology embedded in fare smart cards (2012) Latest Trends Syst, 2, pp. 599-605; de Potter, P., Belet, P., Poppe, C., Verstockt, S., Lambert, P., van De Walle, R., Passenger counting in public rail transport-using head-shoulder contour tracking (2012) International Conference on Computer Vision Theory and Applications, pp. 705-708. , pp; Li, F., Yang, F., Liang, H., Yang, W., Automatic passenger counting system for bus based on RGB-D video (2016) Proceedings of the 2Nd Annual International Conference on Electronics, Electrical Engineering and Information Science (EEEIS 2016), pp. 209-220. , pp; Sojol, J.I., Piya, N.F., Sadman, S., Motahar, T., Smart bus: An automated passenger counting system (2018) Mathematics, 118 (18), pp. 3169-3177","Ab Wahab, M.N.; School of Computer Sciences, Malaysia; email: mohdnadhir@usm.my",Badioze Zaman H.Mohamad Ali N.Ahmad M.N.Smeaton A.F.Shih T.K.Velastin S.Terutoshi T.,,Springer,"6th International Conference on Advances in Visual Informatics, IVIC 2019",19 November 2019 through 21 November 2019,,235609,3029743,9.78303E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85077861214
"Mohamed A.S.A., Ab Wahab M.N., Suhaily S.S., Arasu D.B.L.",57190968285;36471236100;54384197200;57207817920;,Smart mirror design powered by raspberry Pi,2018,ACM International Conference Proceeding Series,,,,166,173,,2,10.1145/3299819.3299840,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062995332&doi=10.1145%2f3299819.3299840&partnerID=40&md5=a71f316475360fd59cb3bce7588ca710,"School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; School of Arts, Universiti Sains Malaysia, Penang, Malaysia","Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Ab Wahab, M.N., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Suhaily, S.S., School of Arts, Universiti Sains Malaysia, Penang, Malaysia; Arasu, D.B.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","The smart mirror projects consisting of observable mirror, microcontroller, camera and PC monitor. Existing smart projects are limited with features available and only displaying information based on command receiving directly from the user. To make this mirror to be smarter, artificial intelligence are added in this project. Facial expression detection will be implemented so that smart mirror is able to interact with user and recognize changes of the facial muscle. By accordingly to their expression, smart mirror will make decision to display related information. Only recognized user can utilize this smart mirror via face recognition. At end of the project, a working smart mirror is expected and have ability to become one of these connected devices in our households. © 2018 Association for Computing Machinery.",Artificial Intelligence; Face Recognition; Facial Expressions; Smart Mirror,Artificial intelligence; Cloud computing; Mirrors; Facial expression detections; Facial Expressions; Facial muscles; Mirror design; PC monitors; Smart projects; Face recognition,,,,,,,,"Ross Beveridge, B.J., Bolme, D., Draper, B.A., Teixeira, M., The CSU face identification evaluation system (2005) Machine Vision and Applications, 16 (2), pp. 128-138. , https://doi.org/10.1007/s00138-004-0144-7, 01 Feb 2005; Anwar Hossain, M., Smart mirror for ambient home environment (2007) IET Conference Proceedings, pp. 589-596. , January 2007, 7; Jin, K., Deng, X., Huang, Z., Chen, S., Design of the smart mirror based on raspberry Pi (2018) 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC), pp. 1919-1923. , https://doi.org/10.1109/IMCEC.2018.8469570; Jose, J., Chakravarthy, R., Jacob, J., Ali, M.M., Dsouza, S.M., Home automated smart mirror as an internet of things (IoT) implementation - Survey paper (2017) International Journal of Advanced Research in Computer and Communication Engineering, 6 (2), pp. 126-128. , February 2017; Khanna, V., Vardhan, Y., Nair, D., Pannu, P., Design and development of a smart mirror using raspberry Pi (2017) International Journal of Electrical, Electronics and Data Communication, 5, pp. 63-65. , 2017, 1; Lu, J., Plataniotis, K.N., Venetsanopoulos, A.N., Regularized discriminant analysis for the small sample size problem in face recognition (2003) Pattern Recogn. Lett., 24 (16), pp. 3079-3087. , https://doi.org/10.1016/S0167-8655(03)00167-3, 2003; Ok, F., Can, M., Smart mirror applications with raspberry Pi (2017) 2017 International Conference on Computer Science and Engineering (UBMK), pp. 94-98. , https://doi.org/10.1109/UBMK.2017.8093566, H. ÃIJÃğgÃijn, and U. YÃijzgeÃğ; Olivier, S.L., Porterfield, A.K., Wheeler, K.B., Prins, J.F., Scheduling task parallelism on multi-socket multicore systems (2011) Proceedings of the 1st International Workshop on Runtime and Operating Systems for Supercomputers (ROSS'11), pp. 49-56. , https://doi.org/10.1145/1988796.1988804, ACM, New York, NY, USA; Sun, Y., Geng, L., Dan, K., Design of smart mirror based on raspberry Pi (2018) 2018 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS), pp. 77-80. , https://doi.org/10.1109/ICITBS.2018.00028; Yusri, M.M., Kasim, S., Hassan, R., Abdullah, Z., Ruslai, H., Jahidin, K., Arshad, M.S., Smart mirror for smart life (2017) 2017 6th ICT International Student Project Conference (ICT-ISPC), pp. 1-5. , https://doi.org/10.1109/ICTISPC.2017.8075339; Zhao, W., Chellappa, R., Phillips, P.J., Rosenfeld, A., Face recognition: A literature survey (2003) ACM Comput. Surv., 35 (4), pp. 399-458. , https://doi.org/10.1145/954339.954342, Dec. 2003",,,,Association for Computing Machinery,"2018 International Conference on Artificial Intelligence and Cloud Computing, AICCC 2018",21 December 2018 through 23 December 2018,,145904,,9.78145E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85062995332
"Shanmugasundaram K., Mohamed A.S.A., Ruhaiyem N.I.R.",57193491154;57190968285;57190964192;,An overview of hand-based multimodal biometrie system using multi-classifier score fusion with score normalization,2018,"Proceedings of IEEE International Conference on Signal Processing and Communication, ICSPC 2017",2018-January,,,53,57,,6,10.1109/CSPC.2017.8305806,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046944218&doi=10.1109%2fCSPC.2017.8305806&partnerID=40&md5=0a40f31e5e64bca1e652f85cbf6d003d,"School of Computer Sciences, Universiti Sains Malaysia, USM, Penang, 11800, Malaysia","Shanmugasundaram, K., School of Computer Sciences, Universiti Sains Malaysia, USM, Penang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, USM, Penang, 11800, Malaysia; Ruhaiyem, N.I.R., School of Computer Sciences, Universiti Sains Malaysia, USM, Penang, 11800, Malaysia","In the emerging trends of biometrie authentication, multimodal biometries getting more attention from researchers due to its universality, uniqueness, no intra-class variations, no inter-class similarities, and anti-spoofing attacks than unimodal biometrics. Hand-based multibiometric system is the most successful and used in many real time systems especially law enforcement and forensics. Moreover, it is very user friendly and ease of use among all other biometric traits. Multi classifier fusion is the use of more classifiers for each modality involved rather than single at the score fusion of multibiometric system. Furthermore, hand-based multimodal biometrics can use either or all traits of fingerprint, palm print, finger vein, palm vein, dorsal vein, hand geometry, finger knuckle print and many more. In this paper, we reviewed various score normalization techniques and multi-classifiers used in the hand-based multimodal biometrics for each modality involved at the matching score fusion for enhancing the system performance further. © 2017 IEEE.",Multi-classifier; Multimodal biometrics; Score fusion,Biometrics; Interactive computer systems; Real time systems; Biometrie systems; Finger knuckle prints; Intra-class variation; Multi-classifier; Multi-modal biometrics; Multibiometric systems; Score fusion; Score normalization; Signal processing,,,,,,,,"Wozniak, M., A survey of multi-classifier as hybrid systems (2014) Information Fusion; Aravinth, J., Valarmathy, S., Multi classifier-based score level fusion of multi-modal biometric recognition and its application to remote biometrics authentication (2016) The Imaging Science Journal, 64 (1), pp. 1-14; Saigaa, M., (2014) Hand-based Biometric for Personal Identification Using Correlation Filter Classifier, , Taylor & Francis Group, LLC; Ramalho, M., Secure multispectral hand recognition system (2011) European Signal Processing Conference, Spain; Zhu, L.Q., (2010) Multimodal Biometric Identification System Based on Finger Geometry, Knuckle Print, and Palm Print, , pattern recognition letters; Peng, J., Multimodal biometric authentication based on score level fusion of finger biometrics (2014) Optik; Karthik, Score Level Fusion using Hybrid BF-pfPSO for Face and Fingerprint Multimodal Biometric System (2016) IEEE Conference Proceedings, ICECS; Bharathi, S., Hand Vein-based Multimodal Biometric Recognition (2015) Acta Polytechnica Hungarica, 12 (6); Sumathi, S., Multimodal Biometrics for Person Authentication using Hand Image (2013) Ijca, 70 (24). , May; Nandakumar, R.K., Jain, A.K., (2006) Handbook of Multibiometrics, , Springer, New York, USA, 1st edition; Esther, A multimodal biometric system based on palm print and finger knuckle print recognition methods (2015) An International Arab Journal of Information Technology, 12 (2). , March; Kumar, A., Personal authentication using finger knuckle surface (2009) IEEE Trans. Info. Forensics and Security, 4 (1), pp. 98-110. , March; Arulalan, V., Multimodal biometric system using iris and inner knuckle print (2014) Ijca, 106 (6). , Nov; Maltoni, D., (2009) Handbook of Fingerprint Recognition, , springer; Jain, A., Score normalization in multimodal biometric systems (2005) Pattern Recognition 38-2270-2285, , Elsevier; Cappelli, R., Combining fingerprint classifiers (2000) Proceedings of First International Workshop on Multiple Classifier Systems, pp. 351-361; Hampel, F.R., (1986) Robust Statistics: The Approach Based on Influence Functions, , Wiley, New York; Meroumia, A., Multimodal Biometric Person Recognition System Based on Fingerprint& Finger-Knuckle-Print Using Correlation Filter Classifier; Hanmandlu, M., Score level fusion of multimodal biometrics using triangular norms (2001) Pattern Recognition Letters","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",,,Institute of Electrical and Electronics Engineers Inc.,"2017 IEEE International Conference on Signal Processing and Communication, ICSPC 2017",28 July 2017 through 29 July 2017,,135075,,9.78151E+12,,,English,"Proc. IEEE Int. Conf. Signal Process. Commun., ICSPC",Conference Paper,Final,,Scopus,2-s2.0-85046944218
"Azlan Mohamed A.S., Soter E.B., Singh A., Raihana Ruhaiyem N.I.",57190968285;57201704699;57201699924;57201704161;,Gesture based help identification for hospital& elderlycare using dynamic time warping: A systematic study,2017,ACM International Conference Proceeding Series,,,,94,98,,,10.1145/3177404.3177426,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045831292&doi=10.1145%2f3177404.3177426&partnerID=40&md5=6809df7237e357161f2a64c9f73f4084,"School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","Azlan Mohamed, A.S., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Soter, E.B., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Singh, A., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Raihana Ruhaiyem, N.I., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","Recent advancement of depth imaging sensor technology can provide opportunities, especially in healthcare sector to improve the quality of life of the hospital patients and elderly care institutes by facilitating certain tasks without any assistant and enabling supportive ecosphere. This paper presents a novel hand gesture system via motion capture for appliance control in the hospital environment. A selection of hand gestures were prepared for the subject to perform with a set of questionnaires to learn the user acceptance towards this implementation with the adoption of dynamic time warping (DTW) algorithm for identifying the gestures. The results shown that gestures are easily performed by the patient to control specific tasks in a controlled environment. Most participants agreed that this system is easy to use and learn. The aim of this study is to evaluate the user experience on the proposed gesture setup and study the acceptance of the proposed hand gestures by the subjects. . © 2017 Association for Computing Machinery.",Dynamic Time Warping; Hand Gesture; Kinect; Recognition,Hospitals; Image processing; Palmprint recognition; Surveys; Video signal processing; Appliance controls; Controlled environment; Dynamic time warping; Dynamic time warping algorithms; Hand gesture; Hospital environment; Kinect; Recognition; Gesture recognition,,,,,Universiti Sains Malaysia: 304/PKOMP/6313259,The authors wish to thank Universiti Sains Malaysia for the support it has extended in the completion of the present research through Short Term University Grant No: 304/PKOMP/6313259.,,"Ahuja, M.K., Singh, A., Static vision based hand gesture recognition using principal component analysis (2015) IEEE 3rd International Conference on MOOCs. Innovation and Technology in Education (MITE), , October 1-2, 2015; Ann, O.C., Theng, L.B., Human activity recognition: A review (2014) IEEE International Conference on Control System, Computing and Engineering, pp. 389-393. , November 28-30, 2014; Argoty, J.A., Figueroa, P., Design and development of a prototype of an interactive hospital room with kinect (2014) Proceedings of The 15th International Conference on Human Interaction, , Spain, September 10-12, 2014; Athavale, S., Deshmukh, M., Dynamic hand gesture recognition for human computer interaction: A comparative study (2014) International J. of Engineering Research and General Science, 2 (2), pp. 38-55. , February – March, 2014; Bharambe, A., Chanekar, D., Naik, D., Vitekar, A.B., Automatic hand gesture based remote control for home appliances (2015) International J. of Advanced Research in Computer Science and Software Engineering, 5 (2), pp. 567-571; Bonechere, B., Jansen, B., Salvia, P., Bouzahouene, H., Omelina, L., Cornelis, J., Rooze, M., Jan, S.V.S., Can the Kinect sensors be used for motion analysis? (2014) Trans. On Electrical and Electronic Circuits and Systems., 4 (1), pp. 1-6; Chen, Z.H., Kim, J.T., Liang, J., Zhang, J., Yuan, Y.B., Real-time hand gesture recognition using finger segmentation (2014) The Scientific World J; Dan, R.B., Mohod, P.S., Survey on hand gesture recognition approaches (2012) International J. of Computer Science and Information Technologies, 5 (2), pp. 2050-2052; Ganzeboom, M., How hand gestures are recognized using data glove (2010) Human Media Interaction (HMI); Hernandez, J., Mcduff, D.J., Picard, R.W., Bioinsights Extracting personal data from “Still” wearable motion sensors (2015) Proceeding IEEE 12th International Conference Wearable Implantable Body Sensor Network, , June 9-12, 2015; Jacob, M.G., Li, Y.T., Akingba, G.A., Wachs, Collaboration with a robotic scrub nurse (2013) Commun. ACM, 56 (5), pp. 68-75. , May. 2013; Jyothilakshmi, P., Rekha, K.R., Natraj, K.R., Implementation of a smart ward system in a hi-tech hospital by using a kinect sensor camera (2016) International J. on Recent and Innovation Trends in Computing and Comun, 4 (5), pp. 531-536; Jyothilakshmi, P., Rekha, K.R., Natraj, K.R., Patient assistance system in a super specialty hospital using a kinect sensor camera 2016 (2016) International Conference on Electrical, Electronics, and Optimization Techniques, , March 3-5; Kelly, P., Marshall, S.J., Badland, H., Kerr, J., Oliver, M., Doherthy, A.R., Foster, C., An ethical framework for automated, wearable cameras in health behavior research (2013) American J. of Preventive Medicine., 44, pp. 314-319; Kumar, P., Verma, J., Prasad, S., Hand data glove: A wearable real-time device for human computer interaction (2012) International J. of Advanced Science and Technology., 43, pp. 15-26. , June, 2012; Murthy, G.R.S., Jadon, R.S., A review of vision based hand gestures recognition (2009) International J. of Information Technology and Knowledge Management, 12 (2), pp. 405-410. , July-December,2009; Ni, B., Da, N.C., Moulin, P., RGBD-camera based get-up event detection for hospital fall prevention (2000) Proceedings of International Conference on Acoustics, Speech, and Signal Process, pp. 1405-1408; Ren, Z., Yuan, J., Zhang, Z., Robust hand gesture recognition based on finger-earth mover’s distance with a commodity depth camera (2011) Proceedings of The 19thInternational Conference on Multimedia, pp. 1093-1096. , ACM; Riemen, R., The sensors behind the apple watch (2015) Electrical Engineering Community; Rosli, L., What happens when Malaysia enters ageing nation status in 2030? (2016) New Straits Times Press (M) Berhad, , 10 January 2018; Samad, S.A., Mansor, N., Population ageing and social protection in Malaysia (2013) Malaysia J. of Economic Studies., pp. 139-156; Solanki, U.V., Desai, N., Hand gesture based remote control for home appliances: Handmote (2011) World Congress on Information and Commun. Technologies., pp. 419-423; Sonkusare, J.S., Chopade, N.B., Sor, R., Tade, S.L., A review on hand gesture recognition system (2015) International Conference on Computing Communication Control and Automation, , February 26-27, 2015; Wachs, J.P., Kolsch, M., Stern, H., Edan, Y., Vision- Based hand gesture applications (2011) ACM Commun, 54 (2), pp. 60-71. , February,2011; Weng, C., Li, Y., Zhang, M., Guo, K., Tang, X., Pan, Z., Robust hand posture recognition integrating multi-cue hand tracking (2010) International Conference on Technologies for E-Learning and Digital Entertainment, 6249, pp. 497-508",,,Nanyang Technological University,Association for Computing Machinery,"2017 International Conference on Video and Image Processing, ICVIP 2017",27 December 2017 through 29 December 2017,,135440,,9.78145E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85045831292
"Pearson S.J., Mohammed A.S.A., Hussain S.R.",7201386436;57190968285;55860068900;,Patellar tendon in vivo regional strain with varying knee angle,2017,Journal of Biomechanics,61,,,45,50,,9,10.1016/j.jbiomech.2017.06.038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025440777&doi=10.1016%2fj.jbiomech.2017.06.038&partnerID=40&md5=71454dea2c414daae602708766ce8dbb,"Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Greater Manchester, United Kingdom; School of Computer Sciences, Universiti Sains Malaysia (USM)Penang  11800, Malaysia","Pearson, S.J., Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Greater Manchester, United Kingdom; Mohammed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia (USM)Penang  11800, Malaysia; Hussain, S.R., Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Greater Manchester, United Kingdom","Purpose Descriptive data on the aspects of site specific in vivo tendon strain with varying knee joint angle are non-existent. The present study determines and compares surface and deep layer strain of the patellar tendon during isometric contractions across a range of knee joint angles. Methods Male participants (age 22.0 ± 3.4) performed ramped isometric knee extensions at knee joint angles of 90°, 70°, 50° and 30° of flexion. Strain patterns of the anterior and posterior regions of the patellar tendon were determined using real-time B-mode ultrasonography at each knee joint angle. Regional strain measures were compared using an automated pixel tracking method. Results Strain was seen to be greatest for both the anterior and posterior regions with the knee at 90° (7.76 ± 0.89% and 5.06 ± 0.76%). Anterior strain was seen to be significantly greater (p < 0.05) than posterior strain for all knee angles apart from 30°, 90° = (7.76 vs. 5.06%), 70° = (4.77 vs. 3.75%), and 50° = (3.74 vs. 2.90%). The relative strain (ratio of anterior to posterior), was greatest with the knee joint angle at 90°, and decreased as the knee joint angle reduced. Conclusions The results from this study indicate that not only are there greater absolute tendon strains with the knee in greater flexion, but that the knee joint angle affects the regional strain differentially, resulting in greater shear between the tendon layers with force application when the knee is in greater degrees of flexion. These results have important implications for rehabilitation and training. © 2017",Isometric; Knee extension; Localised strain; Patella; Tendon,"Joints (anatomy); Physiological models; Strain; Force application; Isometric; Isometric contractions; Knee extension; Knee-joint angle; Localised; Patella; Patellar Tendon; Tendons; accident prevention; adult; algorithm; Article; cross-sectional study; echography; human; human experiment; in vivo study; knee function; knee joint angle; male; muscle isometric contraction; muscle strain; musculoskeletal system parameters; normal human; patellar ligament; priority journal; reliability; statistics; young adult; anatomy and histology; biomechanics; joint characteristics and functions; knee; mechanical stress; patella; physiology; tendon; Biomechanical Phenomena; Humans; Isometric Contraction; Knee; Male; Patella; Range of Motion, Articular; Stress, Mechanical; Tendons; Young Adult",,,,,,,,"Aalbersberg, S., Kingma, I., Ronsky, J.L., Frayne, R., van Dieen, H.J., Orientation of tendons in vivo with active and passive knee muscles (2005) J. Biomech., 38, pp. 1780-1788; Almekinders, L.C., Tendinitis and other chronic tendinopathies (1998) J. Am. Acad. Orthop. Surg., 6, pp. 157-164; Almekinders, L.C., Vellema, J.H., Weinhold, P.S., Strain patterns in the patellar tendon and the implications for patellar tendinopathy (2002) Knee Surg Sports Traumatol Arthrosc., 10 (1), p. 2; Arndt, A., Bengtsson, A.S., Peolsson, M., Thorstensson, A., Movin, T., Non-uniform displacement within the Achilles tendon during passive ankle joint motion (2012) Knee Surg Sports Traumatol Arthrosc., 20 (9), pp. 1868-1874; Astrom, M., Rausing, A., Chronic Achilles tendinopathy: a survey of surgical and histopathological findings (1995) Clin. Orthop., 316, pp. 151-164; Basso, O., Amis, A.A., Race, A., Johnson, D.P., Patellar tendon fiber strains: their differential responses to quadriceps tension (2002) Clin. Orthop. Relat. Res., 400, pp. 246-253; Carolan, B., Cafarelli, E., Adaptations in coactivation after isometric resistance training (1992), J. Appl. Physiol. (1985) 73(3), 911–917; DeFrate, L.E., Wook Nha, K., Papannagari, R., Moses, J.M., Gill, T.J., Li, G., The Biomechanical function of the patellar tendon during in-vivo weight-bearing flexion (2007) J. Biomech., 40 (8), pp. 1716-1722; Dillon, E.M., Erasmus, P.J., Müller, J.H., Scheffer, C., de Villiers, R.V., Differential forces within the proximal patellar tendon as an explanation for the characteristic lesion of patellar tendinopathy: an in vivo descriptive experimental study (2008) Am. J. Sports Med., 36 (11), pp. 2119-2127; Hansen, P., Bojsen-Moller, J., Aagaard, P., Kjaer, M., Magnusson, S.P., Mechanical properties of the human patellar tendon, in vivo (2006) Clin Biomech (Bristol, Avon), 21 (1), pp. 54-58; Hansen, P., Haraldsson, B.T., Aagaard, P., Kovanen, V., Avery, N.C., Qvortrup, K., Larsen, J.O., Magnusson, S.P., Lower strength of the human posterior patellar tendon seems unrelated to mature collagen cross-linking and fibril morphology (2010) J. Appl. Physiol., 108 (1), pp. 47-52; Haraldsson, B.T., Aagaard, P., Krogsgaard, M., Alkjaer, T., Kjaer, M., Magnusson, S.P., Region-specific mechanical properties of the human patella tendon (2010) J. Appl. Physiol., 98 (3), pp. 1006-1012; Hermens, H.J., Freriks, B., Merletti, R., Hägg, G., Stegeman, D., Blok, J., Web Of Science, February 10, 2017. Times Cited. (Eds.); Herring, S.A., Nilson, K.L., Introduction to overuse injuries (1987) Clin. Sports Med., 6, pp. 225-239; Ilfeld, F.W., Can stroke modification relieve tennis elbow? (1992) Clin. Orthop., 276, pp. 182-186; James, S.L., Running injuries to the knee (1995) J. Am. Acad. Orthop. Surg., 3, pp. 309-318; Kader, D., Saxena, A., Movin, T., Maffulli, N., Achilles tendinopathy: some aspects of basic science and clinical management (2002) Br. J. Sports Med., 36, pp. 239-249; Kibler, W.B., Chandler, T.J., Pace, B.K., Principles of rehabilitation after chronic tendon injuries (1992) Clin. Sports Med., 11, pp. 661-671; Korkia, P.K., Tunstall-Pedoe, D.S., Mafulli, N., An epidemiologic investigation of training and injury patterns in British triathletes (1994) Br. J. Sports Med., 28, pp. 191-196; Krevolin, J.L., Pandy, M.G., Pearce, J.C., Moment arm of the patellar tendon in the human knee (2004) J. Biomech., 37 (5), pp. 785-788; Leadbetter, W.B., Cell-matrix response in tendon injury (1992) Clin. Sports Med., 11, pp. 533-578; Lersch, C., Grotsch, A., Segesser, B., Koebke, J., Bruggemann, G.P., Potthast, W., Influence of calcaneus angle and muscle forces on strain distribution in the human Achilles tendon (2012) Clin. Biomech. (Bristol, Avon), 27 (9), pp. 955-961; Lippold, O.C., The relationship between integrated action potentials in a human muscle and its isometric tension (1952) J. Physiol., 177, pp. 492-499; Maffulli, N., Kader, D., Tendinopathy of tendo Achillis (2002) J. Bone Joint Surg. Br., 84, pp. 1-8; Malliaras, P., Kamal, B., Nowell, A., Farley, T., Dhamu, H., Simpson, V., Morrissey, D., Reeves, N.D., Patellar tendon adaptation in relation to load-intensity and contraction type (2013) J. Biomech., 46, pp. 1893-1899; Orchard, J.W., Cook, J.L., Halpin, N., Stress-shielding as a cause of insertional tendinopathy: the operative technique of limited adductor tenotomy supports this theory (2004) J. Sci. Med. Sport., 7 (4), pp. 424-428; Pearson, S.J., Onambele, G.N., Influence of time of day on tendon compliance and estimations of voluntary activation levels (2006) Muscle Nerve, 33 (6), pp. 792-800; Pearson, S.J., Ritchings, T., Mohamed, A.S., Regional strain variations in the patellar tendon (2014) Med. Sci. Sports Exerc., 46 (7), pp. 1343-1351; Regan, W., Wold, L.E., Coonrad, R., Mircroscopic histopathology of chronic refractory lateral epicondylitis (1992) Am. J. Sports Med., 20, pp. 746-749; Richards, D.P., Ajemian, S.V., Wiley, J.P., Zernicke, R.F., Knee joint dynamics predict patellar tendinitis in elite volleyball players (1996) Am. J. Sports Med., 24, pp. 676-683; Riley, G., Tendinopathy: from basic science to treatment (2008) Nat. Clin. Pract. Rheumatol., 4, pp. 82-89; Rufai, A., Ralphs, J.R., Benjamin, M., Structure and histopathology of the insertional region of the human Achilles tendon (1995) J. Orthop. Res., 13, pp. 585-593; Tsaopoulos, D.E., Baltzopoulos, V., Maganaris, C.N., Human patellar tendon moment arm length: measurement considerations and clinical implications for joint loading assessment (2006) Clin. Biomech. (Bristol, Avon), 21 (7), pp. 657-667; van der Worp, H., Zwerver, J., Kuijer, P.P., The impact of physically demanding work of basketball and volleyball players on the risk for patellar tendinopathy and on work limitations (2011) Back Musculoskelet Rehabil., 24 (1), pp. 49-55; Visnes, H., Tegnander, A., Bahr, R., Ultrasound characteristics of the patellar and quadriceps tendons among young elite athletes (2014) Scand. J. Med. Sci. Sports, 24; Vogel, K.G., Ordog, A., Pogany, G., Proteoglycans in the compressed region of the human tibialis posterior tendon and in ligaments (1993) J. Orthop. Res., 11, pp. 68-77; Ward, T.R., Pandit, H., Hollinghurst, D., Zavatsky, A.B., Gill, H.S., Thomas, N.P., Murray, D.W., A low-riding patella in posterior stabilised total knee replacements alters quadriceps' mechanical advantage, resulting in reduced knee flexion moments (2012) Knee, 19 (4), pp. 299-305; Wearing, S.C., Hooper, S.L., Purdam, C., Cook, J., Grigg, N., Locke, S., Smeathers, J.E., The acute transverse strain response of the patellar tendon to quadriceps exercise (2013) Med. Sci. Sports Exerc., 45 (4), pp. 772-777; Zwerver, J., Bredeweg, S.W., van den Akker-Scheek, I., Prevalence of Jumper's knee among nonelite athletes from different sports: a cross-sectional survey (2011) Am. J. Sports Med., 39 (9), pp. 1984-1988","Pearson, S.J.; Centre for Health, United Kingdom; email: s.pearson@salford.ac.uk",,,Elsevier Ltd,,,,,219290,,JBMCB,28736078,English,J. Biomech.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85025440777
"Sukri S.S., Ruhaiyem N.I.R., Mohamed A.S.A.",57197836300;57190964192;57190968285;,Face recognition with real time eye lid movement detection,2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10645 LNCS,,,352,363,,1,10.1007/978-3-319-70010-6_33,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035149981&doi=10.1007%2f978-3-319-70010-6_33&partnerID=40&md5=ac5ac86118d32da08b3b5b89e5155c08,"School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia","Sukri, S.S., School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia; Ruhaiyem, N.I.R., School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia","The enhancement of current face recognition system used in attendance system is proposed to fulfill the motivations for this project which are to encounter the shortcomings from the existing systems, to put an innovation into the existing system and to make the system smarter by using real-time functionality. There are three objectives in this project which are to make the system able to differentiate between real face and a photo, to make the system works on desired speed and important key is to make a user-friendly system in term of its interface and functions. Techniques that will be used to achieve the objectives are by using average standard deviation of depth or pulse magnification, using JAVA programming language and develop using simple and standard user interface components and functions. At the end, this system is expected to fulfill the objectives stated and can encounter the problem arise in existing system. As the conclusion, there is no perfect system and still need to be enhanced from time to time. © Springer International Publishing AG 2017.",Attendance system; Face recognition system; Innovation; Real-time,Computer programming; Eye movements; Innovation; Real time systems; User interfaces; Attendance systems; Desired speed; Existing systems; Face recognition systems; Movement detection; Real time; Standard deviation; User interface components; Face recognition,,,,,Universiti Sains Malaysia: 304/PKOMP/6313259,Acknowledgments. The authors wish to thank Universiti Sains Malaysia for the support it has extended in the completion of the present research through Short Term University Grant No: 304/PKOMP/6313259.,,"Cornelissen, F., Peters, E., Palmer, J., The Eyeblink Toolbox: Eye tracking with MATLAB and the Psychophysics Toolbox (2002) Behav. Res. Methods Instrum. Comput., 34 (4), pp. 613-617; How Often and Why Do people’s Eyes Blink? - the Boston Globe, , http://archive.boston.com/news/science/articles/2007/05/14/how_often_and_why_do_peoples_eyes_blink/; NEC Corporation of Malaysia Introduces Neoface® Facial Recognition Solutions for the First Time in Malaysia, , http://sg.nec.com/en_AP/press/201408/ap_20140812_01.html; (2016), http://www.biometric-solutions.com/software/reviews.php?story=keylemon, Biometric-solutions.com; Makwana, H., Singh, T., Comparison of different algorithm for face recognition (2013) Glob. J. Comput. Sci. Technol. Graph. Vis., 13 (9), p. 17; Ahonen, T., Hadid, A., Pietikäinen, M., Face recognition with local binary patterns (2004) ECCV 2004. LNCS, 3021, pp. 469-481. , Pajdla, T., Matas, J. (eds.), Springer, Heidelberg; Singh, A., Comparison of face recognition algorithms on dummy faces (2012) Int. J. Multimed. Appl., 4 (4), pp. 121-135; Mohamed, A.S.A., Ritchings, T., Pearson, S., Image tracking using normalized cross-correlation to track and analyse mechanical tendon properties (2011) Proceedings of the Salford Postgraduate Annual Research Conference (SPARC 2011), 2, pp. 10-11. , Manchester, United Kingdom; Shanmugasundaram, K., Mohamed, A.S.A., Venkat, I., An overview of multimodal biometrics using meta-heuristic optimization techniques for F2R system (2015) Int. J. Soft Comput. Eng. (IJSCE, 5 (5); Ruhaiyem, N.I.R., Mohamed, A.S.A., Belaton, B., Optimized segmentation of cellular tomography through organelles’ morphology and image features (2016) J. Telecommun. Electron. Comput. Eng. (JTEC), 8 (3), pp. 79-83; Halim, M.A.A., Ruhaiyem, N.I.R., Fauzi, E.R.I., Mohamed, A.S.A., Automatic laser welding defect detection and classification using sobel-contour shape detection (2016) J. Telecommun. Electron. Comput. Eng. (JTEC), 8 (6), pp. 157-160; Veeraputhara Thevar, V., Ruhaiyem, N.I.R., (2016) Concept, Theory and Application: Hybrid Watershed Classic and Active Contour for Enhanced Image Segmentation, , The Visual Informatics International Seminar, Bangi, Selangor; Ruhaiyem, N.I.R., Semi-automated cellular tomogram segmentation workflow (CTSW): Towards an automatic target-scoring system (2014) Proceedings of the International Conference on Computer Graphics, Multimedia and Image Processing, pp. 38-48. , Kuala Lumpur, Malaysia; Ruhaiyem, N.I.R., Boundary-based versus region-based approaches for cellular tomography segmentation (2014) Proceedings of 1St International Engineering Conference, pp. 260-267. , Erbil, Iraq; Ruhaiyem, N.I.R., (2014) Multiple, Object-Oriented Segmentation Methods of Mammalian Cell Tomograms, , Ph.D. thesis, Institute for Molecular Bioscience, The University of Queensland","Ruhaiyem, N.I.R.; School of Computer Sciences, Malaysia; email: intanraihana@usm.my",Shih T.K.Velastin S.Robinson P.Smeaton A.F.Terutoshi T.Badioze Zaman H.Jaafar A.Mohamad Ali N.,,Springer Verlag,"5th International Visual Informatics Conference, IVIC 2017",28 November 2017 through 30 November 2017,,205759,3029743,9.78332E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85035149981
"Mohamed A.S.A., Chingeng P.S., Mat Isa N.A., Surip S.S.",57190968285;57197832344;6603297760;57192173209;,Body matching algorithm using normalize dynamic time warping (NDTW) skeleton tracking for traditional dance movement,2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10645 LNCS,,,669,680,,,10.1007/978-3-319-70010-6_62,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035135801&doi=10.1007%2f978-3-319-70010-6_62&partnerID=40&md5=8dc415760e01c20cbb444fa60b3576c1,"School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Malaysia; School of the Arts, Universiti Sains Malaysia, Gelugor, Malaysia","Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Malaysia; Chingeng, P.S., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Malaysia; Mat Isa, N.A., School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Malaysia; Surip, S.S., School of the Arts, Universiti Sains Malaysia, Gelugor, Malaysia","Traditional dance in Malaysia is generating considerable amount of interest due to its unique elements of heritage which have contributed to its diverse music and dance forms. For example, Zapin, Kuda Kepang, Mak Yong, Joget, Ngajat and much more. Recent developments in technology and ever- growing online community, traditional dance are undergoing a revolution where these dance form can be studied and observed easily especially when there are dance software that can help guide users to learn by performing the dance steps in real-time. However, the use of gesture sensor for accurately mapping the dance movements of traditional dance is not yet explored, since only modern dances are normally available to the masses in the form of computer games. This paper outlines a new approach to implement Normalize Dynamic Time Warping (NDTW) algorithm using skeleton tracking techniques to imitate the intricate movements of traditional dance and to assess the robustness of the algorithm. For this study, the traditional dance of Zapin was chosen because it consists of simple body movements and data were acquired using Microsoft Kinect. The results showed that the proposed algorithm gave the overall matching rate of 99.21% with maximum mean success rate of dancers gave 99.68% and non-dancers gave the percentage of 98.76%. This technique may be considered as a relatively unexplored application area, and the proposed system is an attempt to address the problem with reasonable accuracy and scopes for further research. © Springer International Publishing AG 2017.",Body matching; Kinect; Motion capture; Skeleton tracking; Traditional dance,Computer games; Body matching; Dynamic time warping; Kinect; Motion capture; On-line communities; Reasonable accuracy; Tracking techniques; Traditional dance; Musculoskeletal system,,,,,"Universiti Sains Malaysia, USM: 304/PKOMP/6313280",Acknowledgements. The author wish to thank Universiti Sains Malaysia for the support it has extended in the completion of the present research through Short Term University Grant No. 304/PKOMP/6313280.,,"Alexiadis, D.S., Kelly, P., Daras, P., O’Connor, N.E., Boubekeur, T., Moussa, M.B., Evaluating a dancer’s performance using kinect-based skeleton tracking (2011) ACM International Conference on Multimedia, pp. 659-662. , ACM, New York; Brodd-Reijer, C., (2012) Dance Quantification with Kinect: Adjusting Music Volume by Using Depth Data from a Kinect Sensor; Carmona, J.M., Climent, J., A performance evaluation of HMM and DTW for gesture recognition (2012) CIARP 2012. LNCS, 7441, pp. 236-243. , Alvarez, L., Mejail, M., Gomez, L., Jacobo, J. (eds.), Springer, Heidelberg; Correa, D.S., Sciotti, D.F., Prado, M.G., Mobile robots navigation in indoor environments using kinect sensor (2012) Second Brazilian Conference on Critical Embedded Systems (CBSEC), pp. 36-41. , Brazil; Csaba, G., Somlyai, L., Vámossy, Z., Differences between kinect and structured lighting sensor in robot navigation (2012) 2012 IEEE 10Th International Symposium Applied Machine Intelligence and Informatics (SAMI), pp. 85-90. , Herl’any, Slovakia; Essid, S., Alexiadis, D., Tournemenne, R., Gowing, M., Kelly, P., Monaghan, D., Daras, P., O’Connor, N.E., An advanced virtual dance performance evaluator (2012) 2012 IEEE International Conference Acoustics, Speech and Signal Processing (ICASSP), , Kyoto, Japan; Gowing, M., Kell, P., O’Connor, N.E., Concolato, C., Essid, S., Lefeuvre, J., Zhang, Q., Enhanced visualisation of dance performance from automatically synchronised multimodal recordings (2011) MM International Multimedia Conference, pp. 667-670. , ACM, New York; Hani, B.-S., Clinton, J., Evaluating the effect of 3D world integration within a social software environment (2015) 2015 12Th International Conference Information Technology -New Generations (ITNG), pp. 255-260. , Las Vegas, NV, USA; Higinio, G., Riveiro, B., Esteban, V.-F., Martinez-Sanchez, J., Pedro, A., Metrological evaluation of microsoft kinect and asus xtion sensors (2013), pp. 1800-1806; Hu, M.-C., Chen, C.-W., Cheng, W.-H., Chang, C.-H., Lai, J.-H., Wu, J.-L., Real-time human movement retrieval and assessment with kinect sensor (2014) IEEE Trans. Cybern, pp. 742-753; Huang, C.-H., Boyer, E., Ilic, S., Robust human body shape and pose tracking (2013) International Conference on 3D Vision, pp. 287-294. , Washington, DC, USA; Jia, W., Won-Jae, Y., Jafar, S., Erdal, O., 3D image reconstruction and human body tracking using stereo vision and kinect technology (2012) 2012 IEEE International Conference Electro/Information Technology (EIT, , Indianapolis, IN, USA. IEEE; Jo, H., Yu, H., Kim, K., Sung, J.H., Motion tracking system for multi-user with multiple kinects (2015) Int. J. U-And E-Serv. Sci. Technol., pp. 99-108; Kar, R., Konar, A., Chakraborty, A., Dance composition using microsoft kinect (2015) Transactions on Computational Science XXV. LNCS, 9030, pp. 20-34. , Gavrilova, M.L., Tan, C.J.K., Saeed, K., Chaki, N., Shaikh, S.H. (eds.), Springer, Heidelberg; Adistambha, K., Ritz, C.H., Burnett, I.S., Motion classification using dynamic time warping (2008) 2008 IEEE 10Th Workshop on Multimedia Signal Processing, , Australia. IEEE; Kitsikidis, A., Dimitropoulos, K., Douka, S., Grammalidis, N., Dance analysis using multiple Kinect sensors (2014) Computer Vision Theory and Applications (VISAPP), pp. 789-795; Kyan, M., Sun, G., Li, H., Zhong, L., Muneesawang, P., Dong, N., Guan, L., An approach to ballet dance training through MS kinect and visualization in a cave virtual reality environment (2015) ACM Trans. Intell. Syst. Technol. (TIST), 623. , Special Section on Visual Understanding with RGB-D Sensors. ACM, New York, NY, USA; Marija, M., Mile, J., Darko, M., Analysis of the problem of Macedonian folk dance recognition (2013) Conference for Informatics and Information Technology; Martin, C.C., Burkert, D.C., Choi, K.R., A real-time ergonomic monitoring system using the microsoft kinect (2012) Systems and Information Symposium (SIEDS, pp. 50-55; Mohamed, A., Surip, S., Real-time interactive cultural dance with gesture gaming elements via kinect-based skeleton tracking (2016) 6Th International Conference on Local Knowledge (ICLK, pp. 385-391; Moran, A., Kamhi, G., Popov, A., Groscot, R., (2015) Introducing Intel® RealSense™. Robotics Innovation Program, , http://roscon.ros.org/2015; Nazeeh, A., Khan, A., Alnowaimi, M., Morfeq, A.H., Ehab, A.H., (2014) Accuracy of Joint Angles Tracking Using Markerless Motion System; Papadopoulos, G.T., Axenopoulos, A., Daras, P., Real-time skeleton-tracking-based human action recognition using kinect data (2014) MMM 2014. LNCS, 8325, pp. 473-483. , Gurrin, C., Hopfgartner, F., Hurst, W., Johansen, H., Lee, H., O’Connor, N. (eds.), Springer, Cham; Park, H., Lee, J., Bae, J., Development of a dance rehabilitation system using kinect and a vibration feedback glove (2015) 2015 15Th International Conference Control, Automation and Systems (ICCAS, , Busan, South Korea; Pohl, H., Hadjakos, A., Dance pattern recognition using dynamic time warping (2010) Sound and Music Computing; Raptis, M., Kirovski, D., Hoppe, H., Real-time classification of dance gestures from skeleton animation (2011) Symposium on Computer Animation, pp. 147-156. , ACM, New York; Schulz, S., Woerner, A., Automatic motion segmentation for human motion synthesis (2010) AMDO 2010. LNCS, 6169, pp. 182-191. , Perales, F.J., Fisher, R.B. (eds.), Springer, Heidelberg; Sungphill, M., Youngbin, P., Wook, K.D., Hong, S.I., Multiple kinect sensor fusion for human (2015) Int. J. Adv. Robot. Syst.; Tang, J.K., Chan, J.C., Leung, H., Interactive dancing game with real-time recognition of continuous dance moves from 3D human motion capture (2011) International Conference on Ubiquitous Information Management and Communication, p. 50. , ACM, New York; Vantigodi, S., Radhakrishnan, V.B., Action recognition from motion capture data using meta-cognitive RBF network classifier (2014) 2014 IEEE Ninth International Conference Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP, pp. 1-6. , Singapore; Wang, Q., Kurillo, G., Ofli, F., Bajcsy, R., Evaluation of pose tracking accuracy in the first and second generations of microsoft kinect (2015) Healthcare Informatics, pp. 380-389; Yang, Y., Leung, H., Deng, L., Automatic dance lesson generation (2011) IEEE Trans. Learn. Technol., pp. 191-198; (2016), http://archive.boston.com/news/science/articles/2007/05/14/how_often_and_why_do_peoples_eyes_blink/, The Boston Globe. Archive.boston.com; (2016), http://sg.nec.com/en_AP/press/201408/ap_20140812_01.html, NEC Corporation of Malaysia introduces Neoface® facial recognition solutions for the first time in Malaysia. Sg.nec.com; (2016), http://www.biometric-solutions.com/software/reviews.php?story=keylemon, Review: KeyLemon, Biometric-solutions.com, Accessed 8 Oct 2016; Makwana, H., Singh, T., Comparison of different algorithm for face recognition (2013) Global J. Comput. Sci. Technol. Graph. Vis, 13 (9); Ahonen, T., Hadid, A., Pietikäinen, M., Face recognition with local binary patterns (2004) ECCV 2004. LNCS, 3021, pp. 469-481. , Pajdla, T., Matas, J. (eds.), Springer, Heidelberg; Singh, A., Comparison of face recognition algorithms on dummy faces (2012) Int. J. Multimed. Appl., 4 (4), pp. 121-135; Muhammad, M.A.N., Ruhaiyem, N.I.R., Mohamed, A.S.A., Keeping curiosity in local historical knowledge alive by sensor based simulation game using flash actionscript 3 (2016) Proceedings of the International Conference Local Knowledge; Ravi, P.L., Ruhaiyem, N.I.R., Intelligent gameplay for improved retro games (2016) J. Telecommun. Electron. Comput. Eng. (JTEC), 8 (6), pp. 23-26","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",Shih T.K.Velastin S.Robinson P.Smeaton A.F.Terutoshi T.Badioze Zaman H.Jaafar A.Mohamad Ali N.,,Springer Verlag,"5th International Visual Informatics Conference, IVIC 2017",28 November 2017 through 30 November 2017,,205759,3029743,9.78332E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85035135801
"Shanmugasundaram K., Mohamed A.S.A., Ruhaiyem N.I.R.",57193491154;57190968285;57190964192;,Hybrid improved bacterial swarm (HIBS) optimization algorithm,2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10645 LNCS,,,71,78,,1,10.1007/978-3-319-70010-6_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035117123&doi=10.1007%2f978-3-319-70010-6_7&partnerID=40&md5=37c714551e6804df5c55ed62d488fd8d,"School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia","Shanmugasundaram, K., School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia; Ruhaiyem, N.I.R., School of Computer Sciences, Universiti Sains Malaysia (USM), Gelugor, Penang  11800, Malaysia","This paper proposed a hybrid improved bacterial swarm optimization (HIBS) algorithm by combining bacterial foraging optimization algorithm (BFO) with particle swarm optimization (PSO) to improve the performance of the classical BFO algorithm. Adaptive step size is introduced instead of fixed step size by random walk of the Fire Fly Algorithm (FFA) in the tumble move of the bacterium at the chemo-taxis stage of BFO. So that, the slow convergence of the BFO algorithm is mitigated. PSO algorithm is acted as mutation operator to attain the global best. So, the trapping out in the local optima by PSO is being avoided. BFO algorithm is used to attain the local best optimality. The new algorithm is tested on a set of benchmark functions. The proposed hybrid algorithm is compared with the original BFO and PSO algorithm. It has been proved that the proposed algorithm shows the significance than the classical BFO and PSO algorithms. © Springer International Publishing AG 2017.",Adaptive step size; Bacterial foraging optimization; Fire fly algorithm; Particle swarm optimization,Particle swarm optimization (PSO); Adaptive step size; Bacterial foraging optimization; Bacterial foraging optimization algorithms; Bacterial swarm optimizations; Benchmark functions; Mutation operators; Optimization algorithms; Slow convergences; Optimization,,,,,Universiti Sains Malaysia: 304/PKOMP/6313280,Acknowledgements. The author wish to thank Universiti Sains Malaysia for the support it has extended in the completion of the present research through Short Term University Grant No. 304/PKOMP/6313280.,,"Alostaz, A., Alhanjouri, M., A new adaptive BFO based on PSO for learning neural network. I-Manager’s (2013) J. Comput. Sci, 1, p. 9; Bakwad, K.M., Patnaik, S.S., Hybrid bacterial foraging with parameter free PSO (2009) IEEE World Congress on Nature and Biologically Inspired Computing; Kevin, M., Biomimicry of bacterial foraging for distributed optimization and control (2002) IEEE Control Syst. Mag.; Biswas, A., Das, S., Abraham, A., Synergy of PSO and bacterial foraging optimization: A comparative study on numerical benchmarks (2007) Innovations in Hybrid Intelligent Systems. ASC, 44, pp. 255-263. , Corchado, E., Corchado, J.M., Abraham, A. (eds.), Springer, Heidelberg; Jarraya, Y., Bouaziz, S., Alimi, A.M., Abraham, A., A hybrid computational chemotaxis in bacterial foraging optimization algorithm for global numerical optimization (2003) IEEE International Conference on Cybernetics, pp. 213-218; Kora, P., Kalva, S.R., Hybrid bacterial foraging and particle swarm optimization for detecting Bundle Branch Block (2015) Springerplus, 4 (1), p. 481; Kumar, S., Sing, S.K., Hybrid BFO and PSO Swarm Intelligence Approach for Biometric Feature Optimization (2017) Nature-Inspired Computing Concepts, Methodologies, Tools, and Applications. IGI Global, Hershey; Yan, X., Zhu, Y., Chen, H., Zhang, H., Improved bacterial foraging optimization with social cooperation and adaptive step size (2012) ICIC 2012. LNCS, 7389, pp. 634-640. , Huang, D.-S., Jiang, C., Bevilacqua, V., Figueroa, J. C. (eds.), Springer, Heidelberg; Daas, M.S., Chikhi, S., Batouche, M., Bacterial foraging optimization with double role of reproduction and step adaptation (2015) Proceedings of International Conference on Intelligent Information Processing, Security and Advanced Communication, 71; Hanmandlu, M., Kumar, A., Madasu, V.K., Yarlagadda, P., Fusion of hand based biometrics using particle swarm optimization (2008) 5Th International Conference on Information Technology: New Generations, pp. 783-788; Cherifi, Multimodal score-level fusion using hybrid GA-PSO for multibiometric system (2015) Informatica, 39, pp. 209-216; Datta, T., Improved adaptive bacteria foraging algorithm in optimization of antenna array for faster convergence (2008) Prog. Electromagn. Res., 1, pp. 143-157; Chen, C.-H., Hybrid of bacterial foraging optimization and particle swarm optimization for evolutionary neural fuzzy classifier (2014) Int. J. Fuzzy Syst, 16, pp. 422-433; Yang, X.-S., Firefly algorithms for multimodal optimization (2009) SAGA 2009. LNCS, 5792, pp. 169-178. , Watanabe, O., Zeugmann, T. (eds.), Springer, Heidelberg; Mao, L., Particle swarm and bacterial foraging inspired hybrid artificial bee colony algorithm for numerical function optimization (2016) Math. Probl. Eng.; Kumar, A., A new framework for adaptive multimodal biometrics management (2010) IEEE Trans. Inf. Forensics Secur., 5, pp. 92-102; Kumar, A., Adaptive management of multimodal biometrics fusion using ant colony optimization (2016) Inf. Fusion, 32, pp. 49-63; Kennedy, J., Kennedy, J.F., Eberhart, R.C., Shi, Y., (2001) Swarm Intelligence, , Morgan Kaufmann, Burlington; Hanmandlu, M., Kumar, A., Madasu, V.K., Yarlagadda, P., Fusion of hand based biometrics using particle swarm optimization (2008) Fifth International Conference on Information Technology: New Generations, pp. 783-788; Kora, P., Krishna, K.S.R., Hybrid firefly and particle swarm optimization algorithm for the detection of Bundle Branch Block (2016) Int. J. Cardiovasc. Acad., 2, pp. 44-48; Ruhaiyem, N.I.R., Mohamed, A.S.A., Belaton, B., Optimized segmentation of cellular tomography through organelles’ morphology and image features (2016) J. Telecommun. Electron. Comput. Eng. (JTEC), 8 (3), pp. 79-83; Thevar, V.V., Ruhaiyem, N.I.R., Concept, theory and application: Hybrid watershed classic and active contour for enhanced image segmentation (2016) Visual Informatics International Seminar; Ruhaiyem, N.I.R., Semi-automated cellular tomogram segmentation workflow (CTSW): Towards an automatic target-scoring system (2014) Proceedings of International Conference on Computer Graphics, Multimedia and Image Processing (CGMIP 2014), pp. 38-48. , Kuala Lumpur, Malaysia; Ruhaiyem, N.I.R., Boundary-based versus region-based approaches for cellular tomography segmentation (2014) Proceedings of 1St International Engineering Conference (IEC 2014), pp. 260-267. , Erbil, Iraq; Ruhaiyem, N.I.R., (2014) Multiple, Object-Oriented Segmentation Methods of Mammalian Cell Tomograms, , Ph.D. Thesis, Institute for Molecular Bioscience, The University of Queensland","Mohamed, A.S.A.; School of Computer Sciences, Malaysia; email: sufril@usm.my",Shih T.K.Velastin S.Robinson P.Smeaton A.F.Terutoshi T.Badioze Zaman H.Jaafar A.Mohamad Ali N.,,Springer Verlag,"5th International Visual Informatics Conference, IVIC 2017",28 November 2017 through 30 November 2017,,205759,3029743,9.78332E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85035117123
"Halim M.A.A., Ruhaiyem N.I.R., Fauzi E.R.I., Jamil M.S.C., Mohamed A.S.A.",57192171962;57190964192;56641781800;36727346400;57190968285;,Automatic laser welding defect detection and classification using sobel-contour shape detection,2016,"Journal of Telecommunication, Electronic and Computer Engineering",8,6,,157,160,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999143636&partnerID=40&md5=defe81e1e55fd4dea02b6484d23f303e,"School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; School of Mechanical Engineering, Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, Penang, 14300, Malaysia","Halim, M.A.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Ruhaiyem, N.I.R., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Fauzi, E.R.I., School of Mechanical Engineering, Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, Penang, 14300, Malaysia; Jamil, M.S.C., School of Mechanical Engineering, Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, Penang, 14300, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","This paper describes a detection of common defects in laser welding of structural aluminum alloy. To overcome these problems, a technique has been proposed to detect defects automatically and effectively using the image segmentation technique. Although, this technique has been well developed, it does suffer from several disadvantages of radiographic images taken to be poor in quality, as well as the microscopic size of the defects together with poor orientation relatively to the small size and thickness of the evaluated parts. Using image segmentation algorithm allows the defects to be automatically inspected and measured within the welded surface such as cracks, porosity and foreign inclusions, which may be weakening the welded parts. This paper proposes a system to automatically identifies and classifies the faults from the welding process by using the existing image segmentation algorithms. The output of the developed system produces a measured analysis which can be then used to describe the mechanical properties of welded part of the alloy such as its tensile and force. The benefits of this project will improve the welding process to reduce faults and defects for both constructing and manufacturing fields.",Automatic laser welding; Classification; Defect detection; Sobel-contour shape,,,,,,,,,"Li, C.-T., Chiao, R., Multiresolution genetic clustering algorithm for texture segmentation (2003) Image and Vision Computing, 21 (11), pp. 955-966; Richardson, I.E., (2003) H.264 and MPEG-4 Video Compression: Video Coding for Next-generation Multimedia, , Wiley; Nejatpour, R., Sadabad, A.A., Automated weld defects detection using image processing and cad methods (2008) ASME International Mechanical Engineering Congress and Exposition; Parvati, K., Prakasa Rao, B.S., Mariya Das, M., Image segmentation using gray-scale morphology and marker-controlled watershed transformation (2008) Discrete Dynamics in Nature and Society, p. 8; Singh, K., Singh, A., A study of image segmentation algorithms for different types of images (2010) IJCSI International Journal of Computer Science, (7), p. 5; Bala, A., An improved watershed image segmentation technique using matlab (2012) International Journal of Scientific & Engineering Research, (3), p. 6; Shen, J., (2012) Application of Image Segmentation In Inspection Of Welding-Practical research in MATLAB, , University Of Boras; Dass, R., Devi, P.S., Image segmentation techniques (2012) IJECT, 3 (1); Chaudhary, A., Gulati, T., Segmenting digital images using edge detection (2013) International Journal of Application of Innovation in Engineering & Management, 2 (5); (2013) WELDER'S Visual Inspection, pp. 32-33. , HANDBOOK; Narsimhachary, D., (2014) Effect of Laser Welding Parameters on 6061 Aluminium Alloy, , Department Of metallurgical And Materials Engineering, National Institute Of Technology Rourkela, Odisha-769008; Nand, G.K., Neogi, N.N., Defect detection of steel surface using entropy segmentation (2014) Annual IEEE India Conference, , Department of Electrical And Electronic Engineering, Birla Institute, Mesra, Ranchi-835215; Alam, M.A., Ali, M.M.N., Syed, M.A.A., Sorif, N., Rahaman, M.A., (2014) An Algorithm to Detect and Identify Defects of Industrial Pipes Using Image Processing, , Department of Electrical and Electronic Engineering, International Islamic University Chittagong (IIUC), Chittagong, Bangladesh; Cogranne, R., Statistical detection of defects in radiographic images using an adaptive parametric model (2014) Signal Processing, 96 (8), pp. 173-189; Madani, S., Azizi, M., (2015) Detection of Weld Defects in Radiography Films Using Image Processing, (9); Che Jamil, M.S., Imam Fauzi, E.R., Juinn, C.S., Sheikh, M.A., Laser bending of pre-stressed thin-walled nickel microtubes (2015) Journal of Optics & Laser Technology, 73, pp. 105-117",,,,Universiti Teknikal Malaysia Melaka,,,,,21801843,,,,English,J. Telecommun. Electron. Comput. Eng.,Article,Final,,Scopus,2-s2.0-84999143636
"Muhammad A., Addenan M.F., Latiff M.M., Haris B., Surip S.S., Mohamed A.S.A.",57197347537;57201709304;57192170886;57192171103;57192173209;57190968285;,Interactive sign language interpreter using skeleton tracking,2016,"Journal of Telecommunication, Electronic and Computer Engineering",8,6,,137,140,,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999114737&partnerID=40&md5=75c02ef77d06f94f371fb4d2555cc81f,"School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Faculty of Business and Management, Universiti Teknologi MARA, Shah Alam, Selangor, 40450, Malaysia; School of The Arts, Universiti Sains Malaysia, Penang, 11800, Malaysia","Muhammad, A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Addenan, M.F., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Latiff, M.M., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Haris, B., Faculty of Business and Management, Universiti Teknologi MARA, Shah Alam, Selangor, 40450, Malaysia; Surip, S.S., School of The Arts, Universiti Sains Malaysia, Penang, 11800, Malaysia; Mohamed, A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","The aim of this paper is to introduce an interactive communication system that will benefit both people with hearing and verbal difficulties to convey in the form of the sign language naturally. The idea is to provide two ways of communication between two users by converting sign language to voice and text and provides means of returning communication feedback whereby the other party can speak or key-in text and translates it into sign language movement performed by a three-dimensional (3D) model. A Microsoft Kinect device is used to captures the sign movements by optimizing the skeleton tracking algorithm to understand specific hands movements and dictates using the pre-recorded gesture library to digitized voice and using the same apparatus, speech is translated back into sign language. Research leads in helping the disables have been carried out extensively and majority focuses on only using single type of motion sensing technology such as TOBII (eye tracking) and LEAP (leap motion) which are either costly or limited to a small workable space. Microsoft Kinect technology would be a genuinely equipment used to create a cost-effective and capable technology prototype that enables sign-language communication between signer and non-signer, thus, offers translation into Bahasa Malaysia text.",Kinect; Language translator; Motion; Sign language; Skeleton tracking,,,,,,,,,"Stokoe, W.C., Casterline, D.C., Croneberg, C.G., (1976) A Dictionary of American Sign Language on Linguistic Principles, , Silver Spring, Md. New Edition [Linstok Press]; Stokoe, W.C., (1978) Sign Language Structure [microform], , Scientific Washington, D.C. Journal, [ERIC Clearinghouse]; Yin-Poole, W., (2010) Source: MS Quadrupling Kinect Accuracy, , http://www.eurogamer.net/articles/2010-12-17-source-ms-quadrupling-kinect-accuracy, Eurogamer. Re-trievedfrom; Woodcock, K., Fisher, S.L., (2008) Occupational Health and Safety for Sign Lan-guage Interpreters, , Workplace Safety and Insurance Board Research Advisory Council Grant, [Ryerson University]; Huang, F., Huang, S., Interpreting American sign language with kinect (2011) Journal of Deaf Studies and Deaf Education, , [Oxford University Press]; Roy, C., Metzger, M., Researching signed language interpreting research through a sociolinguistic lens (2014) The International Journal for Translation & Interpreting Research, , [Oxford University Press]; Isard, M., Black, A., Condensation-conditional density propagation for visual tracking (1998) International Journl of Computer Vision, 29, pp. 5-28; Sidenbladh, H., Black, M.J., Fleet, D.J., Stochastic tracking of 3d human gestures using 2d image motion (2000) European Conference on Computer Vision; Choo, K., Fleet, D., People tacking using hybrid monte carlo filtering (2001) International conference on computer vision, , Vancouver, Canada; Dong, C., Leu, M.C., Yin, Z.Z., American sign language alphabet recognition using microsoft kinect computer vision (2005) Pattern Recognition Workshops (CVPRW) 2015 IEEE Conference on",,,,Universiti Teknikal Malaysia Melaka,,,,,21801843,,,,English,J. Telecommun. Electron. Comput. Eng.,Article,Final,,Scopus,2-s2.0-84999114737
"Ruhaiyem N.I.R., Mohamed A.S.A., Belaton B.",57190964192;57190968285;6504014356;,Optimized Segmentation of Cellular Tomography through Organelles' Morphology and Image Features,2016,"Journal of Telecommunication, Electronic and Computer Engineering",8,3,,79,83,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984846552&partnerID=40&md5=d733b548ab584b20283e495ece0bad7f,"Universiti Sains Malaysia, 11800 USM Penang, Malaysia","Ruhaiyem, N.I.R., Universiti Sains Malaysia, 11800 USM Penang, Malaysia; Mohamed, A.S.A., Universiti Sains Malaysia, 11800 USM Penang, Malaysia; Belaton, B., Universiti Sains Malaysia, 11800 USM Penang, Malaysia","Computational tracing of cellular images generally requires painstaking job in optimizing parameter(s). By incorporating prior knowledge about the organelle's morphology and image features, the required number of parameter tweaking can be reduced substantially. In practical applications, however, the general organelles' features are often known in advance, yet the actual organelles' morphology is not elaborated. Two primary contributions of this paper are firstly the classification of insulin granules based on its image features and morphology for accurate segmentation - mainly focused at pre-processing image segmentation and secondly the new hybrid meshing quantification is presented. The method proposed in this study is validated on a set of manually defined ground truths. The study of insulin granules in particular; the location, and its image features has also opened up other options for future studies.",,,,,,,,,,"Olofsson, C.S., Salehi, A., Holm, C., Rorsman, P., Palmitate increases l- Type ca2+ currents and the size of the readily releasable granule pool in mouse pancreatic beta- cells (2004) Journal of Physiology, 557, pp. 935-948; Hutton, J.C., The insulin secretory granule (1989) Diabetologia, 32, pp. 271-281; Howell, S.L., The molecular organization of the beta granule of the islets of langerhans (1974) Advances in Cytopharmacology, 2, pp. 319-327; Ladinsky, M.S., Wu, C.C., Mcintosh, S., Mcintosh, J.R., Howell, K.E., Structure of the golgi and distribution of reporter molecules at 20 degrees c reveals the complexity of the exit compartments (2002) Molecular Biology of the Cell, 13, pp. 2810-2825; Marsh, B.J., Lessons from tomographic studies of the mammalian golgi (2005) Biochemical and Biophysics Acta, 1744, pp. 273-292; Russ, J.C., Dehoff, R.T., (2000) Practical Stereology, , New York, Kluwer Academic/Plenum; Derganc, J., Mironov, A.A., Svetina, S., Physical factors that affect the number and size of golgi cisternae (2006) Traffic, 7, pp. 85-96; Griffiths, G., Fuller, S.D., Back, R., Hollinshead, M., Pfeiffer, S., Simons, K., The dynamic nature of the golgi complex (1989) Journal of Cell Biology, 108, pp. 277-297; Marsh, B.J., Mastronarde, D.N., Buttle, K.F., Howell, K.E., Mcintosh, J.R., Organellar relationships in the golgi region of the pancreatic beta cell line, hit t15, visualized by high resolution electron tomography (2001) Proceedings of the National Academy of Science U S a, 98, pp. 2399-2406; Ladinsky, M.S., Mastronarde, D.N., Mcintosh, J.R., Howell, K.E., Staehelin, L.A., Golgi, structure in three dimensions: Functional insights from the normal rat kidney cell (1999) Journal of Cell Biology, 144, pp. 1135-1149; Nurntan Raihana, R., (2014) Multiple, Object-oriented Segmentation Methods of Mammalian Cell Tomograms, , PhD Thesis, The University of Queensland; Rorsman, P., Renstrom, E., Insulin granule dynamics in pancreatic beta cells (2003) Diabetologia, 46, pp. 1029-1045; Noske, A.B., Costin, A.J., Morgan, G.P., Marsh, B.J., Expedited approaches to whole cell electron tomography and organelle mark-up in situ in high-pressure frozen pancreatic islets (2008) Journal of Structural, Biology, 161, pp. 298-313; Kremer, J.R., Mastronarde, D.N., Mcintosh, J.R., Computer visualization of three-dimensional image data using imod (1996) Journal of Structural Biology, 116, pp. 71-76; Nurntan Raihana, R., Semi- Automated cellular tomogram segmentation workflow (ctsw): Towards an automaic target scoring system (2014) The International Conference on Computer Graphics, Multimedia and Image Processing",,,,Universiti Teknikal Malaysia Melaka,,,,,21801843,,,,English,J. Telecommun. Electron. Comput. Eng.,Article,Final,,Scopus,2-s2.0-84984846552
"Pearson S.J., Ritchings T., Mohamed A.S.A.",7201386436;15045654400;57190968285;,Regional strain variations in the human patellar tendon,2014,Medicine and Science in Sports and Exercise,46,7,,1343,1351,,16,10.1249/MSS.0000000000000247,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902549535&doi=10.1249%2fMSS.0000000000000247&partnerID=40&md5=c076f3f0f1e4433c4a398e1a429848a7,"Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Manchester M66PU, United Kingdom; Control and Systems Engineering Research Centre, University of Salford, Greater Manchester, United Kingdom","Pearson, S.J., Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Manchester M66PU, United Kingdom; Ritchings, T., Control and Systems Engineering Research Centre, University of Salford, Greater Manchester, United Kingdom; Mohamed, A.S.A., Control and Systems Engineering Research Centre, University of Salford, Greater Manchester, United Kingdom","Purpose: Characteristics of localized tendon strain in vivo are largely unknown. The present study examines local tendon strain between the deep, middle, and surface structures at the proximal and distal aspects of the patellar tendon during ramped isometric contractions. Methods: Male subjects (age 28.0 ± 6.3 yr) were examined for patellar tendon excursion (anterior, midsection, and posterior) during ramped isometric voluntary contractions using real-time B-mode ultrasonography and dynamometry. Regional tendon excursion measurements were compared using an automated pixel tracking method. Strain was determined from the tendon delta length normalized to initial/resting segment length. Results: Strain increased from 10% to 100% of force for all regions. Significantly greater mean strain was seen for the anterior proximal region compared to the posterior and mid layer of the tendon (7.5% ± 1.1% vs 3.7% ± 0.5% vs 5.5% ± 1.0%; P < 0.05). Similarly, the distal posterior region showed greater mean strain compared to the mid and anterior regions (7.9% ± 0.6% vs 5.0% ± 0.6% vs 5.4% ± 0.6%; P < 0.05). Relative changes in strain differences from 50% to 100% of force for the proximal region were greatest for the anterior to midline regions (4.6% ± 0.6% and 5.6% ± 0.6%, respectively) and those for the distal region were also greatest for the anterior to midline regions (4.4% ± 0.2% and 5.3% ± 0.2%, respectively). The largest mean strain for the proximal region was at the anterior layer (7.5% ± 1.1%) and that for the distal tendon region was at the posterior layer (7.9% ± 0.9%). Conclusions: This study shows significant regional differences in strain during ramped isometric contractions for the patellar tendon. Lower proximal strains in the posterior tendon compared to the anterior region may be associated with the suggestion of ""stress shielding"" as an etiological factor in insertional tendinopathy. © 2014 by the American College of Sports Medicine.",In Vivo; regional structural properties; tendon; ultrasound,"adult; biomechanics; dynamometer; human; male; mechanical stress; muscle isometric contraction; patella ligament; physiology; risk factor; young adult; Adult; Biomechanical Phenomena; Humans; Isometric Contraction; Male; Muscle Strength Dynamometer; Patellar Ligament; Risk Factors; Stress, Mechanical; Young Adult",,,,,,,,"Almekinders, L.C., Vellema, J.H., Weinhold, P.S., Strain patterns in the patellar tendon and the implications for patellar tendinopathy (2002) Knee Surg Sports Traumatol Arthrosc., 10 (1), pp. 2-5; Arndt, A., Bengtsson, A.S., Peolsson, M., Thorstensson, A., Movin, T., Non-uniform displacement within the Achilles tendon during passive ankle joint motion (2011) Knee Surg Sports Traumatol Arthrosc., pp. 1868-1874; Arndt, A., Bruggemann, G.P., Koebke, J., Segesser, B., Asymmetrical loading of the human triceps surae: I. Mediolateral force differences in the Achilles tendon (1999) Foot Ankle Int., 20, pp. 444-449; Basso, O., Amis, A.A., Race, A., Johnson, D.P., Patellar tendon fiber strains: Their differential responses to quadriceps tension (2002) Clin Orthop Relat Res., 400, pp. 246-253; Bojsen-Moller, J., Hansen, P., Aagaard, P., Svantsson, U., Kjaer, M., Magnusson, P., Differential displacement of the human soleus and medial gastrocnemius aponeuroses during isometric plantar flexion contractions in vivo (2004) J. Appl Physiol., 97, pp. 1908-1914; Carolan, B., Cafarelli, E., Adaptations in coactivation after isometric resistance training (1992) J Appl Physiol., 73 (3), pp. 911-917; Carroll, C.C., Dickinson, J.M., Haus, J.M., Influence of aging on the in vivo properties of human patellar tendon (2008) J Appl Physiol., 105 (6), pp. 1907-1915; Child, S., Bryant, A.L., Clark, R.A., Crossley, K.M., Mechanical properties of the Achilles tendon aponeurosis are altered in athletes with Achilles tendinopathy (2010) Am J Sports Med., 9 (38), pp. 1885-1893; Couppé, C., Kongsgaard, M., Aagaard, P., Habitual loading results in tendon hypertrophy and increased stiffness of the human patellar tendon (2008) J Appl Physiol., 105 (3), pp. 805-810; Dilley, A., Greening, J., Lynn, B., Leary, R., Morris, V., The use of cross-correlation analysis between high-frequency ultrasound images to measure longitudinal median nerve movement (2001) Ultrasound Med Biol., 27 (9), pp. 1211-1218; Farron, J., Varghese, T., Thelen, D.G., Measurement of tendon strain during muscle twitch contractions using ultrasound elastography (2009) IEEE Trans Ultrason Ferroelectr Freq Control., 56 (1), pp. 27-35; Hansen, P., Bojsen-Moller, J., Aagaard, P., Kjaer, M., Magnusson, S.P., Mechanical properties of the human patellar tendon, in vivo (2006) Clin Biomech (Bristol, Avon)., 21 (1), pp. 54-58; Hansen, P., Haraldsson, B.T., Aagaard, P., Lower strength of the human posterior patellar tendon seems unrelated to mature collagen cross-linking and fibril morphology (2010) J Appl Physiol., 108 (1), pp. 47-52; Haraldsson, B.T., Aagaard, P., Krogsgaard, M., Alkjaer, T., Kjaer, M., Magnusson, S.P., Region-specific mechanical properties of the human patella tendon (2005) J Appl Physiol., 98 (3), pp. 1006-1012; Hermens, H.J., Fredriks, B., Disselhorst-Klug, C., Rau, G., Development of recommendations for SEMG sensors and sensor placement procedures (2000) J Electromyogr Kinesiol., 10 (5), pp. 361-374; Kim, Y.S., Kim, J.M., Bigliani, L.U., Kim, H.J., Jung, H.W., In vivo strain analysis of the intact supraspinatus tendon by ultrasound speckles tracking imaging (2011) J Orthop Res., 29 (12), pp. 1931-1937; Kongsgaard, M., Reitelseder, S., Pedersen, T.G., Region specific patellar tendon hypertrophy in humans following resistance training (2007) Acta Physiol (Oxf)., 191 (2), pp. 111-121; Korstanje, J.W., Selles, R.W., Stam, H.J., Hovius, S.E., Bosch, J.G., Development and validation of ultrasound speckle tracking to quantify tendon displacement (2010) J Biomech., 43 (7), pp. 1373-1379; Kovanen, V., Suominen, H., Age and training-related changes in the collagen metabolism of rat skeletal muscle (1989) Eur J Appl Physiol Occup Physiol., 58 (7), pp. 765-771; Krevolin, J.L., Pandy, M.G., Pearce, J.C., Moment arm of the patellar tendon in the human knee (2004) J Biomech., 37 (5), pp. 785-788; Kubo, K., Ikebukuro, T., Maki, A., Yata, H., Tsunoda, N., Time course of changes in the human Achilles tendon properties and metabolism during training and detraining in vivo (2012) Eur J Appl Physiol., 112 (7), pp. 2679-2691; Leadbetter, W.B., Cell-matrix response in tendon injury (1992) Clin Sports Med., 11 (3), pp. 533-578; Lersch, C., Grötsch, A., Segesser, B., Koebke, J., Brüggemann, G.P., Potthast, W., Influence of calcaneus angle and muscle forces on strain distribution in the human Achilles tendon (2012) Clin Biomech (Bristol, Avon), 27 (9), pp. 955-961; Lippold, O.C., The relationship between integrated action potentials in a human muscle and its isometric tension (1952) J Physiol., 177, pp. 492-499; Loram, I.D., Maganaris, C.N., Lakie, M., Use of ultrasound to make noninvasive in vivo measurement of continuous changes in human muscle contractile length (2006) J Appl Physiol., 100 (4), pp. 1311-1323; Maganaris, C.N., Narici, M.V., Almekinders, L.C., Maffulli, N., Biomechanics and pathophysiology of overuse tendon injuries: Ideas on insertional tendinopathy (2004) Sports Med., 34 (14), pp. 1005-1017; Magnusson, S.P., Kjaer, M., Region-specific differences in Achilles tendon cross-sectional area in runners and non-runners (2003) Eur J Appl Physiol., 90, pp. 549-553; Miller, B.F., Olesen, J.L., Hansen, M., Dlssing, S., Crameri, R.M., Welling, R.J., Coordinated collagen and muscle protein synthesis in human patella tendon and quadriceps muscle after exercise (2005) J Physiol., 15 (567), pp. 1021-1033; Ofer, N., Akselrod, S., Nyska, M., Werner, M., Glaser, E., Shabat, S., Motion-based tendon diagnosis using sequence processing of ultrasound images (2004) J Orthop Res., 22 (6), pp. 1296-1302; Onambele, G.N., Burgess, K., Pearson, S.J., Gender-specific in vivo measurement of the structural and mechanical properties of the human patellar tendon (2007) J Orthop Res., 25 (12), pp. 1635-1642; Pearson, S.J., Burgess, K., Onambele, G.N., Creep and the in vivo assessment of human patellar tendon mechanical properties (2007) Clin Biomech (Bristol, Avon), 22 (6), pp. 712-717; Pearson, S.J., Onambele, G.N., Influence of time of day on tendon compliance and estimations of voluntary activation levels (2006) Muscle Nerve, 33 (6), pp. 792-800; Pearson, S.J., Ritchings, T., Mohamed, A.S., The use of normalized crosscorrelation analysis for automatic tendon excursion measurement in dynamic ultrasound imaging (2013) J Appl Biomech., 29 (2), pp. 165-173; Revell, J., Mirmehdi, M., McNally, D., Computer vision elastography: Speckle adaptive motion estimation for elastography using ultrasound sequences (2005) IEEE Trans Med Imaging., 24 (6), pp. 755-766","Pearson, S.J.; Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Manchester M66PU, United Kingdom; email: s.pearson@salford.ac.uk",,,Lippincott Williams and Wilkins,,,,,1959131,,MSCSB,24389512,English,Med. Sci. Sports Exerc.,Article,Final,,Scopus,2-s2.0-84902549535
"Pearson S.J., Ritchings T., Mohamed A.S.A.",7201386436;15045654400;57190968285;,The use of normalized cross-correlation analysis for automatic tendon excursion measurement in dynamic ultrasound imaging,2013,Journal of Applied Biomechanics,29,2,,165,173,,13,10.1123/jab.29.2.165,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877992010&doi=10.1123%2fjab.29.2.165&partnerID=40&md5=a92dccc2ab17fb48c0172f2ba5c0b20f,"Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Greater Manchester, United Kingdom; Control and Systems Engineering Research Centre, University of Salford, Greater Manchester, United Kingdom","Pearson, S.J., Centre for Health, Sport and Rehabilitation Sciences Research, University of Salford, Greater Manchester, United Kingdom; Ritchings, T., Control and Systems Engineering Research Centre, University of Salford, Greater Manchester, United Kingdom; Mohamed, A.S.A., Control and Systems Engineering Research Centre, University of Salford, Greater Manchester, United Kingdom","The work describes an automated method of tracking dynamic ultrasound images using a normalized crosscorrelation algorithm, applied to the patellar and gastrocnemius tendon. Displacement was examined during active and passive tendon excursions using B-mode ultrasonography. In the passive test where two regions of interest (2-ROI) were tracked, the automated tracking algorithm showed insignificant deviations from relative zero displacement for the knee (0.01 ± 0.04 mm) and ankle (-0.02 ± 0.04 mm) (P > .05). Similarly, when tracking 1-ROI the passive tests showed no significant differences (P > .05) between automatic and manual methods, 7.50 ± 0.60 vs 7.66 ± 0.63 mm for the patellar and 11.28 ± 1.36 vs 11.17 ± 1.35 mm for the gastrocnemius tests. The active tests gave no significant differences (P > .05) between automatic and manual methods with differences of 0.29 ± 0.04 mm for the patellar and 0.26 ± 0.01 mm for the gastrocnemius. This study showed that automatic tracking of in vivo displacement of tendon during dynamic excursion under load is possible and valid when compared with the standardized method. This approach will save time during analysis and enable discrete areas of the tendon to be examined. © 2013 Human Kinetics, Inc.",Normalized cross-correlation; Speckle tracking; Tendon; Ultrasound,Ultrasonic imaging; Ultrasonics; Automated tracking; Automatic tracking; Normalized cross correlation; Regions of interest; Speckle tracking; Standardized methods; Ultrasound images; Ultrasound imaging; Tendons; adult; algorithm; ankle; article; automation; B scan; biomechanics; correlation analysis; gastrocnemius muscle; human; human experiment; image analysis; in vivo study; knee; male; measurement; musculoskeletal function; normal human; patella tendon; tendon excursion,,,,,,,,"Fukunaga, T., Ito, M., Ichinose, Y., Kuno, S., Kawakami, Y., Fukashiro, S., Tendinous movement of a human muscle during voluntary contractions determined by real-time ultrasonography (1996) Journal of Applied Physiology, 81 (3), pp. 1430-1433; Kubo, K., Kanehisa, H., Kawakami, Y., Fukunaga, T., Elastic properties of muscle-tendon complex in long-distance runners (2000) Eur J Appl Physiol, 81, pp. 181-187. , PubMed doi:10.1007/s004210050028; Hansen, P., Bojsen-Moller, J., Aagaard, P., Kjaer, M., Magnusson, S.P., Mechanical properties of the human patellar tendon, in vivo (2006) Clin Biomech (Bristol, Avon), 21, pp. 54-58. , PubMed doi:10.1016/j.clinbiomech.2005.07.008; Onambélé, G.N., Burgess, K., Pearson, S.J., Gender-specific in vivo measurement of the structural and mechanical properties of the human patellar tendon (2007) J Orthop Res, 25, pp. 1635-1642. , PubMed doi:10.1002/jor.20404; Dilley, A., Greening, J., Lynn, B., Leary, R., Morris, V., The use of cross-correlation analysis between high-frequency ultrasound images to measure longitudinal median nerve movement (2001) Ultrasound in Medicine and Biology, 27 (9), pp. 1211-1218. , DOI 10.1016/S0301-5629(01)00413-6, PII S0301562901004136; Lee, S.S.M., Lewis, G.S., Piazza, S.J., An algorithm for automated analysis of ultrasound images to measure tendon excursion in vivo (2008) Journal of Applied Biomechanics, 24 (1), pp. 75-82. , http://www.humankinetics.com/eJournalMedia/pdfs/15521.pdf; Kim, Y.S., Kim, J.M., Bigliani, L.U., Kim, H.J., Jung, H.W., In vivo strain analysis of the intact supraspinatus tendon by ultrasound speckles tracking imaging (2011) J Orthop Res, 29, pp. 1931-1937. , PubMed doi:10.1002/jor.21470; Farron, J., Varghese, T., Thelen, D.G., Measurement of Tendon Strain During Muscle Twitch Contractions Using Ultrasonography (2009) IEEE Transaction of Ultrasonics, Ferroelectrics, and Frequency Control, 56, pp. 27-35. , doi:10.1109/TUFFC.2009.1002; Koga, T., Iinuma, K., Hirano, A., Iijima, Y., Ishiguro, T., Motion Compensated Interframe Coding for Video Conferencing Proc. Nat. Telcommun. Conf., New Orleans, LA. 1981;Nov, pp. 5.3.1-5.3.5; Arampatzis, A., Stafilidis, S., DeMonte, G., Karaminidis, K., Morey-Klapsing, G., Bruggemann, G.P., Strain and elongation of the human gastrocnemius tendon and aponeurosis during maximal plantarflexion effort (2005) J Biomech, 38, pp. 883-1841. , PubMed; Revell, M.M., McNally, D., Computer vision elastography: Speckle adaptive motion estimation for elastography using ultrasound sequences (2005) IEEE Trans Med Imaging, 24, p. 755. , PubMed doi:10.1109/TMI.2005.848331; Pearson, S.J., Burgess, K., Onambele, G.N., Creep and the in vivo assessment of human patellar tendon mechanical properties (2007) Clin Biomech (Bristol, Avon), 22, pp. 712-717. , PubMed doi:10.1016/j.clinbiomech.2007.02.006; Maganaris, C.N., Baltzopoulos, V., Sergeant, A.K., In vivo measurement-based estimations of the human Achilles tendon moment arm (2000) Eur J Appl Physiol, 83, pp. 363-369. , PubMed doi:10.1007/s004210000247; Magnusson, S.P., Hansen, P., Aagaard, P., Differential strain patterns of the human gastrocnemius aponeurosis and free tendon, in vivo (2003) Acta Physiol Scand, 177, pp. 185-195. , PubMed doi:10.1046/j.1365-201X.2003.01048.x; Loram, I.D., Maganaris, C.N., Lakie, M., Use of ultrasound to make noninvasive in vivo measurement of continuous changes in human muscle contractile length (2006) J Appl Physiol, 100, pp. 1311-1323. , PubMed doi:10.1152/japplphysiol.01229.2005","Pearson, S.J.; Centre for Health, , Greater Manchester, United Kingdom",,,Human Kinetics Publishers Inc.,,,,,10658483,,JABOE,,English,J. Appl. Biomech.,Article,Final,,Scopus,2-s2.0-84877992010
